{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Concrete Strength Prediction</center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset - Concrete Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Description of the dataset\n",
    "The dataset describes the strength of the concrete for different proportions of its ingredients. The various ingredients that helps to determine the strength of the concrete includes:\n",
    "<ul>\n",
    "    <li>Cement</li>\n",
    "    <li>Blast Furnace Slag</li>\n",
    "    <li>Fly Ash</li>\n",
    "    <li>Water</li>\n",
    "    <li>Superplasticizer</li>\n",
    "    <li>Coarse Aggregate</li>\n",
    "    <li>Fine Aggregate</li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
       "0   540.0                 0.0      0.0  162.0               2.5   \n",
       "1   540.0                 0.0      0.0  162.0               2.5   \n",
       "2   332.5               142.5      0.0  228.0               0.0   \n",
       "3   332.5               142.5      0.0  228.0               0.0   \n",
       "4   198.6               132.4      0.0  192.0               0.0   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate  Age  Strength  \n",
       "0            1040.0           676.0   28     79.99  \n",
       "1            1055.0           676.0   28     61.89  \n",
       "2             932.0           594.0  270     40.27  \n",
       "3             932.0           594.0  365     41.05  \n",
       "4             978.4           825.5  360     44.30  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the data\n",
    "concrete_df = pd.read_csv('concrete_data.csv')\n",
    "concrete_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1030, 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape of the data\n",
    "concrete_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>281.167864</td>\n",
       "      <td>73.895825</td>\n",
       "      <td>54.188350</td>\n",
       "      <td>181.567282</td>\n",
       "      <td>6.204660</td>\n",
       "      <td>972.918932</td>\n",
       "      <td>773.580485</td>\n",
       "      <td>45.662136</td>\n",
       "      <td>35.817961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>104.506364</td>\n",
       "      <td>86.279342</td>\n",
       "      <td>63.997004</td>\n",
       "      <td>21.354219</td>\n",
       "      <td>5.973841</td>\n",
       "      <td>77.753954</td>\n",
       "      <td>80.175980</td>\n",
       "      <td>63.169912</td>\n",
       "      <td>16.705742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>102.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>121.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>594.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>192.375000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>164.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>932.000000</td>\n",
       "      <td>730.950000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>23.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>272.900000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>968.000000</td>\n",
       "      <td>779.500000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>34.445000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>350.000000</td>\n",
       "      <td>142.950000</td>\n",
       "      <td>118.300000</td>\n",
       "      <td>192.000000</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>1029.400000</td>\n",
       "      <td>824.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>46.135000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>540.000000</td>\n",
       "      <td>359.400000</td>\n",
       "      <td>200.100000</td>\n",
       "      <td>247.000000</td>\n",
       "      <td>32.200000</td>\n",
       "      <td>1145.000000</td>\n",
       "      <td>992.600000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>82.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Cement  Blast Furnace Slag      Fly Ash        Water  \\\n",
       "count  1030.000000         1030.000000  1030.000000  1030.000000   \n",
       "mean    281.167864           73.895825    54.188350   181.567282   \n",
       "std     104.506364           86.279342    63.997004    21.354219   \n",
       "min     102.000000            0.000000     0.000000   121.800000   \n",
       "25%     192.375000            0.000000     0.000000   164.900000   \n",
       "50%     272.900000           22.000000     0.000000   185.000000   \n",
       "75%     350.000000          142.950000   118.300000   192.000000   \n",
       "max     540.000000          359.400000   200.100000   247.000000   \n",
       "\n",
       "       Superplasticizer  Coarse Aggregate  Fine Aggregate          Age  \\\n",
       "count       1030.000000       1030.000000     1030.000000  1030.000000   \n",
       "mean           6.204660        972.918932      773.580485    45.662136   \n",
       "std            5.973841         77.753954       80.175980    63.169912   \n",
       "min            0.000000        801.000000      594.000000     1.000000   \n",
       "25%            0.000000        932.000000      730.950000     7.000000   \n",
       "50%            6.400000        968.000000      779.500000    28.000000   \n",
       "75%           10.200000       1029.400000      824.000000    56.000000   \n",
       "max           32.200000       1145.000000      992.600000   365.000000   \n",
       "\n",
       "          Strength  \n",
       "count  1030.000000  \n",
       "mean     35.817961  \n",
       "std      16.705742  \n",
       "min       2.330000  \n",
       "25%      23.710000  \n",
       "50%      34.445000  \n",
       "75%      46.135000  \n",
       "max      82.600000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the dataset for missing values\n",
    "concrete_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cement                0\n",
       "Blast Furnace Slag    0\n",
       "Fly Ash               0\n",
       "Water                 0\n",
       "Superplasticizer      0\n",
       "Coarse Aggregate      0\n",
       "Fine Aggregate        0\n",
       "Age                   0\n",
       "Strength              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counting the null values in each feature of the dataset\n",
    "concrete_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is very clean. Thus it is ready to build a model. Before building a model, let us visualize it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Cement', 'Blast Furnace Slag', 'Fly Ash', 'Water', 'Superplasticizer',\n",
       "       'Coarse Aggregate', 'Fine Aggregate', 'Age', 'Strength'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizing the dataset\n",
    "features = concrete_df.columns\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "color = ['r','g','b','c','m','y','blue','orange']\n",
    "for i in range(len(features)-1):\n",
    "    x_cor = concrete_df[features[i]].values\n",
    "    y_cor = concrete_df[features[-1]].values\n",
    "    plt.scatter(x_cor,y_cor,color=color[i])\n",
    "    plt.xlabel(features[i])\n",
    "    plt.ylabel('Strength')\n",
    "    plt.title('{0} Vs Strength'.format(features[i]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seperating Predictor Variables and Response Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Getting all the columns except the 'Strength' column\n",
    "X = concrete_df[features[features != features[-1]]]\n",
    "# Getting the 'Response variable', that is the 'Strength' column\n",
    "Y = concrete_df[[features[-1]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of preditor variable: (1030, 8)\n",
      "Size of response variable: (1030, 1)\n"
     ]
    }
   ],
   "source": [
    "# Getting the shape of the predictor and response variable\n",
    "print('Size of preditor variable:',X.shape)\n",
    "print('Size of response variable:',Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of columns in predictor data\n",
    "n_cols = X.shape[1]\n",
    "n_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. BASE LINE MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Charecteristics of the neural network:**\n",
    "<ul>\n",
    "    <li><b>1</b> hidden layer - with <b>10</b> nodes</li>\n",
    "    <li><b>Activation Function</b>: ReLU </li>\n",
    "    <li><b>Optimizer used</b>: Adam</li>\n",
    "    <li><b>Loss Function</b>: Mean Squared Error (MSE)</li>\n",
    "</ul>\n",
    "\n",
    "The data is randomly split into test sets (**30%**) and train sets (**70%**) and fed into the **Base Line Model**. The model is trained using **50** epochs. Using the test data the model is evaluated and Mean Sqaured Error (**MSE**) is computed.\n",
    "<BR>\n",
    "The baseline model is trained and tested **50 times** each time a different train and test data randomly fed from the dataset, thus computing a set of 50 mean squared errors. Hence the best value of mean squared error is computed and standard deviation is also computed from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the neural network\n",
    "def base_line_model():\n",
    "    # Model Creation\n",
    "    reg_mod = Sequential()\n",
    "    reg_mod.add(Dense(10, activation='relu',input_shape=(n_cols,)))\n",
    "    reg_mod.add(Dense(1))\n",
    "    # Model compilation\n",
    "    reg_mod.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return reg_mod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset split\n",
    "<ol>\n",
    "    <li>Training set: <b>70%</b></li>\n",
    "    <li>Testing set: <b>30%</b></li>\n",
    "    </ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(model, predictor_set, response_set, epochs):\n",
    "    \n",
    "    # Dataset split randomly \n",
    "    # Training set - 70 %\n",
    "    # Testing set - 30 %\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X,Y,test_size=0.3, random_state=5)\n",
    "    print('-----DESCRIPTION----'+' Predictors '+'Labels')\n",
    "    print('Size of training set:',x_train.shape,y_train.shape)\n",
    "    print('Size of testing set: ',x_test.shape,y_test.shape)\n",
    "    \n",
    "    # Training the model with training set using a nuumber epochs\n",
    "    # Fitting the built model with the training set\n",
    "    model.fit(x_train, y_train, validation_split = 0.3, epochs=epochs,verbose=1)\n",
    "    \n",
    "    # Evaluating the model using the test data and predicted value, thus computing mean squared error\n",
    "\n",
    "    # Predicting the values\n",
    "    y_pred = model.predict(x_test)\n",
    "    \n",
    "    # Computing mean squared error\n",
    "    MSE = mean_squared_error(y_test,y_pred)\n",
    "    return MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = base_line_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 38985.9961 - val_loss: 25293.2148\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 17399.9570 - val_loss: 10466.1982\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6762.6709 - val_loss: 3965.6138\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2487.9043 - val_loss: 1727.2634\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1210.9597 - val_loss: 1106.7258\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 917.6122 - val_loss: 971.9320\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 858.9481 - val_loss: 934.8622\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 829.3625 - val_loss: 910.0807\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 802.8891 - val_loss: 884.9734\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 773.5795 - val_loss: 858.4407\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 747.4201 - val_loss: 833.4340\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 718.8002 - val_loss: 809.8570\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 693.5267 - val_loss: 786.9790\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 667.1727 - val_loss: 763.0488\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 642.4034 - val_loss: 739.8381\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 618.2350 - val_loss: 717.5284\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 595.6434 - val_loss: 694.8464\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 571.1927 - val_loss: 671.6151\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 550.2674 - val_loss: 652.0170\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 529.2340 - val_loss: 629.7577\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 509.9941 - val_loss: 608.3504\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 488.2168 - val_loss: 582.5151\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 460.0272 - val_loss: 548.8384\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 429.1993 - val_loss: 510.3508\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 397.4243 - val_loss: 470.6136\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 366.6494 - val_loss: 432.8333\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 338.1479 - val_loss: 399.9684\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 312.2935 - val_loss: 370.0556\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 292.7170 - val_loss: 343.3024\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 272.1974 - val_loss: 321.9337\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 256.7123 - val_loss: 304.4590\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 242.8948 - val_loss: 287.7358\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 231.6415 - val_loss: 275.2529\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 222.1575 - val_loss: 263.0236\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 213.1203 - val_loss: 253.9782\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 205.5845 - val_loss: 244.4547\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 199.5182 - val_loss: 237.5890\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 194.4808 - val_loss: 230.2101\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 188.8321 - val_loss: 225.6380\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 185.8699 - val_loss: 218.7698\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 183.0633 - val_loss: 213.1095\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 179.0763 - val_loss: 212.3182\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 174.3775 - val_loss: 205.8887\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 171.3419 - val_loss: 201.3294\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 169.7174 - val_loss: 199.6216\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 167.4487 - val_loss: 195.4720\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 164.9975 - val_loss: 190.8023\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 161.1775 - val_loss: 189.7946\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 159.6925 - val_loss: 184.3724\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 160.6085 - val_loss: 187.2663\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 155.7847 - val_loss: 181.0014\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 152.4393 - val_loss: 178.2122\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 150.0979 - val_loss: 174.4803\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 148.0195 - val_loss: 173.2945\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 146.7887 - val_loss: 170.1820\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 145.2005 - val_loss: 168.0215\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 143.5197 - val_loss: 164.9742\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 141.4447 - val_loss: 162.8028\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 140.3091 - val_loss: 161.7095\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 140.3382 - val_loss: 159.6875\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 138.1393 - val_loss: 157.7655\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 136.4605 - val_loss: 156.2171\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 135.7038 - val_loss: 157.5930\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 136.3551 - val_loss: 152.4177\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 135.0861 - val_loss: 150.5129\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 133.6475 - val_loss: 153.4415\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 129.6045 - val_loss: 147.5512\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 130.1730 - val_loss: 147.8645\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 128.8133 - val_loss: 147.0986\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 127.9530 - val_loss: 144.2546\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 132.2995 - val_loss: 148.5059\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 127.5013 - val_loss: 143.2886\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 126.8622 - val_loss: 141.7050\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 126.9573 - val_loss: 147.8125\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 125.2549 - val_loss: 139.9646\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 123.5159 - val_loss: 136.8161\n",
      "Epoch 27/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 123.1381 - val_loss: 140.5377\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 121.7219 - val_loss: 135.4908\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 122.0263 - val_loss: 138.6631\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 120.7167 - val_loss: 134.6523\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 120.3734 - val_loss: 133.1747\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 120.2177 - val_loss: 133.2183\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 120.1223 - val_loss: 134.9470\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 119.6686 - val_loss: 134.9159\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 120.0277 - val_loss: 131.0689\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 118.8387 - val_loss: 130.2456\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 118.6745 - val_loss: 141.9736\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 125.3796 - val_loss: 129.4120\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 118.2658 - val_loss: 130.4743\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 117.5246 - val_loss: 129.7891\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 118.7023 - val_loss: 128.6383\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 116.3905 - val_loss: 128.8607\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 117.3659 - val_loss: 126.6895\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 116.7387 - val_loss: 129.7265\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 116.6400 - val_loss: 126.8796\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 115.8388 - val_loss: 128.1344\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 115.8554 - val_loss: 127.2716\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 115.7794 - val_loss: 126.5935\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 115.6331 - val_loss: 127.1446\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 115.2654 - val_loss: 125.6839\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 114.9758 - val_loss: 124.6182\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 117.6167 - val_loss: 126.1574\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 116.4218 - val_loss: 126.0659\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 113.7776 - val_loss: 123.5240\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 114.6584 - val_loss: 124.3971\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 113.8566 - val_loss: 124.5674\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 113.8688 - val_loss: 122.3231\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 115.0089 - val_loss: 121.7533\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 115.1361 - val_loss: 125.2175\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 115.9721 - val_loss: 131.3564\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 117.5376 - val_loss: 121.9883\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 115.1136 - val_loss: 121.1541\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 112.7570 - val_loss: 125.5399\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 112.6705 - val_loss: 120.1880\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 113.2787 - val_loss: 122.9207\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 112.5036 - val_loss: 120.9497\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 112.7834 - val_loss: 119.5838\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 118.3616 - val_loss: 132.4782\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 117.6130 - val_loss: 127.1877\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 115.6712 - val_loss: 119.2309\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 113.0057 - val_loss: 119.1037\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 112.2943 - val_loss: 119.7276\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 113.2744 - val_loss: 125.2327\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 113.6958 - val_loss: 120.3212\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 113.6920 - val_loss: 126.0776\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 112.8985 - val_loss: 119.8841\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 112.0076 - val_loss: 121.0978\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 112.3338 - val_loss: 118.0839\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 112.7627 - val_loss: 118.1018\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.7271 - val_loss: 125.3283\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 113.7926 - val_loss: 120.1281\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 112.5846 - val_loss: 118.4063\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.6378 - val_loss: 122.8266\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.1474 - val_loss: 118.9772\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.1032 - val_loss: 119.8354\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.8082 - val_loss: 118.3457\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.9057 - val_loss: 117.2009\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.2549 - val_loss: 121.0329\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.3943 - val_loss: 118.5077\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.6490 - val_loss: 117.1355\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 112.2683 - val_loss: 117.2221\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 114.0711 - val_loss: 119.6103\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.8145 - val_loss: 117.7296\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.9515 - val_loss: 116.6670\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.8906 - val_loss: 116.4616\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 112.4727 - val_loss: 117.3601\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 113.5401 - val_loss: 124.6714\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.7733 - val_loss: 120.3525\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 115.5926 - val_loss: 115.6945\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 115.4154 - val_loss: 115.9795\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.5823 - val_loss: 118.5380\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.0238 - val_loss: 117.5554\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 4ms/step - loss: 111.0666 - val_loss: 115.1545\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.7728 - val_loss: 114.8991\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.5236 - val_loss: 116.9832\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.2006 - val_loss: 132.6696\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 115.5598 - val_loss: 115.6990\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.5487 - val_loss: 114.1645\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.7093 - val_loss: 116.2180\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.3637 - val_loss: 113.9124\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.8813 - val_loss: 119.3062\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.7938 - val_loss: 114.2570\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.1418 - val_loss: 119.8269\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 111.1872 - val_loss: 120.3594\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.2008 - val_loss: 118.1138\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.6626 - val_loss: 119.7911\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 114.1413 - val_loss: 113.8480\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 112.3140 - val_loss: 113.6567\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.3786 - val_loss: 113.7180\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.6761 - val_loss: 115.9528\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.2341 - val_loss: 112.8335\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.1522 - val_loss: 114.7462\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 112.9563 - val_loss: 118.0878\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.7633 - val_loss: 113.3148\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.0890 - val_loss: 113.1972\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.3653 - val_loss: 114.8655\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.6117 - val_loss: 114.5212\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.5270 - val_loss: 116.3839\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.7610 - val_loss: 113.1054\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 108.4850 - val_loss: 112.2655\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.6403 - val_loss: 113.1447\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 110.3870 - val_loss: 117.7883\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.1139 - val_loss: 112.9125\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.9153 - val_loss: 112.7952\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.8529 - val_loss: 113.6248\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.9419 - val_loss: 111.9224\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.5247 - val_loss: 113.8536\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.7538 - val_loss: 119.7796\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.2195 - val_loss: 112.9158\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 110.2439 - val_loss: 112.2066\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.6257 - val_loss: 112.9272\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.0751 - val_loss: 112.5310\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.2620 - val_loss: 113.8635\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.2453 - val_loss: 112.3986\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.4532 - val_loss: 115.0688\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.3743 - val_loss: 112.1501\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.9886 - val_loss: 113.6323\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.5068 - val_loss: 114.5056\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.8063 - val_loss: 117.1553\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.0986 - val_loss: 111.7667\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 109.0775 - val_loss: 111.7326\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.9852 - val_loss: 114.3153\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.0213 - val_loss: 111.4532\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.4616 - val_loss: 112.4914\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.6611 - val_loss: 111.7995\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.9036 - val_loss: 112.1160\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.8933 - val_loss: 111.8356\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.5405 - val_loss: 111.7445\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.5318 - val_loss: 112.5179\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.0188 - val_loss: 114.5426\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.5347 - val_loss: 112.3499\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.7108 - val_loss: 111.4554\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 109.7439 - val_loss: 123.0889\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.0836 - val_loss: 117.3304\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 114.7986 - val_loss: 121.5967\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.7595 - val_loss: 111.5669\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 119.0386 - val_loss: 115.1814\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.9233 - val_loss: 111.5608\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.1615 - val_loss: 111.9398\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.9221 - val_loss: 111.6733\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.3281 - val_loss: 111.2759\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 112.5868 - val_loss: 112.2533\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.0146 - val_loss: 111.4914\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.4491 - val_loss: 115.7558\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.7846 - val_loss: 127.1440\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.6481 - val_loss: 111.7791\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.1532 - val_loss: 113.3024\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.9463 - val_loss: 123.6488\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.7987 - val_loss: 110.8503\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.8848 - val_loss: 113.4333\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 4ms/step - loss: 108.0385 - val_loss: 116.0025\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.6239 - val_loss: 113.4839\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.1445 - val_loss: 118.8506\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.2747 - val_loss: 112.6886\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 109.5504 - val_loss: 111.6447\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 112.6744 - val_loss: 112.0685\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.7500 - val_loss: 112.3427\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.7241 - val_loss: 111.5289\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.1591 - val_loss: 112.1325\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.1900 - val_loss: 119.4950\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 113.3722 - val_loss: 123.0793\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 118.5447 - val_loss: 116.1439\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 114.8396 - val_loss: 112.0350\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 112.8295 - val_loss: 111.4740\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.4039 - val_loss: 114.7463\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.2000 - val_loss: 111.1362\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.2903 - val_loss: 112.1936\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.0245 - val_loss: 111.4284\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 108.8952 - val_loss: 111.0679\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.3613 - val_loss: 116.0555\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 112.8921 - val_loss: 111.2286\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.8396 - val_loss: 111.3714\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.2053 - val_loss: 113.4309\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.6642 - val_loss: 120.4020\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.2774 - val_loss: 111.2462\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.1168 - val_loss: 112.6627\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.8874 - val_loss: 119.3586\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.4094 - val_loss: 119.0641\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.2238 - val_loss: 111.3931\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.0012 - val_loss: 114.9362\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.6369 - val_loss: 110.6155\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 114.8067 - val_loss: 111.0089\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.8815 - val_loss: 112.2948\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.6938 - val_loss: 111.1054\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.2326 - val_loss: 120.0665\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.5060 - val_loss: 111.0923\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.4690 - val_loss: 113.1402\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.5092 - val_loss: 113.7860\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.0376 - val_loss: 111.5422\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.3958 - val_loss: 110.8487\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.6245 - val_loss: 110.9904\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.3353 - val_loss: 110.9780\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.1766 - val_loss: 110.9304\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.7121 - val_loss: 111.0215\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.1238 - val_loss: 117.9431\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.1594 - val_loss: 117.1042\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 112.1649 - val_loss: 123.5386\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.0682 - val_loss: 112.1501\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.1269 - val_loss: 110.8597\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.9758 - val_loss: 114.1001\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 112.7818 - val_loss: 112.0234\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.2564 - val_loss: 111.2091\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.5797 - val_loss: 112.1907\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 108.5565 - val_loss: 111.0215\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.3429 - val_loss: 110.7899\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.7350 - val_loss: 111.0383\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.9185 - val_loss: 111.5397\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.2684 - val_loss: 110.8437\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.4814 - val_loss: 111.0960\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.7130 - val_loss: 115.6917\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.1917 - val_loss: 111.3998\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.9317 - val_loss: 111.1136\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.5899 - val_loss: 117.7700\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.5491 - val_loss: 117.5194\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.1752 - val_loss: 117.2853\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.8277 - val_loss: 121.8989\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 109.2271 - val_loss: 114.9502\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.4541 - val_loss: 113.1712\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.0047 - val_loss: 111.8507\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.3370 - val_loss: 111.6614\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 111.4225 - val_loss: 112.3794\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.8909 - val_loss: 111.0588\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.2409 - val_loss: 113.7777\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 112.7715 - val_loss: 110.6271\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.2918 - val_loss: 111.8260\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.9104 - val_loss: 113.9247\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 109.6040 - val_loss: 111.5382\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.6029 - val_loss: 111.0083\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.3673 - val_loss: 111.3374\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.5876 - val_loss: 114.2313\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.0944 - val_loss: 111.1147\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.4974 - val_loss: 111.1102\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.4313 - val_loss: 113.4748\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.4579 - val_loss: 117.1860\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.5135 - val_loss: 112.7972\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.8942 - val_loss: 112.6707\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.7150 - val_loss: 111.5033\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.8024 - val_loss: 110.9895\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.3087 - val_loss: 114.1580\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.3492 - val_loss: 117.8925\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 116.1707 - val_loss: 136.6708\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 112.6198 - val_loss: 113.8923\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.6951 - val_loss: 118.5945\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.1804 - val_loss: 114.1080\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.1857 - val_loss: 115.1376\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.8187 - val_loss: 117.9585\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.8388 - val_loss: 110.9019\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.1878 - val_loss: 111.4773\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.1252 - val_loss: 111.2064\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.2238 - val_loss: 114.9972\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.6060 - val_loss: 111.3526\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.3450 - val_loss: 111.7980\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 109.3912 - val_loss: 112.7370\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.0665 - val_loss: 111.3417\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.8449 - val_loss: 114.7005\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.5890 - val_loss: 128.2344\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.7877 - val_loss: 111.8842\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.9138 - val_loss: 111.3191\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 112.3529 - val_loss: 117.2083\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 113.9730 - val_loss: 112.9007\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.3554 - val_loss: 112.2196\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 110.5772 - val_loss: 129.2524\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 112.0742 - val_loss: 115.5662\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.6584 - val_loss: 110.4655\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.8153 - val_loss: 113.4842\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 119.1005 - val_loss: 110.9303\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.4887 - val_loss: 116.2942\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.6221 - val_loss: 111.4077\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.0439 - val_loss: 111.2093\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 109.9070 - val_loss: 110.9124\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 108.7854 - val_loss: 114.0831\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.1623 - val_loss: 111.0245\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.6757 - val_loss: 110.7899\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.2666 - val_loss: 112.2866\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 112.7493 - val_loss: 116.6558\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 115.6344 - val_loss: 111.4101\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.8508 - val_loss: 113.8139\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.2161 - val_loss: 111.0928\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.0715 - val_loss: 110.8380\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.4479 - val_loss: 110.8791\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.0085 - val_loss: 112.6339\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 111.1549 - val_loss: 111.2641\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.0809 - val_loss: 110.2190\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.4175 - val_loss: 112.4593\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.6076 - val_loss: 124.3667\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.8216 - val_loss: 119.4562\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.7195 - val_loss: 120.0661\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.7440 - val_loss: 120.5067\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.0001 - val_loss: 119.6620\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 112.8029 - val_loss: 128.7952\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 109.8441 - val_loss: 111.8280\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 108.9311 - val_loss: 114.5122\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 113.3826 - val_loss: 113.2975\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.3332 - val_loss: 110.9160\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 109.1532 - val_loss: 111.0760\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.8675 - val_loss: 111.2067\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.2263 - val_loss: 110.6665\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.9350 - val_loss: 113.8203\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.8001 - val_loss: 114.6325\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.3600 - val_loss: 111.0711\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.9659 - val_loss: 114.5554\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 112.7761 - val_loss: 110.4065\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 113.5090 - val_loss: 122.2603\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.6230 - val_loss: 110.6477\n",
      "Epoch 35/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 110.2999 - val_loss: 110.6153\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.6487 - val_loss: 110.9687\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.3765 - val_loss: 111.3025\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 118.3637 - val_loss: 111.5407\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.7447 - val_loss: 111.9286\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.2288 - val_loss: 112.6910\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 115.9596 - val_loss: 111.7645\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.5977 - val_loss: 123.9956\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.7094 - val_loss: 110.5122\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.5950 - val_loss: 115.2203\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 113.5849 - val_loss: 111.1260\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.0018 - val_loss: 115.5257\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.0034 - val_loss: 111.7752\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.0609 - val_loss: 111.4387\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.7209 - val_loss: 111.1091\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.5815 - val_loss: 112.8607\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 110.9003 - val_loss: 121.4118\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 115.7090 - val_loss: 111.2884\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 122.5257 - val_loss: 112.0031\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.4171 - val_loss: 110.9719\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.5981 - val_loss: 111.1330\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.9370 - val_loss: 110.2518\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.7123 - val_loss: 110.9529\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 111.1823 - val_loss: 110.2627\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 111.8273 - val_loss: 112.7603\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.0365 - val_loss: 112.1151\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.2740 - val_loss: 111.0644\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.4936 - val_loss: 111.7454\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 114.1798 - val_loss: 109.7974\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 119.3772 - val_loss: 119.0241\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 118.9817 - val_loss: 138.5350\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 121.3268 - val_loss: 122.1776\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 112.8486 - val_loss: 123.0598\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 112.4697 - val_loss: 118.7503\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.2896 - val_loss: 111.7530\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.0258 - val_loss: 114.1729\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 108.8757 - val_loss: 110.9365\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.4286 - val_loss: 113.0407\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.0316 - val_loss: 111.7141\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.6829 - val_loss: 112.2100\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.1876 - val_loss: 116.0797\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.3485 - val_loss: 110.6184\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.0164 - val_loss: 115.3213\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.8559 - val_loss: 111.0694\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.8471 - val_loss: 112.3252\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.7142 - val_loss: 111.1481\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.3397 - val_loss: 113.6169\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 112.7212 - val_loss: 127.4565\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.0278 - val_loss: 111.5373\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 113.1432 - val_loss: 111.1076\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 113.4195 - val_loss: 110.5622\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 109.2250 - val_loss: 111.0985\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.0862 - val_loss: 111.3072\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.7112 - val_loss: 113.8042\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.5970 - val_loss: 111.0391\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 112.5501 - val_loss: 110.8644\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.4438 - val_loss: 117.3116\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 114.1822 - val_loss: 110.5161\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.0907 - val_loss: 114.8240\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.4035 - val_loss: 115.2481\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.7720 - val_loss: 116.9661\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 112.8615 - val_loss: 120.5720\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.4554 - val_loss: 112.4394\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.5652 - val_loss: 112.6652\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.5039 - val_loss: 113.2080\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.1086 - val_loss: 111.6744\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 108.1266 - val_loss: 115.6947\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.7107 - val_loss: 115.4610\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 114.2044 - val_loss: 112.2906\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 115.0766 - val_loss: 110.9204\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.3959 - val_loss: 119.3671\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.9172 - val_loss: 110.5783\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 109.2194 - val_loss: 113.3302\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.3491 - val_loss: 115.6093\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 113.6568 - val_loss: 110.8326\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.0275 - val_loss: 111.8447\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 109.9772 - val_loss: 118.6494\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.1836 - val_loss: 110.7032\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.5929 - val_loss: 115.9271\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.1174 - val_loss: 113.0082\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.6399 - val_loss: 113.2527\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.8436 - val_loss: 111.6350\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.7710 - val_loss: 111.8590\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.3198 - val_loss: 114.0211\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.2411 - val_loss: 111.1758\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.9499 - val_loss: 112.0967\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.9606 - val_loss: 110.9688\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 112.4995 - val_loss: 112.2347\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 117.6874 - val_loss: 114.1725\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 111.0660 - val_loss: 111.7235\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.3199 - val_loss: 127.5552\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.1242 - val_loss: 110.9259\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 108.4408 - val_loss: 124.2289\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.2474 - val_loss: 132.1365\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 117.2045 - val_loss: 120.5654\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 112.0574 - val_loss: 116.1462\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 113.2501 - val_loss: 111.5871\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 108.7251 - val_loss: 110.0813\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.7895 - val_loss: 125.7926\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 117.2088 - val_loss: 111.4611\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 109.4626 - val_loss: 114.4259\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 111.7944 - val_loss: 111.4044\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.8522 - val_loss: 111.0621\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 111.7539 - val_loss: 112.2878\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.1978 - val_loss: 112.6625\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.4143 - val_loss: 111.5052\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.6977 - val_loss: 115.1479\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.9534 - val_loss: 111.4945\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 111.2647 - val_loss: 114.5197\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 112.4858 - val_loss: 110.1293\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.8593 - val_loss: 110.5869\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.2290 - val_loss: 111.5286\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 109.9793 - val_loss: 113.1789\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.5499 - val_loss: 110.1883\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.0817 - val_loss: 109.9584\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.7273 - val_loss: 116.3124\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 108.6655 - val_loss: 115.6386\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 106.5263 - val_loss: 120.9451\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 115.4251 - val_loss: 110.6609\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 108.6554 - val_loss: 111.1703\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.5096 - val_loss: 119.1653\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 112.7871 - val_loss: 136.4793\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 114.4536 - val_loss: 112.6590\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 109.8014 - val_loss: 115.0818\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.7533 - val_loss: 111.6275\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.6873 - val_loss: 113.1316\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.9874 - val_loss: 110.5123\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 110.6078 - val_loss: 113.6733\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.7859 - val_loss: 110.4445\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 114.1594 - val_loss: 120.8454\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 111.2299 - val_loss: 131.8510\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 111.7631 - val_loss: 116.3789\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 113.6015 - val_loss: 112.0086\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.4902 - val_loss: 111.5180\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 111.1946 - val_loss: 122.7444\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 115.0615 - val_loss: 111.5064\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 113.3144 - val_loss: 112.9152\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.5794 - val_loss: 111.3461\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.4791 - val_loss: 111.1714\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.9047 - val_loss: 116.0539\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.0334 - val_loss: 112.9665\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.7823 - val_loss: 115.3297\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.3405 - val_loss: 127.1838\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 114.6740 - val_loss: 121.3765\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 113.6794 - val_loss: 121.4530\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 107.7602 - val_loss: 119.1501\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.7952 - val_loss: 110.4907\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.4150 - val_loss: 110.4217\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 112.5533 - val_loss: 109.9562\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 109.5770 - val_loss: 111.1041\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.3216 - val_loss: 113.2864\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.1736 - val_loss: 111.0035\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.6349 - val_loss: 117.6330\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.1717 - val_loss: 115.3083\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 115.2757 - val_loss: 125.7137\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.2469 - val_loss: 121.3798\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.5285 - val_loss: 113.9334\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.7718 - val_loss: 111.6397\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.9940 - val_loss: 111.4717\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 113.5316 - val_loss: 114.4653\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 118.8100 - val_loss: 111.0736\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.4448 - val_loss: 120.0925\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 112.5038 - val_loss: 122.0594\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.6219 - val_loss: 116.6259\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 113.1556 - val_loss: 125.5432\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 112.1148 - val_loss: 110.0639\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 109.3695 - val_loss: 111.4945\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 108.4131 - val_loss: 113.8952\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 109.1470 - val_loss: 118.7539\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 113.7885 - val_loss: 112.5656\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 126.9896 - val_loss: 111.5162\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 113.4370 - val_loss: 111.3394\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.2265 - val_loss: 111.6058\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.4103 - val_loss: 113.3846\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 117.1494 - val_loss: 111.3558\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.8130 - val_loss: 111.7113\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 110.1950 - val_loss: 113.5817\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.1791 - val_loss: 113.8660\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.5993 - val_loss: 110.5541\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.1439 - val_loss: 110.7695\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.9499 - val_loss: 110.6376\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.6256 - val_loss: 113.2320\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.7816 - val_loss: 113.5599\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.2514 - val_loss: 113.9675\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.8483 - val_loss: 112.9925\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.7615 - val_loss: 110.4326\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.9636 - val_loss: 110.3108\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 111.9351 - val_loss: 111.6731\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.4572 - val_loss: 109.9339\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 118.8388 - val_loss: 117.5339\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.1594 - val_loss: 111.7558\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.1102 - val_loss: 112.7645\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.6951 - val_loss: 110.8869\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 108.8730 - val_loss: 110.3689\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.7249 - val_loss: 111.7434\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.1672 - val_loss: 110.4845\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.6844 - val_loss: 112.1829\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 113.5319 - val_loss: 109.9713\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.4407 - val_loss: 110.0339\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 112.3978 - val_loss: 111.3594\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 112.8571 - val_loss: 117.0916\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.4679 - val_loss: 117.2610\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.4959 - val_loss: 112.0937\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.2026 - val_loss: 113.8245\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 113.5427 - val_loss: 112.0199\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.0082 - val_loss: 110.2973\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 108.2777 - val_loss: 110.8131\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 108.7532 - val_loss: 121.3648\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.9208 - val_loss: 131.9083\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 114.1533 - val_loss: 129.2493\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.7208 - val_loss: 112.8865\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.2643 - val_loss: 110.7513\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 107.6341 - val_loss: 110.2984\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.9099 - val_loss: 111.7866\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.1331 - val_loss: 110.3591\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.4544 - val_loss: 115.1860\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.4334 - val_loss: 122.1875\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 114.6886 - val_loss: 121.9577\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 112.7006 - val_loss: 117.4315\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 109.9295 - val_loss: 119.2634\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.3992 - val_loss: 115.7054\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.5314 - val_loss: 110.2281\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 113.2944 - val_loss: 115.7766\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.6889 - val_loss: 110.5590\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.6480 - val_loss: 110.9937\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.4502 - val_loss: 117.5518\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.7726 - val_loss: 111.2083\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.3254 - val_loss: 112.6034\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.6570 - val_loss: 113.0983\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.2793 - val_loss: 110.8397\n",
      "Epoch 15/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 107.8749 - val_loss: 110.6698\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.6022 - val_loss: 110.4796\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.4597 - val_loss: 110.0671\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.5992 - val_loss: 114.5110\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 114.5901 - val_loss: 114.1315\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.1544 - val_loss: 114.3767\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.8820 - val_loss: 111.8870\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.3624 - val_loss: 110.5956\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.9265 - val_loss: 112.3364\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.6797 - val_loss: 110.4738\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.2727 - val_loss: 112.0431\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.4163 - val_loss: 110.8252\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.0931 - val_loss: 116.5976\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.6896 - val_loss: 114.1010\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.0476 - val_loss: 110.9267\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.7809 - val_loss: 112.1086\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.3605 - val_loss: 118.4663\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.5745 - val_loss: 111.0806\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.4281 - val_loss: 121.1933\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 110.7969 - val_loss: 115.2491\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.9458 - val_loss: 118.9936\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 107.9275 - val_loss: 110.8768\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 108.1019 - val_loss: 113.6498\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 112.5788 - val_loss: 111.0562\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.1173 - val_loss: 111.8214\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.4566 - val_loss: 110.5919\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 107.9030 - val_loss: 110.5985\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.4828 - val_loss: 110.5797\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.8909 - val_loss: 111.7653\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.8630 - val_loss: 117.8522\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.9499 - val_loss: 110.9410\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.1645 - val_loss: 111.1959\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 113.3596 - val_loss: 115.9303\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 112.7370 - val_loss: 110.4067\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 114.9647 - val_loss: 128.1569\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 114.2701 - val_loss: 112.6686\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 109.1015 - val_loss: 118.8537\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 125.6171 - val_loss: 131.8594\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 121.2917 - val_loss: 111.5865\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 110.9318 - val_loss: 111.7486\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.3935 - val_loss: 118.1817\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 110.1341 - val_loss: 111.4893\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.6490 - val_loss: 110.9174\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.4095 - val_loss: 112.7753\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.0790 - val_loss: 113.4401\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 109.4365 - val_loss: 115.4200\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.9654 - val_loss: 110.4541\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.2762 - val_loss: 110.6602\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.5767 - val_loss: 111.2423\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 115.6237 - val_loss: 130.8101\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 119.9403 - val_loss: 113.7704\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.3813 - val_loss: 115.0387\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.5987 - val_loss: 112.3447\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 109.1085 - val_loss: 115.5247\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 113.5301 - val_loss: 125.8681\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 116.1308 - val_loss: 126.4053\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.5989 - val_loss: 110.0484\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 108.6188 - val_loss: 111.2597\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.7560 - val_loss: 111.5014\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.2116 - val_loss: 119.4778\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.3815 - val_loss: 112.9465\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.6310 - val_loss: 112.1777\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.6869 - val_loss: 117.3469\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.7356 - val_loss: 110.4134\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.3580 - val_loss: 110.8296\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 113.0482 - val_loss: 110.9126\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.5062 - val_loss: 112.3924\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.7502 - val_loss: 111.5395\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.7850 - val_loss: 120.2143\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 112.7302 - val_loss: 110.1370\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 115.9595 - val_loss: 113.0587\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 111.3913 - val_loss: 112.6043\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 108.7357 - val_loss: 112.9949\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.4938 - val_loss: 113.3169\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 115.3675 - val_loss: 110.4494\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.6095 - val_loss: 111.7345\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 112.7006 - val_loss: 112.5204\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.8867 - val_loss: 110.7091\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 109.1095 - val_loss: 110.8350\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.3722 - val_loss: 110.8260\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.2048 - val_loss: 113.9144\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.7348 - val_loss: 113.8661\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.6704 - val_loss: 117.8861\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.1435 - val_loss: 118.7317\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.5242 - val_loss: 111.6173\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.3460 - val_loss: 111.3947\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 107.7470 - val_loss: 118.9515\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.9264 - val_loss: 116.0622\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.3479 - val_loss: 117.2739\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.1192 - val_loss: 110.0505\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.5685 - val_loss: 111.2393\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.3538 - val_loss: 110.4938\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.1889 - val_loss: 112.0098\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.0261 - val_loss: 113.1589\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 107.7484 - val_loss: 111.3608\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.0118 - val_loss: 112.5824\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 107.8437 - val_loss: 111.5196\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.9470 - val_loss: 111.3123\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.1356 - val_loss: 110.7137\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.9014 - val_loss: 111.0862\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 112.6840 - val_loss: 111.7564\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.0283 - val_loss: 115.5651\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 114.4419 - val_loss: 110.8193\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.0264 - val_loss: 111.5444\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.2756 - val_loss: 127.3126\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 113.0440 - val_loss: 122.4127\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.5701 - val_loss: 112.9782\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.6786 - val_loss: 110.8688\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.0563 - val_loss: 111.1211\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 111.3336 - val_loss: 112.4319\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.4397 - val_loss: 120.1427\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.2267 - val_loss: 117.3138\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 115.3122 - val_loss: 118.7131\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 118.9001 - val_loss: 110.7016\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.3797 - val_loss: 111.0730\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.2180 - val_loss: 111.6083\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.3871 - val_loss: 114.0291\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.2944 - val_loss: 110.9759\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 110.2234 - val_loss: 122.3590\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.3465 - val_loss: 111.2287\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.2353 - val_loss: 112.4680\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.5944 - val_loss: 111.4075\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 109.4748 - val_loss: 111.5881\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 111.0436 - val_loss: 116.4393\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.7797 - val_loss: 111.6912\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.0056 - val_loss: 111.5731\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.7765 - val_loss: 111.1545\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 108.0989 - val_loss: 112.7432\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 108.0743 - val_loss: 115.8611\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 111.9602 - val_loss: 113.8732\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.9763 - val_loss: 110.5511\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.2484 - val_loss: 111.1919\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 109.1396 - val_loss: 111.8784\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.6985 - val_loss: 111.8164\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.7607 - val_loss: 114.5017\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.8978 - val_loss: 112.9368\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 109.1595 - val_loss: 113.4504\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.7221 - val_loss: 110.6284\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.4068 - val_loss: 114.5927\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.1000 - val_loss: 118.7570\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.5497 - val_loss: 111.7185\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.0170 - val_loss: 120.6073\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.8361 - val_loss: 134.2376\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 119.1427 - val_loss: 117.4638\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 116.2668 - val_loss: 111.1840\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 112.5391 - val_loss: 111.8079\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.3216 - val_loss: 112.4085\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 108.6117 - val_loss: 111.0178\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 111.1616 - val_loss: 112.3908\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 109.5861 - val_loss: 110.8666\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.0612 - val_loss: 111.2121\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.5877 - val_loss: 112.4204\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 113.0178 - val_loss: 121.4228\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 108.2025 - val_loss: 110.7869\n",
      "Epoch 19/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 4ms/step - loss: 108.5351 - val_loss: 111.3625\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.7522 - val_loss: 115.4000\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 108.4384 - val_loss: 119.3738\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.2188 - val_loss: 115.3031\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.7774 - val_loss: 111.2131\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.6940 - val_loss: 114.4279\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.4041 - val_loss: 112.6666\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.9302 - val_loss: 111.6941\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 112.7327 - val_loss: 114.1403\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 112.7756 - val_loss: 112.1825\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.1928 - val_loss: 113.4640\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.8135 - val_loss: 111.9540\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 115.7684 - val_loss: 111.2632\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.8355 - val_loss: 113.8777\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.9118 - val_loss: 117.8695\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.8676 - val_loss: 113.3102\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.9939 - val_loss: 111.6113\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.0798 - val_loss: 122.1952\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 114.1343 - val_loss: 111.7314\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.7388 - val_loss: 111.4266\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.9506 - val_loss: 111.9007\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 108.4606 - val_loss: 115.3152\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 109.9674 - val_loss: 110.7097\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 109.9308 - val_loss: 113.9295\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 113.9385 - val_loss: 112.5747\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.7249 - val_loss: 111.2266\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.2513 - val_loss: 125.6111\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.7520 - val_loss: 118.0400\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.5175 - val_loss: 117.5411\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.5942 - val_loss: 119.6026\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.5222 - val_loss: 112.2207\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.2259 - val_loss: 114.0135\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 108.1743 - val_loss: 119.4334\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 112.8559 - val_loss: 111.5538\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 110.7460 - val_loss: 116.0683\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 108.9670 - val_loss: 111.5630\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.7782 - val_loss: 111.5095\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.7836 - val_loss: 117.1591\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 108.5811 - val_loss: 111.5052\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.5422 - val_loss: 111.6399\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.8396 - val_loss: 110.9378\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.9943 - val_loss: 111.2988\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 108.3657 - val_loss: 112.4270\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.6335 - val_loss: 111.2535\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.7897 - val_loss: 115.8368\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.4754 - val_loss: 115.0267\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.3731 - val_loss: 120.2130\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.5505 - val_loss: 113.9541\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.6806 - val_loss: 124.0787\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.8644 - val_loss: 119.8196\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.9679 - val_loss: 118.6771\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.3726 - val_loss: 121.9155\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.6325 - val_loss: 123.4025\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 113.7569 - val_loss: 113.8719\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.5931 - val_loss: 111.3705\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.6269 - val_loss: 116.1034\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.5990 - val_loss: 117.0224\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.9159 - val_loss: 111.1729\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 112.0426 - val_loss: 117.7398\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.5785 - val_loss: 112.6590\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 108.5186 - val_loss: 111.8477\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.1923 - val_loss: 112.0745\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.6053 - val_loss: 118.8405\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.4319 - val_loss: 115.0730\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.3250 - val_loss: 111.7068\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.9075 - val_loss: 110.9526\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.4441 - val_loss: 118.0096\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.3257 - val_loss: 116.0325\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 113.1626 - val_loss: 111.4395\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.3831 - val_loss: 111.2642\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.9844 - val_loss: 112.8721\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 112.3378 - val_loss: 133.4135\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 113.2300 - val_loss: 112.7923\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.9217 - val_loss: 111.8964\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.5912 - val_loss: 111.5747\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 112.8862 - val_loss: 111.5029\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 114.3832 - val_loss: 112.7852\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.5687 - val_loss: 111.7053\n",
      "Epoch 47/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 110.0181 - val_loss: 110.8806\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.3833 - val_loss: 116.0017\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 114.3544 - val_loss: 122.0522\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 113.3129 - val_loss: 145.6397\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 117.0818 - val_loss: 131.1368\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.2772 - val_loss: 115.2112\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.2571 - val_loss: 111.8834\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.8994 - val_loss: 111.2468\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.3824 - val_loss: 111.8750\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.5436 - val_loss: 116.9172\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.8597 - val_loss: 113.1684\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 115.7806 - val_loss: 129.4485\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 113.3177 - val_loss: 112.7728\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.1643 - val_loss: 110.5002\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 118.3877 - val_loss: 116.8672\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.1023 - val_loss: 113.0997\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.8587 - val_loss: 113.8490\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 107.6331 - val_loss: 112.0347\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 111.1489 - val_loss: 119.4023\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 115.7625 - val_loss: 117.2050\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.4975 - val_loss: 122.1889\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.2951 - val_loss: 113.8632\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.2949 - val_loss: 113.2437\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.0583 - val_loss: 112.3830\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.7541 - val_loss: 112.4951\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 108.7891 - val_loss: 114.8641\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.9824 - val_loss: 110.9434\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.7087 - val_loss: 122.6314\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.6232 - val_loss: 120.6439\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.3823 - val_loss: 117.0366\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.1463 - val_loss: 131.0146\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 114.4577 - val_loss: 162.7401\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 118.1108 - val_loss: 122.9167\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 107.8375 - val_loss: 112.3380\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 112.8574 - val_loss: 120.1412\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 109.8059 - val_loss: 111.4829\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 106.8396 - val_loss: 137.0435\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 113.1247 - val_loss: 131.5331\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.1112 - val_loss: 112.4630\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.3729 - val_loss: 110.8897\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.9812 - val_loss: 114.2347\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 117.8543 - val_loss: 113.7173\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.2278 - val_loss: 111.1150\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.7526 - val_loss: 111.2150\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.6481 - val_loss: 111.7661\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.6861 - val_loss: 111.8703\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.8954 - val_loss: 112.0363\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 107.5057 - val_loss: 117.9769\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.4971 - val_loss: 112.5283\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 109.0993 - val_loss: 118.2349\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 114.4041 - val_loss: 123.7166\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 107.3253 - val_loss: 111.6913\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.3825 - val_loss: 112.9718\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.5183 - val_loss: 113.3563\n",
      "10/10 [==============================] - 0s 0s/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 110.2661 - val_loss: 118.4848\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 112.9331 - val_loss: 115.6248\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 108.2567 - val_loss: 113.1318\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 112.7340 - val_loss: 120.4698\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.5183 - val_loss: 112.0343\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.6375 - val_loss: 113.6522\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.9805 - val_loss: 111.4294\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.7101 - val_loss: 111.5528\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.6251 - val_loss: 113.2216\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.1418 - val_loss: 110.1532\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 110.6849 - val_loss: 111.5078\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 119.6674 - val_loss: 114.2066\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.1863 - val_loss: 117.3481\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.0334 - val_loss: 118.3051\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.0795 - val_loss: 111.9574\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 110.4367 - val_loss: 113.6634\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.7839 - val_loss: 110.9956\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 117.0497 - val_loss: 119.0610\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 115.8109 - val_loss: 130.3260\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 112.6480 - val_loss: 112.0148\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.8256 - val_loss: 116.1168\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.0777 - val_loss: 113.2428\n",
      "Epoch 23/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 4ms/step - loss: 110.0538 - val_loss: 113.5031\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.8604 - val_loss: 111.2937\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.1911 - val_loss: 112.6463\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.0907 - val_loss: 111.6401\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.7691 - val_loss: 123.1305\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.5862 - val_loss: 114.7566\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.0463 - val_loss: 114.2107\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.6524 - val_loss: 112.5154\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 108.8649 - val_loss: 116.5291\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 109.2317 - val_loss: 117.8196\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.1742 - val_loss: 111.8089\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.3383 - val_loss: 111.6108\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.6751 - val_loss: 111.2603\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 108.0489 - val_loss: 112.4712\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.0819 - val_loss: 112.1345\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.9456 - val_loss: 114.6948\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 113.1293 - val_loss: 111.6358\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.0510 - val_loss: 112.3067\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.4899 - val_loss: 114.4449\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.6038 - val_loss: 111.7758\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.3106 - val_loss: 128.0388\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.1074 - val_loss: 114.5179\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 108.8613 - val_loss: 122.7399\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 112.1750 - val_loss: 112.7876\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 115.1964 - val_loss: 111.2524\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.1254 - val_loss: 112.8872\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.6090 - val_loss: 114.6657\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.0518 - val_loss: 112.1574\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 109.8744 - val_loss: 111.2112\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.8635 - val_loss: 113.0778\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.8421 - val_loss: 113.9492\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.0318 - val_loss: 111.4636\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 110.4489 - val_loss: 110.7646\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 108.2078 - val_loss: 117.1258\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 110.1606 - val_loss: 111.2071\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.4557 - val_loss: 111.1448\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 114.0706 - val_loss: 119.6880\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 113.6427 - val_loss: 115.0810\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.2553 - val_loss: 117.3253\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.8065 - val_loss: 116.3316\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.4936 - val_loss: 116.1350\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.2131 - val_loss: 116.0015\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.1412 - val_loss: 111.7902\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.6789 - val_loss: 115.9512\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.4240 - val_loss: 116.2842\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.7534 - val_loss: 125.9175\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.2000 - val_loss: 118.7731\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 112.0830 - val_loss: 114.6475\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.8062 - val_loss: 115.4819\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 109.0692 - val_loss: 112.8000\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 108.5342 - val_loss: 113.3718\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.5698 - val_loss: 115.8125\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 112.5838 - val_loss: 116.9165\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 106.9038 - val_loss: 112.3041\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.6830 - val_loss: 112.3440\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.9646 - val_loss: 114.4392\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.4472 - val_loss: 115.2753\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.3293 - val_loss: 114.6260\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.1498 - val_loss: 121.0117\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 114.1030 - val_loss: 111.0653\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 116.5197 - val_loss: 112.9087\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.1595 - val_loss: 111.2080\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.7303 - val_loss: 111.6890\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.5290 - val_loss: 111.0592\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 113.9134 - val_loss: 111.6563\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 112.0112 - val_loss: 114.4096\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 114.4337 - val_loss: 112.0785\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.6792 - val_loss: 120.0469\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.4313 - val_loss: 111.6125\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.9987 - val_loss: 112.6315\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 115.1758 - val_loss: 116.3294\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.2251 - val_loss: 113.1345\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.1122 - val_loss: 120.1859\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.9211 - val_loss: 117.6971\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.9029 - val_loss: 117.1774\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 107.8184 - val_loss: 115.8049\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.2224 - val_loss: 112.2259\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.5804 - val_loss: 124.4219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 118.2596 - val_loss: 112.1477\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.9231 - val_loss: 112.2602\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 113.4537 - val_loss: 112.9697\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 106.9796 - val_loss: 121.4480\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.6611 - val_loss: 112.4777\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.4703 - val_loss: 112.4021\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.9246 - val_loss: 111.3206\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 118.4038 - val_loss: 112.2199\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.1381 - val_loss: 114.4814\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.0927 - val_loss: 111.5918\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.7559 - val_loss: 112.7070\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.8426 - val_loss: 112.6386\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.0462 - val_loss: 116.3311\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.2034 - val_loss: 111.2335\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 106.9646 - val_loss: 113.5733\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.1033 - val_loss: 112.3485\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.5403 - val_loss: 113.4386\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.0157 - val_loss: 110.8983\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.3635 - val_loss: 111.0912\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.2328 - val_loss: 114.9379\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.1602 - val_loss: 112.2299\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.6194 - val_loss: 120.5838\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.1833 - val_loss: 118.5606\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.4278 - val_loss: 116.4765\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 114.0973 - val_loss: 114.3529\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 114.7244 - val_loss: 112.3440\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.9381 - val_loss: 117.0798\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.2690 - val_loss: 121.6716\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.0879 - val_loss: 114.4645\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.8433 - val_loss: 118.2987\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 115.5804 - val_loss: 115.5074\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 113.0839 - val_loss: 120.0202\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 113.3996 - val_loss: 122.6609\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 114.3092 - val_loss: 112.7570\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.3391 - val_loss: 114.9686\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.4348 - val_loss: 111.9689\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.9287 - val_loss: 116.9638\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.3007 - val_loss: 110.7636\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.2637 - val_loss: 111.4713\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.2740 - val_loss: 116.0196\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 110.9334 - val_loss: 120.6096\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.9366 - val_loss: 111.3736\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.6906 - val_loss: 111.1216\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.8478 - val_loss: 113.7724\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.7601 - val_loss: 111.6880\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.2897 - val_loss: 111.9638\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 111.8614 - val_loss: 111.2560\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.2812 - val_loss: 124.4473\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.8120 - val_loss: 120.3432\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 113.0088 - val_loss: 121.2525\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 107.8469 - val_loss: 112.7988\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.2356 - val_loss: 116.6703\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.8170 - val_loss: 112.0368\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.4566 - val_loss: 111.4799\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.7620 - val_loss: 112.5182\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 109.2710 - val_loss: 111.4776\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.4240 - val_loss: 111.6281\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.2843 - val_loss: 111.8729\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 117.4301 - val_loss: 127.6326\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 114.0192 - val_loss: 119.8312\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 112.7615 - val_loss: 129.1527\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 114.0237 - val_loss: 117.6601\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.5312 - val_loss: 118.3228\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.7009 - val_loss: 111.7765\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 108.1462 - val_loss: 117.1229\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 112.8804 - val_loss: 112.0866\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.7236 - val_loss: 111.1304\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.6362 - val_loss: 110.8559\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 107.9138 - val_loss: 111.8614\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.4529 - val_loss: 113.2067\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 112.4228 - val_loss: 119.7664\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.3923 - val_loss: 112.5507\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.6162 - val_loss: 112.5307\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.2112 - val_loss: 114.3250\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 112.5731 - val_loss: 112.6621\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.9009 - val_loss: 111.5563\n",
      "Epoch 27/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 108.0477 - val_loss: 113.0083\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 112.2013 - val_loss: 112.7292\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 117.6721 - val_loss: 118.2781\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.5527 - val_loss: 115.6624\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 112.0027 - val_loss: 140.4240\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 116.0513 - val_loss: 123.6061\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.6060 - val_loss: 113.8153\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.9936 - val_loss: 121.4098\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 107.4065 - val_loss: 122.8098\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.2807 - val_loss: 131.1918\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.8828 - val_loss: 130.3373\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 110.4715 - val_loss: 114.8919\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.5625 - val_loss: 110.2600\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.0440 - val_loss: 111.6918\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.1450 - val_loss: 113.6050\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 112.8914 - val_loss: 111.4555\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 114.4848 - val_loss: 115.1933\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 114.0899 - val_loss: 113.8549\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 112.2293 - val_loss: 113.3106\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 107.9776 - val_loss: 115.0365\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.4122 - val_loss: 112.7256\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.7797 - val_loss: 111.6743\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.4896 - val_loss: 112.7407\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.5503 - val_loss: 112.6773\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 108.8733 - val_loss: 113.9285\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.6890 - val_loss: 111.9195\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 108.2075 - val_loss: 120.4355\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 108.8329 - val_loss: 116.0553\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.4662 - val_loss: 116.1480\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.5943 - val_loss: 111.4094\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.6066 - val_loss: 114.2214\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 107.9063 - val_loss: 111.0544\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.7094 - val_loss: 112.0436\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.4265 - val_loss: 111.7145\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.1546 - val_loss: 112.6904\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 109.0043 - val_loss: 112.1652\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.7914 - val_loss: 119.7042\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.7722 - val_loss: 113.1355\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.3196 - val_loss: 116.9275\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.5870 - val_loss: 117.1863\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.9883 - val_loss: 111.3238\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.9335 - val_loss: 115.2918\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 114.9570 - val_loss: 117.3199\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.4886 - val_loss: 112.0050\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.9596 - val_loss: 113.6529\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 110.8806 - val_loss: 112.1626\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 107.3533 - val_loss: 110.6454\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 111.5444 - val_loss: 111.7774\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.3522 - val_loss: 116.4137\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.6019 - val_loss: 113.3981\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.3332 - val_loss: 111.4979\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 112.3598 - val_loss: 114.4891\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.4782 - val_loss: 111.6516\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.6164 - val_loss: 117.1050\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 110.4690 - val_loss: 114.6856\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.0614 - val_loss: 111.9791\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.7254 - val_loss: 111.8310\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.5708 - val_loss: 113.6597\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 109.6676 - val_loss: 113.5949\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.9873 - val_loss: 114.4432\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.0991 - val_loss: 111.1737\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.9544 - val_loss: 115.0200\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.7254 - val_loss: 110.1633\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.5032 - val_loss: 111.8746\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.5894 - val_loss: 111.1628\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 108.7525 - val_loss: 111.0363\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 107.8194 - val_loss: 135.0603\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 118.7538 - val_loss: 143.5851\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.7572 - val_loss: 125.2961\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 112.4584 - val_loss: 147.2131\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 118.4074 - val_loss: 139.9314\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 115.1198 - val_loss: 135.9992\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 115.8192 - val_loss: 123.6231\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.6707 - val_loss: 115.2131\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 108.6175 - val_loss: 125.3708\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 109.6846 - val_loss: 113.6936\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 4ms/step - loss: 109.3326 - val_loss: 125.3364\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 109.7771 - val_loss: 113.5288\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.9344 - val_loss: 116.0943\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.6753 - val_loss: 111.8669\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 107.6908 - val_loss: 112.7400\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.2238 - val_loss: 113.1857\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.9064 - val_loss: 111.7455\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 113.4818 - val_loss: 118.2599\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.4295 - val_loss: 118.8781\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.5003 - val_loss: 112.6820\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.8652 - val_loss: 110.9161\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.7480 - val_loss: 112.5297\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.4016 - val_loss: 112.6134\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.8066 - val_loss: 113.6610\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.7895 - val_loss: 112.3444\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.4448 - val_loss: 112.2097\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.1844 - val_loss: 118.4805\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 114.4190 - val_loss: 132.1921\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 115.7647 - val_loss: 125.9889\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 117.8405 - val_loss: 116.0651\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.7882 - val_loss: 110.4419\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 107.8795 - val_loss: 111.2438\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 112.6100 - val_loss: 112.3202\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.8545 - val_loss: 112.0632\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.1347 - val_loss: 112.3641\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 107.6819 - val_loss: 111.9548\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 108.0257 - val_loss: 112.8749\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.6963 - val_loss: 112.3064\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.5091 - val_loss: 114.5726\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.8234 - val_loss: 118.5340\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.2412 - val_loss: 113.3760\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.8820 - val_loss: 112.1753\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 107.6200 - val_loss: 111.3234\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.4093 - val_loss: 112.2207\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.2436 - val_loss: 111.7296\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 108.4675 - val_loss: 114.7122\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.1021 - val_loss: 117.3679\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.8695 - val_loss: 112.5773\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.5779 - val_loss: 116.6918\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 106.3450 - val_loss: 112.1834\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 108.6627 - val_loss: 111.8353\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 108.9649 - val_loss: 113.0731\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.3912 - val_loss: 119.2239\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.1325 - val_loss: 116.3197\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 112.1947 - val_loss: 112.1945\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.4681 - val_loss: 114.5189\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.0883 - val_loss: 112.6535\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 107.6044 - val_loss: 111.8865\n",
      "10/10 [==============================] - 0s 453us/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 110.2842 - val_loss: 111.9688\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 109.6373 - val_loss: 112.3354\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.4452 - val_loss: 115.1103\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.4765 - val_loss: 112.3226\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.3786 - val_loss: 111.5326\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.6059 - val_loss: 111.4757\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.3301 - val_loss: 112.8026\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 112.7862 - val_loss: 111.3362\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.6652 - val_loss: 112.4489\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 114.8302 - val_loss: 113.3452\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.4400 - val_loss: 128.3828\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 112.7957 - val_loss: 124.6475\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.5970 - val_loss: 126.4211\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.0740 - val_loss: 113.0148\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 115.0419 - val_loss: 124.2341\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 117.6788 - val_loss: 120.2331\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 118.4705 - val_loss: 111.2943\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 115.8115 - val_loss: 117.1523\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.4270 - val_loss: 115.1944\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.4491 - val_loss: 120.0338\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.3332 - val_loss: 110.7772\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 111.4946 - val_loss: 113.1586\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 113.7451 - val_loss: 117.3324\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 109.3716 - val_loss: 114.2087\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.3050 - val_loss: 111.4368\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 113.6947 - val_loss: 113.3500\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.2917 - val_loss: 111.1835\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.6050 - val_loss: 113.6515\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 113.0629 - val_loss: 116.4274\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 107.6253 - val_loss: 111.2361\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 109.4100 - val_loss: 113.4048\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.1170 - val_loss: 111.3987\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.8750 - val_loss: 111.4037\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 109.6064 - val_loss: 112.9453\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 107.8733 - val_loss: 112.2327\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 108.9242 - val_loss: 112.2135\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.9719 - val_loss: 111.9646\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.1096 - val_loss: 112.0264\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.1019 - val_loss: 119.7740\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.8853 - val_loss: 113.3376\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.9945 - val_loss: 113.4169\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.8011 - val_loss: 112.8268\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.4622 - val_loss: 121.6852\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.6145 - val_loss: 112.6147\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.5987 - val_loss: 130.4055\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 115.8850 - val_loss: 131.4889\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 119.5563 - val_loss: 114.3945\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.4333 - val_loss: 115.6269\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.9566 - val_loss: 111.0532\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 115.6432 - val_loss: 112.4050\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 111.0014 - val_loss: 112.4742\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 115.0834 - val_loss: 116.1246\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.6742 - val_loss: 127.6979\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.1319 - val_loss: 127.4019\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.2521 - val_loss: 125.4401\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 114.6831 - val_loss: 128.6200\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.8924 - val_loss: 114.8088\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.4263 - val_loss: 111.4539\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.2653 - val_loss: 114.6272\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.4824 - val_loss: 112.0500\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 108.6028 - val_loss: 112.3096\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.9656 - val_loss: 117.7574\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.7689 - val_loss: 112.0319\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.8837 - val_loss: 112.8214\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.5062 - val_loss: 112.0096\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.1016 - val_loss: 111.6577\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.7406 - val_loss: 116.4517\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 112.5080 - val_loss: 110.2821\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 112.6732 - val_loss: 113.8136\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.7588 - val_loss: 115.0741\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 112.7602 - val_loss: 112.3300\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.6159 - val_loss: 114.1990\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.6073 - val_loss: 115.8096\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 116.3012 - val_loss: 123.6390\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.8365 - val_loss: 111.8974\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.3391 - val_loss: 110.8139\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.9911 - val_loss: 112.9495\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.1949 - val_loss: 116.0563\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 109.9789 - val_loss: 111.5317\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 108.1657 - val_loss: 114.0145\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 113.9932 - val_loss: 115.9555\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.5807 - val_loss: 112.4928\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.9992 - val_loss: 113.5780\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.9619 - val_loss: 113.2165\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.6051 - val_loss: 113.7469\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.5481 - val_loss: 112.1334\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.9208 - val_loss: 118.4907\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.3992 - val_loss: 120.3144\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.8262 - val_loss: 121.6199\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 107.0715 - val_loss: 116.9505\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.0395 - val_loss: 113.5573\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.2246 - val_loss: 118.0222\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.6658 - val_loss: 113.5136\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.2239 - val_loss: 111.9366\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.9144 - val_loss: 125.8234\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.8350 - val_loss: 123.9478\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 115.9940 - val_loss: 139.8420\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 117.8732 - val_loss: 121.9240\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.4134 - val_loss: 116.0035\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.3382 - val_loss: 117.6298\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 108.8520 - val_loss: 118.7324\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.2638 - val_loss: 110.8879\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.8860 - val_loss: 112.5118\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.1929 - val_loss: 116.9183\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.9019 - val_loss: 113.1917\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.4948 - val_loss: 111.3745\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 4ms/step - loss: 108.7297 - val_loss: 116.0765\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.3985 - val_loss: 116.0883\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.0574 - val_loss: 111.8854\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.3209 - val_loss: 112.1558\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 108.1676 - val_loss: 112.8515\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.3936 - val_loss: 111.9447\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 109.5223 - val_loss: 110.6076\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.9925 - val_loss: 111.2532\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.4969 - val_loss: 113.0830\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.4207 - val_loss: 112.4840\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.3620 - val_loss: 112.5786\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 114.6554 - val_loss: 116.1748\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.3936 - val_loss: 113.8701\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 108.1969 - val_loss: 116.4547\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 108.2775 - val_loss: 112.6796\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.8786 - val_loss: 113.5733\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.0572 - val_loss: 117.0186\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 116.4270 - val_loss: 110.9360\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 114.7516 - val_loss: 112.0211\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.2604 - val_loss: 126.5684\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 113.1009 - val_loss: 126.3166\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 109.8382 - val_loss: 111.2714\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.6984 - val_loss: 111.1954\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.7033 - val_loss: 113.0718\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.7770 - val_loss: 112.1776\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.3433 - val_loss: 111.1935\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.9200 - val_loss: 111.8255\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.1266 - val_loss: 120.1703\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 110.6862 - val_loss: 113.2533\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.8270 - val_loss: 111.9553\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.7474 - val_loss: 117.9698\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.0911 - val_loss: 112.7943\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.7520 - val_loss: 114.5952\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.4427 - val_loss: 111.7485\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 112.3641 - val_loss: 112.8004\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.9549 - val_loss: 114.8534\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.2969 - val_loss: 112.4057\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.1862 - val_loss: 119.8479\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.1448 - val_loss: 126.3089\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 112.9492 - val_loss: 123.1760\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 113.2182 - val_loss: 130.9946\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.4403 - val_loss: 112.4909\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.1122 - val_loss: 111.8077\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.4539 - val_loss: 112.2995\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 108.0175 - val_loss: 115.6340\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.4258 - val_loss: 111.6929\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.7129 - val_loss: 112.2652\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.7136 - val_loss: 112.0700\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.3816 - val_loss: 113.9791\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 110.2455 - val_loss: 112.1073\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 114.0102 - val_loss: 113.4014\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 113.0921 - val_loss: 111.0086\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.3997 - val_loss: 110.9752\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.5048 - val_loss: 113.0405\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.7254 - val_loss: 115.3205\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.1782 - val_loss: 111.8920\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.2259 - val_loss: 116.1600\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.3650 - val_loss: 111.8232\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.0695 - val_loss: 111.9044\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.5745 - val_loss: 112.9827\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.1550 - val_loss: 111.7236\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.8749 - val_loss: 111.1282\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.2602 - val_loss: 112.3119\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.5731 - val_loss: 112.2882\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.3012 - val_loss: 111.2904\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.1026 - val_loss: 118.7151\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.0435 - val_loss: 111.3708\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.0256 - val_loss: 112.3666\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 108.1434 - val_loss: 112.8459\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.7628 - val_loss: 115.7221\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.8535 - val_loss: 111.3198\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.7709 - val_loss: 116.7383\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.7402 - val_loss: 116.3646\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.4801 - val_loss: 126.3083\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.0522 - val_loss: 122.7975\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.2810 - val_loss: 110.8052\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.9740 - val_loss: 112.6397\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.5355 - val_loss: 119.1628\n",
      "Epoch 35/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 107.8495 - val_loss: 111.8716\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.0539 - val_loss: 112.1478\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 108.0890 - val_loss: 113.5388\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.3750 - val_loss: 119.7008\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.5135 - val_loss: 121.1635\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 114.8914 - val_loss: 119.6009\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.1544 - val_loss: 113.2302\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.7541 - val_loss: 120.6590\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.1193 - val_loss: 136.1522\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 120.0086 - val_loss: 120.1735\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.2244 - val_loss: 113.0347\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.6967 - val_loss: 112.4389\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 110.2079 - val_loss: 117.6701\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.6407 - val_loss: 124.2091\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 115.0875 - val_loss: 112.4113\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 106.8891 - val_loss: 116.1224\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 109.3101 - val_loss: 113.2373\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.0364 - val_loss: 112.4829\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.8845 - val_loss: 118.1427\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.9977 - val_loss: 111.4827\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 108.0369 - val_loss: 114.4037\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.9226 - val_loss: 111.6607\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.6729 - val_loss: 116.8959\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 111.5596 - val_loss: 117.3189\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 115.2362 - val_loss: 113.3931\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.3978 - val_loss: 115.4878\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.2435 - val_loss: 113.0978\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.9625 - val_loss: 111.7713\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.4220 - val_loss: 116.1919\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.2202 - val_loss: 114.3437\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.7942 - val_loss: 112.8894\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.0445 - val_loss: 116.5277\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.4623 - val_loss: 111.1065\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 111.7863 - val_loss: 111.9091\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.0553 - val_loss: 117.7905\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 112.9460 - val_loss: 112.2696\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.6698 - val_loss: 120.2477\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.4523 - val_loss: 122.5337\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.3860 - val_loss: 112.3075\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.3390 - val_loss: 111.0131\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.8903 - val_loss: 111.6749\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.5784 - val_loss: 127.8292\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 112.2754 - val_loss: 119.7860\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.7038 - val_loss: 120.7386\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 115.1470 - val_loss: 112.2487\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.7409 - val_loss: 114.5953\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.2533 - val_loss: 118.7938\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.9231 - val_loss: 112.6891\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.3214 - val_loss: 116.3968\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 120.0180 - val_loss: 118.3976\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 115.6929 - val_loss: 112.0897\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 113.2156 - val_loss: 111.4230\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 110.9624 - val_loss: 119.1435\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 113.9376 - val_loss: 114.9499\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.1698 - val_loss: 114.3256\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.0280 - val_loss: 125.1183\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.0622 - val_loss: 112.6316\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 109.0588 - val_loss: 121.7009\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 117.5129 - val_loss: 128.5716\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.1760 - val_loss: 112.9467\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 107.7078 - val_loss: 118.1781\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.5323 - val_loss: 117.0651\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.1147 - val_loss: 113.8357\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 112.0556 - val_loss: 118.0102\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.8576 - val_loss: 115.1900\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.0003 - val_loss: 115.0323\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 109.4248 - val_loss: 113.1645\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.7712 - val_loss: 111.6860\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 107.2316 - val_loss: 112.1174\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 108.7892 - val_loss: 111.5511\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.9354 - val_loss: 111.7967\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.1661 - val_loss: 112.5057\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 113.0872 - val_loss: 112.7521\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.6140 - val_loss: 113.2815\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.6749 - val_loss: 112.3264\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.6402 - val_loss: 114.7008\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 111.2867 - val_loss: 114.1434\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 112.6116 - val_loss: 114.6888\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.2499 - val_loss: 111.2961\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.9420 - val_loss: 113.2275\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.0863 - val_loss: 113.2458\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.4858 - val_loss: 110.8721\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.9919 - val_loss: 117.0329\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 112.1645 - val_loss: 112.2636\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.1247 - val_loss: 116.5715\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.5646 - val_loss: 115.5425\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.0625 - val_loss: 124.2548\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 119.2959 - val_loss: 116.5918\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.7309 - val_loss: 111.8589\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.8214 - val_loss: 123.0658\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.2617 - val_loss: 111.7966\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.9475 - val_loss: 113.2965\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 108.7991 - val_loss: 111.2930\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.9716 - val_loss: 111.6455\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 108.2989 - val_loss: 112.0598\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 108.3351 - val_loss: 111.6904\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.9174 - val_loss: 119.4895\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.8200 - val_loss: 113.0663\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.8275 - val_loss: 113.7562\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 108.1448 - val_loss: 112.0065\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.7902 - val_loss: 111.5940\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.6483 - val_loss: 111.2254\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 118.9559 - val_loss: 114.8549\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 112.4948 - val_loss: 113.4658\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.5400 - val_loss: 118.5006\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 107.4404 - val_loss: 112.2683\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.9677 - val_loss: 113.2968\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.8223 - val_loss: 116.7465\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.3612 - val_loss: 111.7471\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.5694 - val_loss: 115.4666\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.2378 - val_loss: 117.2525\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.7277 - val_loss: 111.8119\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.0501 - val_loss: 111.3373\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.7082 - val_loss: 117.4591\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.2013 - val_loss: 117.7955\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.0076 - val_loss: 117.2913\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 109.4966 - val_loss: 111.6056\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.5515 - val_loss: 114.5958\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.5976 - val_loss: 111.5180\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.2509 - val_loss: 112.2045\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.4571 - val_loss: 111.2323\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.3152 - val_loss: 116.1478\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 107.6891 - val_loss: 111.4876\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 109.7682 - val_loss: 118.9392\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.6391 - val_loss: 111.6515\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 109.7376 - val_loss: 112.4511\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 108.9355 - val_loss: 110.9824\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 116.3382 - val_loss: 115.6102\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 113.7359 - val_loss: 111.6401\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.4776 - val_loss: 120.5700\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.7906 - val_loss: 121.7307\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 113.2074 - val_loss: 121.9555\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.8928 - val_loss: 111.6974\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.3135 - val_loss: 111.5055\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 115.8768 - val_loss: 112.1309\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.0223 - val_loss: 124.3868\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.7403 - val_loss: 114.9400\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.7854 - val_loss: 112.2326\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.6399 - val_loss: 113.7964\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 108.6477 - val_loss: 112.1119\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.5545 - val_loss: 114.2995\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.8479 - val_loss: 112.1782\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 108.7523 - val_loss: 124.6048\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 107.5850 - val_loss: 112.8576\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.2864 - val_loss: 113.5032\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.8864 - val_loss: 115.9233\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 111.0671 - val_loss: 111.5754\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 108.2024 - val_loss: 114.8183\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.2528 - val_loss: 118.5830\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 118.4808 - val_loss: 114.2862\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.8537 - val_loss: 113.6792\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.2930 - val_loss: 120.6367\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 108.8223 - val_loss: 113.3038\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.3487 - val_loss: 112.1731\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 109.8227 - val_loss: 113.4101\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.6314 - val_loss: 124.1261\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.4226 - val_loss: 111.8096\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.4120 - val_loss: 113.3354\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.6420 - val_loss: 113.9046\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.7281 - val_loss: 111.9532\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.0123 - val_loss: 111.9530\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 109.7962 - val_loss: 114.2178\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 109.4549 - val_loss: 119.5006\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 114.1068 - val_loss: 116.6231\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.8164 - val_loss: 118.6274\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 112.0499 - val_loss: 114.6293\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 116.8387 - val_loss: 110.7305\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 108.7920 - val_loss: 110.9779\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.1960 - val_loss: 114.8321\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.4393 - val_loss: 113.1323\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.6092 - val_loss: 114.9048\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 110.6656 - val_loss: 120.7500\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 117.2456 - val_loss: 136.0256\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 112.3320 - val_loss: 131.2426\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 114.3067 - val_loss: 130.5780\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 113.8802 - val_loss: 120.3844\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.4352 - val_loss: 111.2677\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.0335 - val_loss: 111.3613\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.0615 - val_loss: 120.9589\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 113.3688 - val_loss: 113.1164\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 109.9258 - val_loss: 110.9843\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.6329 - val_loss: 110.7172\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 107.9439 - val_loss: 113.9144\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 107.2389 - val_loss: 118.3795\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 110.9425 - val_loss: 113.8276\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 114.4969 - val_loss: 130.4048\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 124.5597 - val_loss: 114.0035\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.5221 - val_loss: 118.8830\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 112.9754 - val_loss: 113.5804\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 115.7764 - val_loss: 112.8148\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.5730 - val_loss: 111.1599\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.8577 - val_loss: 111.4894\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.4364 - val_loss: 112.0506\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.0210 - val_loss: 112.5048\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.4620 - val_loss: 114.8136\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.8784 - val_loss: 112.2693\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.9713 - val_loss: 112.1637\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 112.7187 - val_loss: 111.8273\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.2650 - val_loss: 111.6005\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.3490 - val_loss: 111.8538\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 109.7897 - val_loss: 112.0352\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.3665 - val_loss: 115.5219\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 109.8888 - val_loss: 114.4587\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 116.0478 - val_loss: 115.2734\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 109.1994 - val_loss: 113.4174\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.8092 - val_loss: 112.8302\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.6916 - val_loss: 114.1808\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.3711 - val_loss: 114.0004\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.7116 - val_loss: 113.0196\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.0650 - val_loss: 112.1164\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.1992 - val_loss: 111.1577\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 114.5380 - val_loss: 113.0742\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.6879 - val_loss: 112.1642\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.7271 - val_loss: 111.9380\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 112.6556 - val_loss: 112.3078\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.1450 - val_loss: 114.6921\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 109.2186 - val_loss: 116.6957\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.4903 - val_loss: 118.8809\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.6851 - val_loss: 120.1624\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.6689 - val_loss: 114.3685\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 107.9284 - val_loss: 110.9298\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.6747 - val_loss: 111.3628\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 113.3697 - val_loss: 112.2779\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.8181 - val_loss: 113.7873\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.3718 - val_loss: 112.8838\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.7129 - val_loss: 135.1155\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.6473 - val_loss: 111.3718\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.5819 - val_loss: 112.5362\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.9239 - val_loss: 112.8428\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.1011 - val_loss: 110.8594\n",
      "Epoch 15/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 4ms/step - loss: 108.6924 - val_loss: 112.2213\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.0116 - val_loss: 112.2212\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.5779 - val_loss: 112.0576\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.9255 - val_loss: 117.1806\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.7317 - val_loss: 110.7002\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.5224 - val_loss: 111.8178\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.0496 - val_loss: 111.7054\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 107.8860 - val_loss: 112.6251\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.2292 - val_loss: 112.2805\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.7390 - val_loss: 114.5587\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.1624 - val_loss: 112.5363\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.5221 - val_loss: 116.5500\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 111.1470 - val_loss: 113.2516\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.2638 - val_loss: 112.0222\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 113.0035 - val_loss: 111.8274\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.1789 - val_loss: 115.3500\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.5422 - val_loss: 118.7095\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 110.5585 - val_loss: 111.8222\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 108.0540 - val_loss: 112.7728\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 113.8716 - val_loss: 119.1958\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.7488 - val_loss: 114.9204\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.9779 - val_loss: 113.9423\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.6138 - val_loss: 114.4395\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.9177 - val_loss: 111.7730\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.1350 - val_loss: 123.7454\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 109.4060 - val_loss: 112.2817\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.4969 - val_loss: 116.6355\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 112.9454 - val_loss: 117.4044\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.8139 - val_loss: 114.7722\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.2880 - val_loss: 117.0953\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.1954 - val_loss: 114.3125\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 112.3922 - val_loss: 112.7460\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 110.4798 - val_loss: 112.2115\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.3984 - val_loss: 114.4957\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 115.3541 - val_loss: 113.8806\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 111.1675 - val_loss: 116.0135\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 111.3942 - val_loss: 111.5167\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.8817 - val_loss: 117.8753\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.9654 - val_loss: 111.2423\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.0993 - val_loss: 116.7533\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 112.0134 - val_loss: 112.6881\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 110.8708 - val_loss: 113.1687\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 109.5202 - val_loss: 123.6422\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 106.3210 - val_loss: 114.3108\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 115.8116 - val_loss: 118.4539\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 115.0687 - val_loss: 117.2489\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 112.9942 - val_loss: 112.7413\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.9053 - val_loss: 115.4122\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.3194 - val_loss: 110.5019\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.0451 - val_loss: 116.0607\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.8351 - val_loss: 116.0922\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.7700 - val_loss: 117.6060\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.6717 - val_loss: 122.8057\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.1079 - val_loss: 113.3283\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.6457 - val_loss: 116.1339\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.2588 - val_loss: 115.9496\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.7893 - val_loss: 112.5938\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.7383 - val_loss: 114.6151\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.9588 - val_loss: 112.6202\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.5843 - val_loss: 114.3814\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.5792 - val_loss: 113.5008\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.5113 - val_loss: 111.7985\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.6614 - val_loss: 111.7587\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 109.5992 - val_loss: 114.5835\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.6031 - val_loss: 111.6627\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.7299 - val_loss: 114.8465\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.7310 - val_loss: 112.2059\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.0848 - val_loss: 112.6556\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.4023 - val_loss: 115.8503\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 109.1774 - val_loss: 113.3219\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.3529 - val_loss: 116.0195\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.3871 - val_loss: 115.2009\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 112.4432 - val_loss: 110.3639\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 108.2627 - val_loss: 114.7446\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 109.2851 - val_loss: 114.7966\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 109.6607 - val_loss: 116.3483\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 110.0289 - val_loss: 113.3662\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 107.4868 - val_loss: 112.4997\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 4ms/step - loss: 107.5523 - val_loss: 111.7298\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.1117 - val_loss: 113.4300\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.2966 - val_loss: 111.1255\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 112.7376 - val_loss: 111.2303\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 107.6795 - val_loss: 112.8178\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.1589 - val_loss: 119.8206\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 111.2742 - val_loss: 112.2566\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.3374 - val_loss: 117.0669\n",
      "10/10 [==============================] - 0s 501us/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 109.8589 - val_loss: 117.9336\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.3672 - val_loss: 119.4852\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 108.6331 - val_loss: 116.3319\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.2205 - val_loss: 116.2114\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.9447 - val_loss: 119.8834\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 111.2063 - val_loss: 119.1732\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.4065 - val_loss: 112.3691\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 111.6553 - val_loss: 112.6563\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 108.6385 - val_loss: 112.1039\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 107.8704 - val_loss: 112.3022\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.3033 - val_loss: 112.1803\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.1561 - val_loss: 114.0369\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.8135 - val_loss: 112.7763\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.1254 - val_loss: 117.3729\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 109.8195 - val_loss: 119.6211\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 108.3724 - val_loss: 111.6260\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 112.1891 - val_loss: 113.9416\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.9072 - val_loss: 111.3737\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.9971 - val_loss: 119.4208\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.8460 - val_loss: 124.7842\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.0630 - val_loss: 112.6709\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.4816 - val_loss: 112.3325\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 114.5000 - val_loss: 115.4860\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 112.4422 - val_loss: 113.7358\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.9086 - val_loss: 112.9138\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.0168 - val_loss: 117.3780\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 109.1987 - val_loss: 117.0433\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.7223 - val_loss: 117.5348\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.7964 - val_loss: 110.5829\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 109.2737 - val_loss: 111.5203\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.5847 - val_loss: 111.9478\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.1039 - val_loss: 113.7029\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.4815 - val_loss: 112.1869\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.1882 - val_loss: 114.5445\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.2142 - val_loss: 113.1145\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 109.5861 - val_loss: 112.5347\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.5397 - val_loss: 112.0444\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.8811 - val_loss: 131.2223\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 120.4165 - val_loss: 128.0780\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.5165 - val_loss: 116.2963\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.1860 - val_loss: 113.3034\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 110.4841 - val_loss: 111.5026\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.0123 - val_loss: 115.0817\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.6353 - val_loss: 115.4519\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 110.0240 - val_loss: 111.5700\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 113.5202 - val_loss: 111.4094\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.0513 - val_loss: 111.9868\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.7358 - val_loss: 119.5299\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.9733 - val_loss: 118.6410\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.8133 - val_loss: 111.8836\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 110.6653 - val_loss: 111.5945\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 114.5210 - val_loss: 113.1269\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 115.8099 - val_loss: 121.6242\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 129.6034 - val_loss: 143.5767\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 132.5230 - val_loss: 136.1568\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 118.9586 - val_loss: 127.8609\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.0875 - val_loss: 113.0386\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.0477 - val_loss: 127.3181\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 113.8585 - val_loss: 134.7200\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.2418 - val_loss: 126.9798\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.1158 - val_loss: 127.3150\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.0975 - val_loss: 112.2686\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.5412 - val_loss: 122.8867\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.1982 - val_loss: 114.0195\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 115.0265 - val_loss: 123.7796\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.1403 - val_loss: 112.6814\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.1135 - val_loss: 116.8298\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.0595 - val_loss: 124.1703\n",
      "Epoch 19/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 4ms/step - loss: 108.1809 - val_loss: 119.5945\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.3693 - val_loss: 112.9781\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.5230 - val_loss: 118.3792\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.9581 - val_loss: 114.5571\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.4721 - val_loss: 111.9388\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.9163 - val_loss: 113.7579\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.3270 - val_loss: 113.1817\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 108.5635 - val_loss: 111.1158\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.3138 - val_loss: 111.7903\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 113.1938 - val_loss: 110.6224\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.6106 - val_loss: 110.8001\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.2492 - val_loss: 116.3590\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.5371 - val_loss: 115.3827\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.2958 - val_loss: 125.6405\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.9338 - val_loss: 126.2097\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.4238 - val_loss: 116.6118\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.4248 - val_loss: 111.0392\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.8415 - val_loss: 114.7778\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.4925 - val_loss: 111.7072\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.7019 - val_loss: 120.9159\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.9067 - val_loss: 114.4644\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.0052 - val_loss: 117.5575\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.7060 - val_loss: 117.5748\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.2903 - val_loss: 111.6321\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 110.4495 - val_loss: 114.4314\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.1385 - val_loss: 112.4297\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.6710 - val_loss: 111.3673\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.1306 - val_loss: 115.3300\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.5533 - val_loss: 115.0888\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 112.2068 - val_loss: 114.0887\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.3796 - val_loss: 112.4212\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 112.7952 - val_loss: 112.4989\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 108.5702 - val_loss: 116.3200\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 107.0388 - val_loss: 112.3626\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.8715 - val_loss: 118.4665\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 113.4399 - val_loss: 111.7423\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.0760 - val_loss: 110.2036\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.6716 - val_loss: 110.6616\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.4413 - val_loss: 113.6609\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.8829 - val_loss: 131.7056\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.2622 - val_loss: 111.8093\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.0988 - val_loss: 117.3397\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.8196 - val_loss: 113.3719\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.0527 - val_loss: 111.9430\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 108.3488 - val_loss: 112.3403\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.9180 - val_loss: 113.3004\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 108.7851 - val_loss: 111.7932\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.2049 - val_loss: 112.7397\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.2494 - val_loss: 118.8847\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 106.7664 - val_loss: 111.6025\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.7505 - val_loss: 111.8958\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.3632 - val_loss: 112.7402\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.2367 - val_loss: 117.7329\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 114.5990 - val_loss: 112.7458\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.4765 - val_loss: 114.2041\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.9341 - val_loss: 112.4559\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 108.0734 - val_loss: 124.5852\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 112.8221 - val_loss: 145.0077\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.1194 - val_loss: 111.4856\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 108.2176 - val_loss: 113.2406\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.4897 - val_loss: 115.1997\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.8542 - val_loss: 130.6100\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.1749 - val_loss: 119.6476\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.3533 - val_loss: 123.2979\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 113.8491 - val_loss: 125.8267\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 115.7578 - val_loss: 121.2396\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.8823 - val_loss: 125.3566\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 108.2823 - val_loss: 111.6616\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 112.6690 - val_loss: 118.2829\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.2898 - val_loss: 112.0525\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.9852 - val_loss: 112.0372\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.2613 - val_loss: 113.7279\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.7626 - val_loss: 117.0407\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.5833 - val_loss: 122.3708\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.5678 - val_loss: 116.5211\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.9653 - val_loss: 112.6344\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.0224 - val_loss: 115.2250\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 111.8678 - val_loss: 112.7298\n",
      "Epoch 47/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 107.6159 - val_loss: 111.3103\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.8730 - val_loss: 112.9482\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.2141 - val_loss: 113.2487\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 108.6031 - val_loss: 111.4651\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 108.0337 - val_loss: 111.3592\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.1755 - val_loss: 112.5995\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 112.4512 - val_loss: 111.8944\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.7377 - val_loss: 112.2600\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.3969 - val_loss: 112.6329\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.5691 - val_loss: 113.3551\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.8425 - val_loss: 111.9382\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.1770 - val_loss: 117.5457\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.7267 - val_loss: 122.9776\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 112.1620 - val_loss: 124.7509\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.2097 - val_loss: 127.0706\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 113.0016 - val_loss: 113.5275\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.3261 - val_loss: 122.0142\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.5340 - val_loss: 113.0769\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.2955 - val_loss: 114.0136\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.8855 - val_loss: 110.6617\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.5551 - val_loss: 113.3840\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.9041 - val_loss: 112.4718\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 112.3987 - val_loss: 114.5778\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.8731 - val_loss: 123.5174\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 114.4057 - val_loss: 112.3574\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.6132 - val_loss: 120.5788\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.6852 - val_loss: 113.9132\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.9000 - val_loss: 113.3307\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.0118 - val_loss: 112.4895\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.9308 - val_loss: 111.6241\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.4023 - val_loss: 121.8585\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 112.3949 - val_loss: 122.1675\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.0903 - val_loss: 117.1491\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 112.9438 - val_loss: 112.0950\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.3610 - val_loss: 112.3834\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 112.8247 - val_loss: 110.9397\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 112.0401 - val_loss: 123.7142\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 110.2085 - val_loss: 135.4003\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 113.1522 - val_loss: 114.5372\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.3798 - val_loss: 113.8105\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.7099 - val_loss: 115.6264\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.7834 - val_loss: 111.4042\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.9151 - val_loss: 113.8616\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.2003 - val_loss: 112.4638\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.9698 - val_loss: 112.7524\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.8727 - val_loss: 129.2514\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.1552 - val_loss: 115.2092\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 117.6029 - val_loss: 112.3345\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 114.1036 - val_loss: 112.1624\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.4600 - val_loss: 112.3891\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.8265 - val_loss: 116.0090\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.5987 - val_loss: 116.5487\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 109.8448 - val_loss: 116.1479\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.1681 - val_loss: 125.2683\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 109.4464 - val_loss: 112.2619\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 112.2382 - val_loss: 124.7459\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 114.3276 - val_loss: 113.4791\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 118.7857 - val_loss: 112.0412\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.7900 - val_loss: 113.6105\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 110.1657 - val_loss: 110.7616\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 112.4821 - val_loss: 111.3763\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.9238 - val_loss: 111.9925\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 107.4468 - val_loss: 124.7293\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.7345 - val_loss: 113.0484\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.6205 - val_loss: 117.9305\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.6611 - val_loss: 124.6415\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 110.3543 - val_loss: 114.6025\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.8346 - val_loss: 111.5964\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 110.4195 - val_loss: 117.3683\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 112.2732 - val_loss: 114.2476\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.4350 - val_loss: 115.9830\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.6901 - val_loss: 113.2061\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.5086 - val_loss: 125.9181\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.6804 - val_loss: 122.4558\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.2311 - val_loss: 115.1044\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.8642 - val_loss: 114.2526\n",
      "Epoch 23/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 107.6870 - val_loss: 114.8380\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.6753 - val_loss: 112.2651\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.6029 - val_loss: 111.7857\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.5248 - val_loss: 111.9299\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.3869 - val_loss: 112.9380\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 115.8090 - val_loss: 114.7214\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.8407 - val_loss: 115.2702\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.5737 - val_loss: 128.2321\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 118.3742 - val_loss: 127.0195\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 112.9025 - val_loss: 120.7493\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.6397 - val_loss: 111.1845\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.0127 - val_loss: 111.9608\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.9927 - val_loss: 110.8486\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.0963 - val_loss: 114.1067\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 110.1808 - val_loss: 112.5890\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.0021 - val_loss: 111.9863\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.5370 - val_loss: 111.1615\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.0165 - val_loss: 111.8786\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.6891 - val_loss: 111.2340\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.1734 - val_loss: 110.5302\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.2061 - val_loss: 112.4637\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 107.8474 - val_loss: 111.2147\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 112.0306 - val_loss: 111.8210\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.9113 - val_loss: 119.9998\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.1091 - val_loss: 111.7265\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 108.3314 - val_loss: 111.5400\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.1737 - val_loss: 111.8258\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.6848 - val_loss: 115.4243\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 109.9444 - val_loss: 125.0455\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.5584 - val_loss: 113.0406\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.3738 - val_loss: 112.0544\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.3831 - val_loss: 113.0104\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.0522 - val_loss: 112.2248\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.1452 - val_loss: 116.9387\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.3505 - val_loss: 117.1708\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 112.9799 - val_loss: 118.5341\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 112.5592 - val_loss: 126.2834\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.0512 - val_loss: 111.3986\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.8051 - val_loss: 112.8851\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.8868 - val_loss: 110.7245\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.5269 - val_loss: 113.6088\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.8786 - val_loss: 115.8123\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.8581 - val_loss: 111.7726\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.6073 - val_loss: 115.0625\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.6311 - val_loss: 114.5791\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.5849 - val_loss: 114.8345\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 109.5929 - val_loss: 131.4033\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.3314 - val_loss: 129.1142\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 114.4756 - val_loss: 112.8308\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.7703 - val_loss: 114.1734\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 113.7579 - val_loss: 112.1491\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 108.7202 - val_loss: 112.7271\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 110.6839 - val_loss: 112.9174\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 110.6891 - val_loss: 112.5014\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.4762 - val_loss: 117.4218\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.3478 - val_loss: 114.6533\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.9067 - val_loss: 112.2940\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.3033 - val_loss: 111.6096\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 111.9696 - val_loss: 112.2937\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 114.5490 - val_loss: 117.3068\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.2410 - val_loss: 115.5023\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.0119 - val_loss: 121.6025\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.3821 - val_loss: 112.5055\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.1438 - val_loss: 124.6742\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.1359 - val_loss: 113.5906\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.7698 - val_loss: 116.2662\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.2700 - val_loss: 111.8995\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.8213 - val_loss: 117.3522\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.7082 - val_loss: 113.7967\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.0915 - val_loss: 118.9077\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.9250 - val_loss: 111.9585\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.0205 - val_loss: 112.7301\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.0616 - val_loss: 117.7966\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.5959 - val_loss: 111.6941\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.0055 - val_loss: 120.0057\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.5494 - val_loss: 112.0421\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.3520 - val_loss: 113.6823\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.9653 - val_loss: 112.2182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 811us/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 108.6384 - val_loss: 113.1104\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.0500 - val_loss: 121.8633\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 109.0592 - val_loss: 121.1352\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.9636 - val_loss: 115.0118\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.5074 - val_loss: 111.6521\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.6284 - val_loss: 112.6663\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.5051 - val_loss: 115.5938\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 108.6528 - val_loss: 110.8008\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.8237 - val_loss: 112.0641\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.8950 - val_loss: 114.9952\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.4734 - val_loss: 114.2279\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.6181 - val_loss: 112.6213\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.7788 - val_loss: 111.7964\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.2974 - val_loss: 112.7026\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.5188 - val_loss: 113.3807\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.0398 - val_loss: 121.9056\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.9456 - val_loss: 119.6961\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.2616 - val_loss: 119.1010\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 114.8670 - val_loss: 111.9446\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 113.0053 - val_loss: 112.0081\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.8597 - val_loss: 124.6946\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 114.2334 - val_loss: 113.0454\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.9550 - val_loss: 111.5268\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 109.5559 - val_loss: 114.2943\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 117.8296 - val_loss: 114.9830\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.5150 - val_loss: 110.0726\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.3682 - val_loss: 112.4678\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.2242 - val_loss: 111.8806\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.7828 - val_loss: 110.9578\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 109.4907 - val_loss: 111.6813\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.8557 - val_loss: 111.9518\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.3616 - val_loss: 111.2783\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.8902 - val_loss: 111.6335\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.6280 - val_loss: 114.6071\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 113.9774 - val_loss: 111.9294\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.8515 - val_loss: 112.0568\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.5457 - val_loss: 112.1431\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.6796 - val_loss: 111.6330\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.5699 - val_loss: 112.0480\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.9363 - val_loss: 111.7801\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.6142 - val_loss: 111.7605\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.4677 - val_loss: 116.2650\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.4849 - val_loss: 119.6692\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.9754 - val_loss: 117.9644\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.1837 - val_loss: 111.9783\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.6499 - val_loss: 123.9422\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 112.2759 - val_loss: 120.5357\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.1556 - val_loss: 122.6097\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.5257 - val_loss: 110.6381\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.9129 - val_loss: 116.4095\n",
      "10/10 [==============================] - 0s 0s/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 113.0379 - val_loss: 112.7431\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 112.1498 - val_loss: 113.6707\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 109.4701 - val_loss: 111.0036\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.8460 - val_loss: 119.5858\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.4162 - val_loss: 119.6220\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.9999 - val_loss: 121.7086\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 114.5202 - val_loss: 118.6263\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.6284 - val_loss: 112.1808\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.4103 - val_loss: 113.6899\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.5551 - val_loss: 111.2241\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.3217 - val_loss: 114.5415\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.6264 - val_loss: 110.7589\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.3970 - val_loss: 113.9396\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 110.8440 - val_loss: 115.7880\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 111.8883 - val_loss: 114.0203\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.9863 - val_loss: 111.0596\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 109.3017 - val_loss: 113.4620\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.8241 - val_loss: 113.5971\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.7947 - val_loss: 120.5706\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.3447 - val_loss: 112.2519\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.9532 - val_loss: 113.4159\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.1130 - val_loss: 119.8243\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 112.3050 - val_loss: 111.5657\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.2543 - val_loss: 110.8216\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.3472 - val_loss: 115.3886\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 113.2129 - val_loss: 112.2031\n",
      "Epoch 27/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 112.0463 - val_loss: 112.9687\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.0088 - val_loss: 111.8490\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 112.8091 - val_loss: 111.6136\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.9054 - val_loss: 122.0138\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.2741 - val_loss: 115.7992\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.2431 - val_loss: 111.6101\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.9887 - val_loss: 111.3140\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.0241 - val_loss: 111.4721\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.5706 - val_loss: 112.2640\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.5828 - val_loss: 115.9624\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 109.8748 - val_loss: 118.8569\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.0126 - val_loss: 111.8127\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 108.4457 - val_loss: 115.8004\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.2954 - val_loss: 114.2433\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.1564 - val_loss: 111.5048\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.9081 - val_loss: 112.5654\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 113.8603 - val_loss: 113.3578\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.0038 - val_loss: 111.7618\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.7163 - val_loss: 111.7285\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 111.5913 - val_loss: 112.6171\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.0588 - val_loss: 112.8257\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 108.6378 - val_loss: 111.3796\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.4749 - val_loss: 115.2971\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.2953 - val_loss: 117.7358\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 107.8510 - val_loss: 111.6935\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.9800 - val_loss: 114.0023\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.4833 - val_loss: 115.0482\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.2076 - val_loss: 112.8563\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 114.3010 - val_loss: 113.5444\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.1771 - val_loss: 134.2225\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 112.6900 - val_loss: 114.1667\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 106.6913 - val_loss: 123.6623\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 108.5099 - val_loss: 111.5177\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.0999 - val_loss: 114.2294\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.7394 - val_loss: 115.4972\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.8209 - val_loss: 113.6566\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.2477 - val_loss: 112.2505\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.4471 - val_loss: 113.9337\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 115.4025 - val_loss: 114.4613\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 122.1341 - val_loss: 114.5460\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 113.2134 - val_loss: 113.4500\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.2985 - val_loss: 113.3936\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.3667 - val_loss: 111.3458\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 110.2210 - val_loss: 112.2957\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.4632 - val_loss: 117.7370\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.9338 - val_loss: 119.8490\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.4899 - val_loss: 112.4175\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.8077 - val_loss: 111.7399\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 108.0300 - val_loss: 111.6796\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.2715 - val_loss: 112.1676\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.6998 - val_loss: 110.8183\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.6359 - val_loss: 111.1710\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 111.7924 - val_loss: 114.2604\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.9281 - val_loss: 111.2156\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.1865 - val_loss: 111.7663\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.9112 - val_loss: 121.6276\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.5688 - val_loss: 114.0827\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.1044 - val_loss: 115.9418\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.6951 - val_loss: 111.7636\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.8801 - val_loss: 112.9595\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.8534 - val_loss: 110.3210\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.9613 - val_loss: 114.5916\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.3420 - val_loss: 111.3760\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.0234 - val_loss: 115.8418\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.1240 - val_loss: 111.8451\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.2046 - val_loss: 112.5859\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.2078 - val_loss: 112.2703\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 111.1494 - val_loss: 114.3461\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 111.2665 - val_loss: 113.2200\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.6044 - val_loss: 111.0747\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.0029 - val_loss: 113.1325\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 107.6098 - val_loss: 122.0853\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 112.6445 - val_loss: 119.4938\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.0771 - val_loss: 123.6207\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 109.7162 - val_loss: 117.5332\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.6072 - val_loss: 127.3504\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 6ms/step - loss: 114.6102 - val_loss: 138.7204\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.7127 - val_loss: 111.7872\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 111.7504 - val_loss: 111.2291\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.6880 - val_loss: 111.2346\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.0443 - val_loss: 111.7840\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 107.3242 - val_loss: 115.5442\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.3772 - val_loss: 113.5712\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.7910 - val_loss: 115.3987\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.6479 - val_loss: 117.1983\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.6371 - val_loss: 112.4492\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.5767 - val_loss: 123.6589\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.1628 - val_loss: 111.9749\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.1196 - val_loss: 112.6042\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 109.2280 - val_loss: 128.1130\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.0616 - val_loss: 110.8529\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.4432 - val_loss: 116.0387\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 107.5597 - val_loss: 118.4869\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 108.8997 - val_loss: 113.9977\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 113.0048 - val_loss: 112.7052\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 116.2033 - val_loss: 112.0277\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.5693 - val_loss: 123.0845\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.5136 - val_loss: 111.7056\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.7595 - val_loss: 116.2919\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.2071 - val_loss: 110.1972\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.2721 - val_loss: 112.3736\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.2917 - val_loss: 112.4541\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 109.0139 - val_loss: 113.9557\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 109.2260 - val_loss: 120.2223\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.4668 - val_loss: 115.5506\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 108.6443 - val_loss: 121.8572\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.1313 - val_loss: 111.4706\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.6926 - val_loss: 112.4015\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 108.6503 - val_loss: 112.0313\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 110.3172 - val_loss: 110.6929\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.2962 - val_loss: 112.5267\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.6170 - val_loss: 115.3633\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 107.7517 - val_loss: 120.4092\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 111.2406 - val_loss: 116.4189\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.4247 - val_loss: 114.2944\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 109.8373 - val_loss: 124.9551\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.8716 - val_loss: 113.6531\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.0969 - val_loss: 131.1250\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.9781 - val_loss: 114.2830\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 109.0803 - val_loss: 112.0663\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.9140 - val_loss: 114.0325\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.4948 - val_loss: 113.8492\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.4424 - val_loss: 128.2744\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.6301 - val_loss: 114.7707\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 108.8903 - val_loss: 111.6212\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 107.7303 - val_loss: 112.7887\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.0357 - val_loss: 115.3260\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 108.8789 - val_loss: 116.7644\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.0576 - val_loss: 123.1476\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.8638 - val_loss: 119.7665\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.2860 - val_loss: 114.9194\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.5353 - val_loss: 112.8894\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.5345 - val_loss: 112.6813\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.8881 - val_loss: 125.0137\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.1703 - val_loss: 119.1104\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.1508 - val_loss: 112.4730\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.7765 - val_loss: 114.1489\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.0483 - val_loss: 123.5153\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.7873 - val_loss: 111.8652\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.7954 - val_loss: 118.1781\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.5832 - val_loss: 112.1793\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.4858 - val_loss: 120.0254\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 113.8884 - val_loss: 130.0262\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 116.1550 - val_loss: 123.8634\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.0513 - val_loss: 112.9768\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 113.0429 - val_loss: 119.7811\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.1336 - val_loss: 114.7396\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.0392 - val_loss: 116.7641\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.2064 - val_loss: 120.9106\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.6469 - val_loss: 110.4251\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.8205 - val_loss: 111.1180\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.0188 - val_loss: 113.0497\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.2679 - val_loss: 111.0209\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.6715 - val_loss: 110.8871\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 6ms/step - loss: 112.8579 - val_loss: 111.8895\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.6677 - val_loss: 113.4005\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.4561 - val_loss: 113.0928\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.1961 - val_loss: 111.6891\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.5533 - val_loss: 112.0230\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.6038 - val_loss: 112.8876\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.4285 - val_loss: 113.6931\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.8465 - val_loss: 126.6227\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 112.2686 - val_loss: 124.1760\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 112.1650 - val_loss: 111.6720\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.6379 - val_loss: 113.3123\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 112.9943 - val_loss: 111.9798\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 112.0366 - val_loss: 111.2279\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 106.9647 - val_loss: 116.8096\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.1414 - val_loss: 115.5597\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.5372 - val_loss: 132.5716\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.3874 - val_loss: 121.0671\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.1565 - val_loss: 113.9562\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.2807 - val_loss: 113.5563\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.9016 - val_loss: 134.3166\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 110.9374 - val_loss: 119.6267\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 114.6460 - val_loss: 124.3722\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.3001 - val_loss: 119.0047\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.2138 - val_loss: 124.8359\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 113.7480 - val_loss: 127.6056\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.1406 - val_loss: 117.2266\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.9953 - val_loss: 116.5821\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 106.8527 - val_loss: 111.5599\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 108.0625 - val_loss: 112.0941\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.8456 - val_loss: 111.7788\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 109.5388 - val_loss: 115.8011\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.5882 - val_loss: 115.3849\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.2250 - val_loss: 112.7164\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.5766 - val_loss: 112.7100\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 111.3475 - val_loss: 119.1540\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 114.1033 - val_loss: 120.4940\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 124.6155 - val_loss: 114.5251\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.3933 - val_loss: 111.7429\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 110.4774 - val_loss: 111.3691\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.5020 - val_loss: 111.7008\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 108.4747 - val_loss: 113.4835\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.5043 - val_loss: 115.8493\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.6434 - val_loss: 114.4168\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.4686 - val_loss: 113.7788\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.9057 - val_loss: 111.6362\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 110.5870 - val_loss: 113.4123\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.9538 - val_loss: 113.6382\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 109.1045 - val_loss: 111.0934\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.0997 - val_loss: 118.3687\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 109.4744 - val_loss: 112.4900\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.8524 - val_loss: 110.6804\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.8597 - val_loss: 113.4059\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.3510 - val_loss: 113.6984\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 109.7790 - val_loss: 114.1286\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 120.3423 - val_loss: 111.8648\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.0326 - val_loss: 112.9574\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.0291 - val_loss: 112.0104\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.9155 - val_loss: 112.7060\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.0419 - val_loss: 111.8537\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.8589 - val_loss: 113.8504\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 108.8104 - val_loss: 111.9874\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.6036 - val_loss: 113.4070\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 112.5033 - val_loss: 111.0938\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 113.3706 - val_loss: 112.3715\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.6620 - val_loss: 120.6056\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.7523 - val_loss: 127.8762\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 116.1799 - val_loss: 118.8365\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.1615 - val_loss: 115.0254\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.1003 - val_loss: 118.6198\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.5505 - val_loss: 111.5290\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 109.8331 - val_loss: 112.6480\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.9134 - val_loss: 111.1485\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.1726 - val_loss: 115.1581\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.6303 - val_loss: 112.1875\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.5260 - val_loss: 111.5666\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.8667 - val_loss: 111.2219\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 109.6727 - val_loss: 111.7283\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.2327 - val_loss: 112.9426\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.7842 - val_loss: 114.2320\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.1145 - val_loss: 111.7309\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 107.7523 - val_loss: 117.6380\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 108.2320 - val_loss: 120.0196\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.4750 - val_loss: 110.2436\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 107.3717 - val_loss: 119.2977\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.0921 - val_loss: 114.3571\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.2628 - val_loss: 111.1547\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.9458 - val_loss: 113.0132\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.4474 - val_loss: 112.7114\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 106.7676 - val_loss: 111.6539\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.7304 - val_loss: 111.2937\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.3194 - val_loss: 113.1360\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.2095 - val_loss: 112.2639\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.9162 - val_loss: 112.0586\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.6868 - val_loss: 111.1586\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.8762 - val_loss: 113.7375\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.3871 - val_loss: 111.7242\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.5571 - val_loss: 111.6538\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.2132 - val_loss: 114.9554\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 107.4914 - val_loss: 112.9919\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.8287 - val_loss: 112.7638\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.5478 - val_loss: 115.1410\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.8753 - val_loss: 111.9927\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.7185 - val_loss: 121.2108\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 112.1362 - val_loss: 118.9125\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.0983 - val_loss: 139.1598\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 118.1868 - val_loss: 125.2523\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 112.1630 - val_loss: 124.6787\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.5223 - val_loss: 113.8503\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.7835 - val_loss: 112.6702\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 109.0233 - val_loss: 110.7403\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 107.8277 - val_loss: 119.6835\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 111.0240 - val_loss: 119.5770\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.3555 - val_loss: 117.0866\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 108.8620 - val_loss: 113.1935\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.2916 - val_loss: 114.2071\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.5587 - val_loss: 118.0350\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.0966 - val_loss: 126.9442\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.1998 - val_loss: 115.7432\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 112.7629 - val_loss: 112.6097\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.9887 - val_loss: 116.2495\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 110.8266 - val_loss: 114.7129\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.4697 - val_loss: 116.1286\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 115.1550 - val_loss: 118.6822\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 113.2816 - val_loss: 112.6653\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 116.3413 - val_loss: 113.4796\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 120.5060 - val_loss: 113.7732\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 116.3694 - val_loss: 111.8656\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.3449 - val_loss: 113.7537\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.8761 - val_loss: 113.7223\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.6298 - val_loss: 112.8117\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 109.6641 - val_loss: 119.0721\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 108.5816 - val_loss: 125.9432\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 110.5876 - val_loss: 120.9883\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 108.3422 - val_loss: 113.4872\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.5071 - val_loss: 116.0035\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.7891 - val_loss: 110.7402\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.8202 - val_loss: 115.7937\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 109.5558 - val_loss: 112.4307\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.8544 - val_loss: 110.5515\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.9092 - val_loss: 111.9984\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.6044 - val_loss: 113.4896\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 113.5284 - val_loss: 120.1229\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.7575 - val_loss: 118.7912\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 107.5630 - val_loss: 118.0715\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.9619 - val_loss: 121.3223\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 112.7688 - val_loss: 128.6094\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 112.6090 - val_loss: 113.9971\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 113.0590 - val_loss: 116.1917\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.3263 - val_loss: 114.2702\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.8903 - val_loss: 112.4400\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.3420 - val_loss: 113.8047\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 108.8196 - val_loss: 112.2614\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 108.4345 - val_loss: 112.1368\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.3499 - val_loss: 133.5760\n",
      "Epoch 35/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 111.0603 - val_loss: 115.5978\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 110.6259 - val_loss: 113.2536\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 108.9318 - val_loss: 111.7513\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 108.4714 - val_loss: 117.3546\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 108.8947 - val_loss: 122.8448\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.2337 - val_loss: 119.7122\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.4686 - val_loss: 110.0936\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.6975 - val_loss: 124.5854\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.7695 - val_loss: 115.6671\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.7694 - val_loss: 118.7715\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.2646 - val_loss: 111.4027\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.9715 - val_loss: 112.6962\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.8217 - val_loss: 111.6620\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.3707 - val_loss: 115.6155\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 113.0401 - val_loss: 118.6213\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.2121 - val_loss: 111.5318\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 109.4288 - val_loss: 111.9813\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 107.9149 - val_loss: 112.3381\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.1261 - val_loss: 112.8256\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.8733 - val_loss: 113.5852\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.3270 - val_loss: 113.1513\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 108.5625 - val_loss: 112.4010\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.6299 - val_loss: 112.9951\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.6717 - val_loss: 110.8570\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.2152 - val_loss: 128.1714\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 113.7188 - val_loss: 132.6906\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 117.9595 - val_loss: 124.2578\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 110.1848 - val_loss: 110.8494\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.5338 - val_loss: 111.1003\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 108.5185 - val_loss: 112.0831\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 108.1454 - val_loss: 118.6461\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.5471 - val_loss: 110.7786\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 111.2366 - val_loss: 112.3588\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.3201 - val_loss: 137.2746\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 115.8013 - val_loss: 138.9276\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 113.8685 - val_loss: 113.7356\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.3869 - val_loss: 112.3261\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.3276 - val_loss: 111.2288\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 108.4316 - val_loss: 115.2315\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.0566 - val_loss: 112.7432\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.4849 - val_loss: 120.1141\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 110.0563 - val_loss: 115.9246\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.3642 - val_loss: 127.9327\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 113.4785 - val_loss: 126.5657\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.5825 - val_loss: 113.3798\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.0604 - val_loss: 112.7973\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.2835 - val_loss: 113.8046\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 110.9008 - val_loss: 114.5499\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 108.4375 - val_loss: 111.2057\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.5888 - val_loss: 112.5091\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.0170 - val_loss: 112.4598\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.5324 - val_loss: 114.8737\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.6723 - val_loss: 114.5276\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 107.9967 - val_loss: 120.5797\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.5258 - val_loss: 121.2539\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 109.7831 - val_loss: 112.2089\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.7277 - val_loss: 112.1899\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.8711 - val_loss: 112.2333\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.5546 - val_loss: 114.1232\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.3009 - val_loss: 111.8554\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.8709 - val_loss: 112.3191\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.0493 - val_loss: 113.3404\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.1750 - val_loss: 112.3095\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 115.9737 - val_loss: 125.5826\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 114.6597 - val_loss: 109.9711\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.0093 - val_loss: 114.5544\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 108.8421 - val_loss: 111.3141\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.7113 - val_loss: 112.4168\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.5669 - val_loss: 110.5433\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.6020 - val_loss: 112.8975\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.7010 - val_loss: 114.2517\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.5265 - val_loss: 113.0491\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.6118 - val_loss: 121.3478\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 114.1550 - val_loss: 113.4365\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 108.6473 - val_loss: 111.0420\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.2389 - val_loss: 112.1653\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 107.4655 - val_loss: 117.4101\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.8311 - val_loss: 124.3991\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.4306 - val_loss: 116.2415\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.0358 - val_loss: 116.4899\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.6946 - val_loss: 119.2911\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.9229 - val_loss: 120.2684\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.1005 - val_loss: 112.8838\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.1231 - val_loss: 111.6875\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 107.1848 - val_loss: 122.4499\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 114.6667 - val_loss: 110.5851\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 114.6059 - val_loss: 112.1250\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.9180 - val_loss: 111.7771\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.1790 - val_loss: 111.2468\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.2097 - val_loss: 111.5921\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.6917 - val_loss: 111.7266\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.4229 - val_loss: 111.9077\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 109.6085 - val_loss: 111.8395\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.8027 - val_loss: 115.1091\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 110.4641 - val_loss: 111.7710\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 108.9498 - val_loss: 111.4254\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.7241 - val_loss: 115.0604\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.6410 - val_loss: 111.5196\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 109.8602 - val_loss: 116.7686\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.3239 - val_loss: 114.6665\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.5279 - val_loss: 112.4443\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.3941 - val_loss: 111.0651\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.7955 - val_loss: 111.9749\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 107.6043 - val_loss: 113.4723\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.4923 - val_loss: 111.1378\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 109.3616 - val_loss: 113.8680\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 110.4444 - val_loss: 113.6956\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 108.4987 - val_loss: 111.1381\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.4778 - val_loss: 112.1981\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.4671 - val_loss: 110.7671\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.1120 - val_loss: 111.9657\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.9694 - val_loss: 125.7903\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 111.1865 - val_loss: 125.7577\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 114.8695 - val_loss: 119.9587\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.1767 - val_loss: 114.3781\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.9047 - val_loss: 118.8203\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "mse = [] # Initializing the list for appending the MSE upon each iteration\n",
    "for i in range(50):\n",
    "    mse.append(MSE(model, X, Y, 50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reporting Mean and Standard Deviation of the Mean Squared Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the mean squared error\n",
    "x = ['{0}'.format(i+1) for i in range(50)]\n",
    "plt.bar(x,mse)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Mean Squared Error - MSE')\n",
    "plt.title('Evolution of MSE over the iterations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of the MSE's: 112.85093267665532\n",
      "Standard deviation of the MSE's: 10.105960948369903\n"
     ]
    }
   ],
   "source": [
    "# Mean of the MSE's\n",
    "mean_partA = np.array(mse).mean()\n",
    "print(\"Mean of the MSE's:\",mean_partA)\n",
    "\n",
    "# Standard deviation of the MSE'S\n",
    "std_partA = np.array(mse).std()\n",
    "print(\"Standard deviation of the MSE's:\",std_partA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Reporting mean of the mean squared error using normalized version of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.476712</td>\n",
       "      <td>-0.856472</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>-0.916319</td>\n",
       "      <td>-0.620147</td>\n",
       "      <td>0.862735</td>\n",
       "      <td>-1.217079</td>\n",
       "      <td>-0.279597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.476712</td>\n",
       "      <td>-0.856472</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>-0.916319</td>\n",
       "      <td>-0.620147</td>\n",
       "      <td>1.055651</td>\n",
       "      <td>-1.217079</td>\n",
       "      <td>-0.279597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.491187</td>\n",
       "      <td>0.795140</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>2.174405</td>\n",
       "      <td>-1.038638</td>\n",
       "      <td>-0.526262</td>\n",
       "      <td>-2.239829</td>\n",
       "      <td>3.551340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.491187</td>\n",
       "      <td>0.795140</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>2.174405</td>\n",
       "      <td>-1.038638</td>\n",
       "      <td>-0.526262</td>\n",
       "      <td>-2.239829</td>\n",
       "      <td>5.055221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.790075</td>\n",
       "      <td>0.678079</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>0.488555</td>\n",
       "      <td>-1.038638</td>\n",
       "      <td>0.070492</td>\n",
       "      <td>0.647569</td>\n",
       "      <td>4.976069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Cement  Blast Furnace Slag   Fly Ash     Water  Superplasticizer  \\\n",
       "0  2.476712           -0.856472 -0.846733 -0.916319         -0.620147   \n",
       "1  2.476712           -0.856472 -0.846733 -0.916319         -0.620147   \n",
       "2  0.491187            0.795140 -0.846733  2.174405         -1.038638   \n",
       "3  0.491187            0.795140 -0.846733  2.174405         -1.038638   \n",
       "4 -0.790075            0.678079 -0.846733  0.488555         -1.038638   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate       Age  \n",
       "0          0.862735       -1.217079 -0.279597  \n",
       "1          1.055651       -1.217079 -0.279597  \n",
       "2         -0.526262       -2.239829  3.551340  \n",
       "3         -0.526262       -2.239829  5.055221  \n",
       "4          0.070492        0.647569  4.976069  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize the data\n",
    "X_norm = (X-X.mean())/X.std()\n",
    "X_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 109.6688 - val_loss: 139.6484\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 115.6659 - val_loss: 116.1681\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.3652 - val_loss: 111.6242\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.7742 - val_loss: 114.2082\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.6634 - val_loss: 111.1800\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.1076 - val_loss: 112.2398\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.3644 - val_loss: 111.9600\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.7584 - val_loss: 112.6869\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.1940 - val_loss: 112.1112\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.9695 - val_loss: 116.1789\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 107.7206 - val_loss: 111.5589\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.8661 - val_loss: 113.0100\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 108.3155 - val_loss: 116.6495\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.6731 - val_loss: 117.5498\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.5840 - val_loss: 115.8613\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.3647 - val_loss: 113.8678\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.8723 - val_loss: 111.6035\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.8159 - val_loss: 113.2783\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.9549 - val_loss: 111.3571\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.8971 - val_loss: 111.3482\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.0297 - val_loss: 113.5913\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 113.3026 - val_loss: 111.9991\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.2619 - val_loss: 111.0485\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.9383 - val_loss: 115.3600\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.3254 - val_loss: 113.6430\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.4258 - val_loss: 111.2677\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.6931 - val_loss: 113.1360\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.8407 - val_loss: 112.2940\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.3701 - val_loss: 114.3948\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.6760 - val_loss: 112.2274\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.5600 - val_loss: 118.0808\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.0488 - val_loss: 124.4414\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.6003 - val_loss: 116.2084\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 109.7076 - val_loss: 112.9415\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.2345 - val_loss: 113.8286\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 112.3622 - val_loss: 124.1412\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.7409 - val_loss: 119.4792\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.8519 - val_loss: 114.8451\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 109.1437 - val_loss: 112.3804\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 112.8033 - val_loss: 130.3347\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 110.7437 - val_loss: 111.9324\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 108.5556 - val_loss: 111.4874\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.9824 - val_loss: 112.6225\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 115.3177 - val_loss: 111.8839\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 112.4990 - val_loss: 112.7465\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.3230 - val_loss: 113.1998\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.9278 - val_loss: 113.4045\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.0423 - val_loss: 111.9519\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.9999 - val_loss: 112.0875\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.0420 - val_loss: 113.3636\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 108.9736 - val_loss: 113.6622\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.9534 - val_loss: 112.2199\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 109.4107 - val_loss: 111.8077\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 109.0574 - val_loss: 113.7929\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 108.3735 - val_loss: 116.6935\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 114.4214 - val_loss: 114.5391\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 112.4086 - val_loss: 112.4016\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 112.1818 - val_loss: 111.8896\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 108.0975 - val_loss: 111.0470\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 112.0020 - val_loss: 114.9168\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 114.3721 - val_loss: 112.8429\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.3793 - val_loss: 112.1885\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.0344 - val_loss: 110.9743\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.3896 - val_loss: 113.6562\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.3964 - val_loss: 113.2582\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.6279 - val_loss: 111.3033\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.2858 - val_loss: 112.6398\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 109.0907 - val_loss: 117.5394\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.8722 - val_loss: 118.4615\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 114.7790 - val_loss: 124.7037\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.9249 - val_loss: 114.3804\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.7512 - val_loss: 113.9628\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.4294 - val_loss: 117.2411\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 114.8781 - val_loss: 113.6296\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.1740 - val_loss: 115.4741\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.5565 - val_loss: 119.9218\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.7963 - val_loss: 126.9093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 109.3384 - val_loss: 115.9760\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.3853 - val_loss: 129.0391\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 114.2439 - val_loss: 117.2732\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.3906 - val_loss: 114.2142\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.8512 - val_loss: 112.0290\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.1504 - val_loss: 113.0490\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.4689 - val_loss: 110.6789\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.2076 - val_loss: 114.0997\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.8931 - val_loss: 111.4967\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 109.1308 - val_loss: 113.3397\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.9373 - val_loss: 111.1596\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.5608 - val_loss: 114.8574\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111.0125 - val_loss: 125.9223\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.7963 - val_loss: 115.6986\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 107.9234 - val_loss: 111.9892\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.3477 - val_loss: 112.2972\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.5364 - val_loss: 114.3088\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.8592 - val_loss: 114.7817\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 109.6152 - val_loss: 111.4559\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.0313 - val_loss: 111.4933\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 117.2424 - val_loss: 120.1966\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 119.5069 - val_loss: 111.1789\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.9208 - val_loss: 112.1202\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 112.0214 - val_loss: 111.1609\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 112.1928 - val_loss: 116.5911\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 111.4339 - val_loss: 112.3549\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.9303 - val_loss: 117.5504\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.0400 - val_loss: 111.8620\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.2969 - val_loss: 111.7764\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.5492 - val_loss: 114.5123\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.7251 - val_loss: 113.1259\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 113.3494 - val_loss: 115.8094\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 109.0201 - val_loss: 113.9594\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 106.8508 - val_loss: 114.3221\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 111.4999 - val_loss: 111.9381\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.8593 - val_loss: 120.3630\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.7922 - val_loss: 112.3643\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.3280 - val_loss: 116.1794\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.1966 - val_loss: 111.7175\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.2086 - val_loss: 112.7226\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.8634 - val_loss: 114.0604\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.5145 - val_loss: 114.1392\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 107.0614 - val_loss: 111.3635\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.2472 - val_loss: 111.6851\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.1682 - val_loss: 118.3012\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 110.8988 - val_loss: 111.3342\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 112.0793 - val_loss: 112.0985\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.9565 - val_loss: 111.7569\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 108.3984 - val_loss: 112.1747\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.9245 - val_loss: 112.7953\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 110.6270 - val_loss: 114.4969\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 111.0130 - val_loss: 114.0034\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.0161 - val_loss: 118.5509\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 108.9286 - val_loss: 117.5735\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.1518 - val_loss: 111.4280\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.7461 - val_loss: 112.7793\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 108.1388 - val_loss: 112.1656\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.5394 - val_loss: 112.4098\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.6971 - val_loss: 111.5457\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.4147 - val_loss: 113.0990\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.3555 - val_loss: 112.0146\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.2581 - val_loss: 115.0238\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 110.3739 - val_loss: 112.9655\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 109.7742 - val_loss: 120.4536\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 110.0670 - val_loss: 118.8562\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.1643 - val_loss: 112.3936\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.2091 - val_loss: 112.9969\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.3929 - val_loss: 115.5408\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.3212 - val_loss: 120.2424\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.2733 - val_loss: 122.7912\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 109.8991 - val_loss: 115.7294\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 113.0677 - val_loss: 121.9187\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.8476 - val_loss: 121.8397\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 110.4456 - val_loss: 118.5801\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.2473 - val_loss: 111.6531\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.1889 - val_loss: 117.3456\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 107.9507 - val_loss: 111.9294\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.6126 - val_loss: 117.9709\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.7370 - val_loss: 113.7435\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 109.5464 - val_loss: 111.6583\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.3142 - val_loss: 112.6483\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.1749 - val_loss: 111.7486\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 108.5682 - val_loss: 113.8631\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.3548 - val_loss: 112.3642\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.4211 - val_loss: 114.4985\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 106.4677 - val_loss: 113.2451\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.2691 - val_loss: 116.5894\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 108.1166 - val_loss: 111.6245\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.3320 - val_loss: 112.7542\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.5366 - val_loss: 116.8033\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.8653 - val_loss: 111.6898\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.0577 - val_loss: 112.8744\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.3693 - val_loss: 112.0498\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.7887 - val_loss: 111.6476\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 107.1405 - val_loss: 116.1183\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 109.3446 - val_loss: 118.8360\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 109.1371 - val_loss: 122.0040\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.8929 - val_loss: 123.6067\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.5877 - val_loss: 117.7739\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 106.5605 - val_loss: 110.0563\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.4650 - val_loss: 116.6145\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 108.7241 - val_loss: 110.6870\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 106.7088 - val_loss: 110.2593\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 106.3422 - val_loss: 117.3473\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 107.5064 - val_loss: 116.6825\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 108.6497 - val_loss: 109.8157\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 106.5385 - val_loss: 116.1877\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 106.4525 - val_loss: 111.3325\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 109.9358 - val_loss: 108.3478\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 111.1250 - val_loss: 107.7513\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 108.1959 - val_loss: 107.9162\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 104.3206 - val_loss: 114.8826\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 105.3018 - val_loss: 108.4154\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 103.9486 - val_loss: 108.6030\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 103.4337 - val_loss: 104.8831\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 102.3901 - val_loss: 103.7758\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 101.4631 - val_loss: 101.3798\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 102.0214 - val_loss: 101.7275\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 103.4204 - val_loss: 106.9650\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 110.9262 - val_loss: 100.8540\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 97.5045 - val_loss: 97.1625\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 96.0314 - val_loss: 99.7623\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 95.3023 - val_loss: 95.0766\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 92.3795 - val_loss: 91.7205\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 90.3138 - val_loss: 90.2342\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 90.2738 - val_loss: 97.0247\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 89.5765 - val_loss: 89.6403\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 85.8516 - val_loss: 87.5596\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 84.8653 - val_loss: 83.7320\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 86.0215 - val_loss: 86.5995\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 86.3965 - val_loss: 81.2037\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 80.3864 - val_loss: 88.7244\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 79.6161 - val_loss: 80.3587\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 83.0663 - val_loss: 84.4849\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 78.6290 - val_loss: 76.6802\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 75.3005 - val_loss: 79.7265\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 76.5152 - val_loss: 77.4876\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 79.7266 - val_loss: 77.5084\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 73.0660 - val_loss: 74.5370\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 73.7071 - val_loss: 74.8617\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 72.8398 - val_loss: 73.1247\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 73.1624 - val_loss: 71.9992\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 70.8975 - val_loss: 70.1769\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 69.9465 - val_loss: 70.9071\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 67.8725 - val_loss: 68.8707\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 71.3184 - val_loss: 73.5768\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 70.0749 - val_loss: 68.6332\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 67.1703 - val_loss: 68.0088\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 66.2269 - val_loss: 68.4687\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 65.2577 - val_loss: 66.8602\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 65.0941 - val_loss: 68.8881\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 64.9678 - val_loss: 71.7072\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 63.9088 - val_loss: 65.5225\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 63.0130 - val_loss: 63.8316\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 63.4881 - val_loss: 64.0900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 61.9289 - val_loss: 67.6192\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 63.8755 - val_loss: 64.2080\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 61.8175 - val_loss: 64.9316\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 61.1107 - val_loss: 61.8672\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 60.3576 - val_loss: 62.2173\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 61.3493 - val_loss: 61.1175\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 60.0274 - val_loss: 61.1905\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 60.2738 - val_loss: 60.9310\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 60.6369 - val_loss: 64.3605\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 59.6788 - val_loss: 60.9276\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 59.7168 - val_loss: 63.4035\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 60.5370 - val_loss: 61.4553\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 59.2866 - val_loss: 60.1518\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 58.8426 - val_loss: 59.1887\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 58.5788 - val_loss: 59.3592\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 59.5014 - val_loss: 61.6115\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 62.8802 - val_loss: 65.5070\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 58.8852 - val_loss: 58.4483\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 58.7510 - val_loss: 65.5311\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 58.2332 - val_loss: 60.0978\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 57.7514 - val_loss: 58.1708\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 58.5003 - val_loss: 57.8101\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 57.4827 - val_loss: 57.7465\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 57.9292 - val_loss: 57.4444\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 58.1652 - val_loss: 56.5962\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 58.2398 - val_loss: 61.2623\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 58.2928 - val_loss: 56.8294\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 56.3361 - val_loss: 56.5004\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 56.7104 - val_loss: 56.3512\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 56.5442 - val_loss: 56.3423\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 56.0344 - val_loss: 55.9638\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 57.4366 - val_loss: 60.2892\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 57.7880 - val_loss: 61.8280\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 57.0739 - val_loss: 55.0701\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 56.4661 - val_loss: 56.1804\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 55.3111 - val_loss: 67.1527\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 58.1263 - val_loss: 58.1163\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 56.6619 - val_loss: 57.7654\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 56.0615 - val_loss: 55.4610\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 58.3304 - val_loss: 60.5373\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 56.1074 - val_loss: 55.0673\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 55.6186 - val_loss: 58.1852\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 57.2077 - val_loss: 55.6407\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 57.7879 - val_loss: 55.7714\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 55.4227 - val_loss: 56.9593\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 56.3130 - val_loss: 54.8797\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 54.6415 - val_loss: 56.1105\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 55.6769 - val_loss: 55.8886\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 54.7488 - val_loss: 54.2062\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 55.1142 - val_loss: 54.1215\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 55.6418 - val_loss: 54.2941\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 55.1139 - val_loss: 54.9972\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 55.3454 - val_loss: 54.0363\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 55.4501 - val_loss: 58.5711\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 54.8335 - val_loss: 62.2614\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 57.5859 - val_loss: 59.3282\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 55.4503 - val_loss: 55.3353\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 55.0818 - val_loss: 54.4266\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 56.1052 - val_loss: 57.3542\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 57.9076 - val_loss: 58.6216\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 55.8416 - val_loss: 53.4282\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 57.4415 - val_loss: 55.6579\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 55.3451 - val_loss: 53.0286\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 54.8221 - val_loss: 55.3646\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 54.7338 - val_loss: 52.8318\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 53.7040 - val_loss: 58.3120\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 56.9671 - val_loss: 59.9157\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 57.8010 - val_loss: 54.4545\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 57.4969 - val_loss: 53.0828\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 53.8217 - val_loss: 52.7819\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 53.6935 - val_loss: 53.5638\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 55.6278 - val_loss: 53.5472\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 54.2681 - val_loss: 52.2890\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 54.0535 - val_loss: 52.6270\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 54.7113 - val_loss: 52.7720\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 54.0615 - val_loss: 53.7060\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 56.5445 - val_loss: 53.2327\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 53.5058 - val_loss: 54.6917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 57.2311 - val_loss: 62.4160\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 55.9645 - val_loss: 53.1213\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 53.3226 - val_loss: 52.0605\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 53.4934 - val_loss: 59.1962\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 56.0364 - val_loss: 53.6683\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 55.6859 - val_loss: 51.8579\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 53.8357 - val_loss: 51.4505\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 56.0091 - val_loss: 51.3419\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 53.5040 - val_loss: 51.6880\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 53.2542 - val_loss: 51.3113\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 53.0886 - val_loss: 51.9655\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 57.2044 - val_loss: 65.8061\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 59.4207 - val_loss: 64.6241\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 59.8997 - val_loss: 51.4926\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 56.5155 - val_loss: 53.2613\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 54.9277 - val_loss: 55.3692\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 54.0154 - val_loss: 51.0843\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 52.9625 - val_loss: 53.1873\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 53.9658 - val_loss: 53.2210\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 53.8875 - val_loss: 54.2421\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 52.5650 - val_loss: 51.1722\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 52.6601 - val_loss: 50.5863\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 52.4674 - val_loss: 52.7799\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 52.8561 - val_loss: 51.0371\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 54.7979 - val_loss: 52.9022\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 56.7037 - val_loss: 50.7690\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 54.3468 - val_loss: 59.8511\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 58.7915 - val_loss: 51.3068\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 56.2866 - val_loss: 53.5442\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 53.3774 - val_loss: 54.1272\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 52.4565 - val_loss: 52.4544\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 52.3071 - val_loss: 53.8786\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 53.4365 - val_loss: 50.4048\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 52.6713 - val_loss: 52.7297\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 52.2796 - val_loss: 51.4742\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 53.2405 - val_loss: 50.0154\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 52.1563 - val_loss: 52.3120\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 52.3635 - val_loss: 53.0632\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 52.1898 - val_loss: 50.4385\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 53.4605 - val_loss: 50.2449\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 54.7393 - val_loss: 52.0001\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 54.9489 - val_loss: 49.8632\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 52.8287 - val_loss: 55.7935\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 55.8893 - val_loss: 50.3062\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 52.7405 - val_loss: 49.6287\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 52.2180 - val_loss: 50.1265\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 52.1846 - val_loss: 49.8558\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 52.0660 - val_loss: 51.9296\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.9364 - val_loss: 51.6758\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 52.0306 - val_loss: 49.8958\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.7341 - val_loss: 49.7645\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.8869 - val_loss: 49.8931\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 51.5266 - val_loss: 49.7287\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 52.7770 - val_loss: 51.7933\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.5041 - val_loss: 51.0012\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 52.9714 - val_loss: 50.4235\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 53.9832 - val_loss: 52.6787\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 52.0357 - val_loss: 49.3497\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 52.3211 - val_loss: 49.8376\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 51.8390 - val_loss: 49.1344\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.6598 - val_loss: 50.0895\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 52.4044 - val_loss: 50.1908\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.6706 - val_loss: 52.6165\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 52.1471 - val_loss: 50.5135\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 53.8714 - val_loss: 70.5585\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 64.7328 - val_loss: 59.8430\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 53.6045 - val_loss: 49.0991\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 53.5985 - val_loss: 49.1687\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 53.9777 - val_loss: 52.3200\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 52.7340 - val_loss: 58.2770\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 54.1742 - val_loss: 53.4340\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 53.4553 - val_loss: 50.3354\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 53.7341 - val_loss: 48.9688\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.4566 - val_loss: 50.0709\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 53.2236 - val_loss: 48.3864\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 52.1492 - val_loss: 48.7568\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 55.0840 - val_loss: 48.5276\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.6511 - val_loss: 51.1671\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 53.0309 - val_loss: 53.0260\n",
      "Epoch 40/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 4ms/step - loss: 54.7645 - val_loss: 48.4884\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.1792 - val_loss: 48.5129\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.2457 - val_loss: 50.5092\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 51.2660 - val_loss: 49.5569\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.9022 - val_loss: 50.4601\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 50.6142 - val_loss: 49.8077\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 52.8198 - val_loss: 51.5852\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.4817 - val_loss: 49.5681\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 52.7999 - val_loss: 48.3207\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.4521 - val_loss: 48.4467\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.5609 - val_loss: 48.1402\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.4381 - val_loss: 48.2713\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 51.3422 - val_loss: 47.8411\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.0023 - val_loss: 50.2697\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 52.1312 - val_loss: 47.9939\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.4903 - val_loss: 47.6717\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.9649 - val_loss: 47.8609\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 52.3746 - val_loss: 48.8249\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.7171 - val_loss: 47.8530\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.5271 - val_loss: 48.2390\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.6736 - val_loss: 51.0355\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 53.8041 - val_loss: 50.9773\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 52.8552 - val_loss: 50.7453\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 54.0999 - val_loss: 49.4252\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.3545 - val_loss: 47.8317\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.6261 - val_loss: 47.7712\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.6553 - val_loss: 47.3670\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.6632 - val_loss: 47.3935\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 52.6952 - val_loss: 48.1180\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.6354 - val_loss: 48.9663\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.6682 - val_loss: 47.6334\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.1282 - val_loss: 47.7664\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.8250 - val_loss: 49.2655\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 52.9638 - val_loss: 48.2495\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.7952 - val_loss: 54.5809\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 54.6650 - val_loss: 49.5829\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.7570 - val_loss: 47.6473\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.2693 - val_loss: 47.0692\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.1709 - val_loss: 51.1551\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 52.5459 - val_loss: 48.0317\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 53.0383 - val_loss: 52.3929\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.5325 - val_loss: 47.1024\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.5967 - val_loss: 48.5632\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.4996 - val_loss: 49.6352\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 55.1571 - val_loss: 53.8937\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 56.1353 - val_loss: 47.0453\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.4374 - val_loss: 46.8550\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.6630 - val_loss: 47.0876\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.6059 - val_loss: 48.5359\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 52.4902 - val_loss: 47.6038\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.0507 - val_loss: 47.9402\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.8489 - val_loss: 47.0861\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.4850 - val_loss: 51.3050\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 51.7299 - val_loss: 50.5515\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 57.7863 - val_loss: 51.0794\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.4354 - val_loss: 47.7679\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.5069 - val_loss: 46.8643\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.1445 - val_loss: 47.9110\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.7328 - val_loss: 46.8284\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.7466 - val_loss: 47.1160\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.7353 - val_loss: 48.5976\n",
      "10/10 [==============================] - 0s 729us/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 51.4589 - val_loss: 46.4270\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.8327 - val_loss: 47.2053\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.6321 - val_loss: 48.4317\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 53.3608 - val_loss: 46.8719\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.9269 - val_loss: 46.7752\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.9524 - val_loss: 50.0490\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.3783 - val_loss: 46.7324\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.2239 - val_loss: 46.4290\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.2382 - val_loss: 46.5039\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.7828 - val_loss: 47.1841\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 52.2980 - val_loss: 46.4098\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 52.2498 - val_loss: 46.9347\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.8814 - val_loss: 47.1085\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.3111 - val_loss: 46.9938\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.5442 - val_loss: 47.0826\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.5498 - val_loss: 47.0570\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.7002 - val_loss: 46.4739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.9396 - val_loss: 46.5265\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.3135 - val_loss: 46.7143\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.9253 - val_loss: 46.5973\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.9168 - val_loss: 46.3091\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.8272 - val_loss: 50.6573\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.3770 - val_loss: 47.8926\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.8751 - val_loss: 46.6109\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.3305 - val_loss: 46.2050\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.9798 - val_loss: 47.8295\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.5702 - val_loss: 46.6333\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 50.0946 - val_loss: 46.5877\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.0223 - val_loss: 47.3261\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.9463 - val_loss: 46.4997\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.5468 - val_loss: 46.6787\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.4707 - val_loss: 46.5638\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.1297 - val_loss: 45.8171\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.0045 - val_loss: 46.3484\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.9465 - val_loss: 49.3340\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 52.4032 - val_loss: 47.5038\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.8723 - val_loss: 45.9971\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.9496 - val_loss: 48.0646\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.2237 - val_loss: 49.3474\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.3090 - val_loss: 46.9385\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.7826 - val_loss: 46.9851\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 54.3954 - val_loss: 48.4851\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 53.1607 - val_loss: 47.1055\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.2691 - val_loss: 46.0707\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 53.3333 - val_loss: 72.9124\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 56.7897 - val_loss: 45.9383\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.2018 - val_loss: 47.4358\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.8416 - val_loss: 46.5099\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1248 - val_loss: 45.6531\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.7207 - val_loss: 46.3120\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 49.8162 - val_loss: 45.4555\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.2649 - val_loss: 47.0118\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.7014 - val_loss: 45.6099\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.5359 - val_loss: 46.5635\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.3335 - val_loss: 47.1874\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.9974 - val_loss: 45.3647\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.0722 - val_loss: 45.5147\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.4692 - val_loss: 46.1102\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.1090 - val_loss: 45.7388\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 50.6875 - val_loss: 46.5861\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.0600 - val_loss: 46.0304\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9531 - val_loss: 45.7374\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8130 - val_loss: 49.5984\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.7444 - val_loss: 53.3865\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.7025 - val_loss: 45.9194\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.0574 - val_loss: 45.6047\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.4724 - val_loss: 46.1059\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 53.6047 - val_loss: 49.0180\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.1777 - val_loss: 45.6075\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.2921 - val_loss: 49.1971\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 51.3835 - val_loss: 45.7940\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.1688 - val_loss: 46.8167\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.6054 - val_loss: 45.8410\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.0329 - val_loss: 46.5444\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.1206 - val_loss: 47.5216\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.7357 - val_loss: 49.1490\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.6152 - val_loss: 48.7889\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.3843 - val_loss: 46.8046\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.4289 - val_loss: 45.2874\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.2074 - val_loss: 45.8665\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1850 - val_loss: 45.8170\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.5685 - val_loss: 45.6129\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.9908 - val_loss: 50.0290\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 51.6889 - val_loss: 45.6286\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.2847 - val_loss: 48.3184\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.9297 - val_loss: 45.5603\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.8366 - val_loss: 46.0528\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.5118 - val_loss: 49.3197\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.4606 - val_loss: 45.4445\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.2076 - val_loss: 45.5142\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.4738 - val_loss: 47.0099\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.4804 - val_loss: 52.2550\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 51.2724 - val_loss: 47.5851\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.4503 - val_loss: 45.9892\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.0769 - val_loss: 45.4147\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.2716 - val_loss: 45.3461\n",
      "Epoch 47/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 50.2652 - val_loss: 46.5555\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.4554 - val_loss: 47.5300\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.0438 - val_loss: 47.3231\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.8448 - val_loss: 49.1152\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 52.8110 - val_loss: 53.8300\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.6019 - val_loss: 46.0925\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.2643 - val_loss: 51.0809\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.1875 - val_loss: 45.3841\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.3431 - val_loss: 46.5476\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.8617 - val_loss: 45.1569\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8698 - val_loss: 45.9589\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.0939 - val_loss: 45.5416\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.3780 - val_loss: 45.0054\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.7515 - val_loss: 45.2845\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.9729 - val_loss: 47.0729\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.4868 - val_loss: 45.4233\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.0185 - val_loss: 45.2291\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.5790 - val_loss: 46.8975\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1513 - val_loss: 45.2684\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9502 - val_loss: 45.3398\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.6347 - val_loss: 45.3641\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.7587 - val_loss: 46.1410\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.2119 - val_loss: 45.4147\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.8866 - val_loss: 47.9405\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.4430 - val_loss: 46.0752\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.0779 - val_loss: 45.6191\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9991 - val_loss: 45.0227\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.3951 - val_loss: 45.7751\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.2539 - val_loss: 50.1606\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.5491 - val_loss: 45.1306\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9579 - val_loss: 50.6244\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6040 - val_loss: 45.4244\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7964 - val_loss: 44.8849\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.2243 - val_loss: 45.1636\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.9074 - val_loss: 45.7669\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.1921 - val_loss: 48.4367\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.0700 - val_loss: 45.5752\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.5716 - val_loss: 45.4120\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.3076 - val_loss: 44.9432\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.3228 - val_loss: 45.4734\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.3059 - val_loss: 51.8216\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.7095 - val_loss: 45.7139\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.2385 - val_loss: 45.3518\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.7152 - val_loss: 44.8692\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1100 - val_loss: 45.0532\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6574 - val_loss: 45.7594\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.2311 - val_loss: 47.1968\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.8732 - val_loss: 45.9735\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.9275 - val_loss: 46.2143\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.0027 - val_loss: 45.3426\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.1231 - val_loss: 46.2132\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 50.6357 - val_loss: 46.6998\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.8653 - val_loss: 45.2497\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.0614 - val_loss: 45.0616\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 49.9338 - val_loss: 45.3062\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8772 - val_loss: 44.7308\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5847 - val_loss: 49.3118\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.5943 - val_loss: 45.2717\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.6880 - val_loss: 47.7316\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.2534 - val_loss: 50.6225\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.9255 - val_loss: 45.6620\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 50.0672 - val_loss: 44.8152\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 50.8150 - val_loss: 47.8461\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.6823 - val_loss: 45.8733\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3866 - val_loss: 45.1301\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0103 - val_loss: 47.1174\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.0644 - val_loss: 45.5289\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1830 - val_loss: 45.7511\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8886 - val_loss: 45.9745\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.6899 - val_loss: 46.5546\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.0800 - val_loss: 45.3335\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.1393 - val_loss: 45.7568\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8468 - val_loss: 48.5848\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.3130 - val_loss: 45.3629\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 52.4506 - val_loss: 44.5896\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1879 - val_loss: 44.5649\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 51.4184 - val_loss: 49.2103\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.3423 - val_loss: 45.9175\n",
      "Epoch 25/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 4ms/step - loss: 51.8549 - val_loss: 48.6269\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8997 - val_loss: 44.5808\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.3890 - val_loss: 46.3599\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4835 - val_loss: 44.7535\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.6863 - val_loss: 44.7177\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1196 - val_loss: 44.9570\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.3532 - val_loss: 44.6670\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5562 - val_loss: 45.1638\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.2372 - val_loss: 44.8106\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.5558 - val_loss: 45.4598\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1521 - val_loss: 45.2666\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1481 - val_loss: 44.8372\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.9752 - val_loss: 44.4366\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 53.0057 - val_loss: 47.9428\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 53.1282 - val_loss: 46.4034\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.9536 - val_loss: 44.5064\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.2861 - val_loss: 48.8289\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 50.9733 - val_loss: 44.6502\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.9456 - val_loss: 44.4470\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.5982 - val_loss: 45.8383\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.6152 - val_loss: 44.4180\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.3263 - val_loss: 47.9811\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.5752 - val_loss: 45.4251\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3053 - val_loss: 45.0104\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.9153 - val_loss: 44.5558\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.2566 - val_loss: 45.1725\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 50.3521 - val_loss: 47.7204\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.3844 - val_loss: 44.7752\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.6929 - val_loss: 44.5809\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.9077 - val_loss: 44.6375\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.6942 - val_loss: 44.7153\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 52.5926 - val_loss: 51.0906\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.1984 - val_loss: 47.8762\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.4985 - val_loss: 46.6331\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5140 - val_loss: 44.3837\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5551 - val_loss: 45.3492\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.8174 - val_loss: 45.1354\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8704 - val_loss: 53.9170\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.5923 - val_loss: 44.7777\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.7857 - val_loss: 44.9788\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2577 - val_loss: 45.1451\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4495 - val_loss: 45.1261\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.7827 - val_loss: 48.1589\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.1899 - val_loss: 44.8025\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.5047 - val_loss: 44.4353\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.8408 - val_loss: 45.3649\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.4884 - val_loss: 44.3234\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4607 - val_loss: 44.6093\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6392 - val_loss: 44.3398\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.1220 - val_loss: 45.9224\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.2045 - val_loss: 45.1737\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.2435 - val_loss: 45.1896\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.9691 - val_loss: 44.2645\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.2745 - val_loss: 44.7492\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.5454 - val_loss: 45.0190\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2185 - val_loss: 45.2174\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.1593 - val_loss: 44.2944\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.0448 - val_loss: 45.8691\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1662 - val_loss: 47.5597\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.6760 - val_loss: 44.7255\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0636 - val_loss: 44.4499\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.5289 - val_loss: 44.6752\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4527 - val_loss: 50.2207\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8852 - val_loss: 51.5155\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.6022 - val_loss: 44.5569\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.3490 - val_loss: 52.2154\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.6877 - val_loss: 45.3600\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8262 - val_loss: 45.8494\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.9234 - val_loss: 44.7220\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6726 - val_loss: 45.0781\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1611 - val_loss: 44.6328\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 50.4047 - val_loss: 45.7351\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.7732 - val_loss: 45.0857\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1745 - val_loss: 47.1441\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 52.2030 - val_loss: 47.6684\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.1501 - val_loss: 44.7631\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 48.7956 - val_loss: 44.3434\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5961 - val_loss: 44.8008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.9752 - val_loss: 44.7935\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6967 - val_loss: 44.3847\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.7957 - val_loss: 44.8052\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8306 - val_loss: 45.4480\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1938 - val_loss: 45.3185\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.2466 - val_loss: 48.5632\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 54.7081 - val_loss: 50.4209\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.5346 - val_loss: 44.5604\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5026 - val_loss: 45.7774\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.2475 - val_loss: 52.0793\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.5607 - val_loss: 44.6979\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.5999 - val_loss: 44.4981\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5459 - val_loss: 44.2126\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3099 - val_loss: 48.9265\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.4542 - val_loss: 45.2610\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.0093 - val_loss: 55.3560\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 52.3856 - val_loss: 47.6840\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6454 - val_loss: 44.4623\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.9933 - val_loss: 44.7178\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3261 - val_loss: 44.3119\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4017 - val_loss: 45.3022\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.3983 - val_loss: 44.3950\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.0660 - val_loss: 44.2435\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.4715 - val_loss: 44.8447\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.8925 - val_loss: 45.9667\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.0933 - val_loss: 46.5983\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.4991 - val_loss: 45.3998\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8788 - val_loss: 49.4549\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.2021 - val_loss: 48.7631\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.8085 - val_loss: 45.9582\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.0165 - val_loss: 44.7547\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6942 - val_loss: 44.4043\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.6232 - val_loss: 45.9951\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.5374 - val_loss: 44.5704\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6273 - val_loss: 44.1973\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1828 - val_loss: 44.8309\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.5218 - val_loss: 45.8613\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9805 - val_loss: 44.0498\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.0523 - val_loss: 45.7477\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5690 - val_loss: 44.4902\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4254 - val_loss: 44.4407\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1138 - val_loss: 44.8546\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.1583 - val_loss: 44.2146\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.5049 - val_loss: 44.5850\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7863 - val_loss: 44.8787\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4430 - val_loss: 44.7586\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8187 - val_loss: 45.8169\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.6900 - val_loss: 44.6573\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 48.2660 - val_loss: 44.7388\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4259 - val_loss: 45.2407\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4516 - val_loss: 44.4657\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3655 - val_loss: 46.5711\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8881 - val_loss: 44.2716\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.3296 - val_loss: 46.9800\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.9394 - val_loss: 45.1272\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 50.4412 - val_loss: 46.0382\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.8602 - val_loss: 49.2690\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 52.6292 - val_loss: 61.5070\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 52.8683 - val_loss: 46.1336\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.9805 - val_loss: 43.9477\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1652 - val_loss: 47.7219\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.9436 - val_loss: 44.2281\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.9711 - val_loss: 46.5636\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.8802 - val_loss: 44.0494\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.3102 - val_loss: 53.3482\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.5505 - val_loss: 44.4595\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3621 - val_loss: 46.4317\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8741 - val_loss: 44.0648\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.9474 - val_loss: 58.7597\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 53.4437 - val_loss: 49.5930\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9725 - val_loss: 45.3877\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7511 - val_loss: 49.6336\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.4713 - val_loss: 44.2969\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5049 - val_loss: 45.7419\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.5860 - val_loss: 47.0563\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.4480 - val_loss: 46.4437\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.4091 - val_loss: 45.0604\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.4543 - val_loss: 44.2863\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2831 - val_loss: 48.2065\n",
      "Epoch 32/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 52.1697 - val_loss: 44.4100\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.9950 - val_loss: 45.7531\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 50.0504 - val_loss: 44.6702\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2288 - val_loss: 44.1029\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.4947 - val_loss: 46.5154\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.7968 - val_loss: 44.6495\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6935 - val_loss: 44.2807\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 53.8204 - val_loss: 49.0548\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 52.1433 - val_loss: 44.4027\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.3567 - val_loss: 49.2221\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 52.1816 - val_loss: 44.1131\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5959 - val_loss: 44.4052\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6753 - val_loss: 51.4498\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.9210 - val_loss: 46.1191\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1093 - val_loss: 43.9115\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.0470 - val_loss: 44.9988\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6353 - val_loss: 44.6079\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5568 - val_loss: 44.0981\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4298 - val_loss: 45.2037\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 49.2471 - val_loss: 46.5833\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.2680 - val_loss: 44.7782\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0542 - val_loss: 44.9197\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6816 - val_loss: 43.9628\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.7990 - val_loss: 44.7048\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.2232 - val_loss: 48.3277\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.1136 - val_loss: 45.8507\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.8404 - val_loss: 47.1168\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.7712 - val_loss: 44.0235\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.1585 - val_loss: 44.1729\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.7159 - val_loss: 46.7691\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.8810 - val_loss: 48.8956\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.5029 - val_loss: 48.3940\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.4990 - val_loss: 45.8534\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.0872 - val_loss: 44.6558\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9843 - val_loss: 44.6971\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.9579 - val_loss: 48.3995\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.3677 - val_loss: 44.2270\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.2785 - val_loss: 44.8909\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8196 - val_loss: 46.0279\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.3188 - val_loss: 45.2680\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0506 - val_loss: 44.3849\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.7396 - val_loss: 44.2607\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3327 - val_loss: 44.1731\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3206 - val_loss: 44.7111\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.1978 - val_loss: 46.6819\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 50.3808 - val_loss: 47.8408\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.7486 - val_loss: 46.7603\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.8841 - val_loss: 45.2408\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.4262 - val_loss: 44.9529\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 51.0683 - val_loss: 47.6641\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.3985 - val_loss: 44.1363\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.7455 - val_loss: 52.7495\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 52.1439 - val_loss: 44.2221\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.8022 - val_loss: 44.2229\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5864 - val_loss: 44.9513\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.3980 - val_loss: 44.7182\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 50.3275 - val_loss: 46.5407\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.0295 - val_loss: 47.0774\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.6498 - val_loss: 45.3829\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.7493 - val_loss: 44.2787\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3385 - val_loss: 43.7134\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0304 - val_loss: 45.5140\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5858 - val_loss: 44.6841\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2116 - val_loss: 49.2070\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.4373 - val_loss: 46.3102\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.6179 - val_loss: 43.7787\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6446 - val_loss: 44.5574\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6542 - val_loss: 44.0857\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.8688 - val_loss: 46.6009\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 51.0203 - val_loss: 44.5801\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6406 - val_loss: 45.2712\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8603 - val_loss: 49.1448\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 52.0073 - val_loss: 45.1940\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2209 - val_loss: 44.0366\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3592 - val_loss: 44.0596\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.3533 - val_loss: 46.6805\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.6697 - val_loss: 44.4052\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9238 - val_loss: 44.3759\n",
      "Epoch 10/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 6ms/step - loss: 48.6299 - val_loss: 43.9938\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1283 - val_loss: 44.5066\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.4929 - val_loss: 44.1692\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1226 - val_loss: 44.8611\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.1521 - val_loss: 44.3691\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3457 - val_loss: 44.1341\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7325 - val_loss: 44.3718\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1513 - val_loss: 47.5700\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 50.2945 - val_loss: 46.7673\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.6340 - val_loss: 44.2727\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.8353 - val_loss: 46.4281\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.4253 - val_loss: 44.8508\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.0492 - val_loss: 48.3775\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8958 - val_loss: 44.0235\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8618 - val_loss: 45.4888\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.2728 - val_loss: 45.4650\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6118 - val_loss: 44.6561\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9574 - val_loss: 45.2971\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.2812 - val_loss: 44.0286\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1827 - val_loss: 44.1838\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0243 - val_loss: 44.4931\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6485 - val_loss: 44.0962\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2865 - val_loss: 44.4634\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.1656 - val_loss: 46.8836\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.5426 - val_loss: 44.2378\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 50.6684 - val_loss: 50.3617\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.6638 - val_loss: 44.8398\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8389 - val_loss: 44.4962\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.5370 - val_loss: 44.4579\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 52.1558 - val_loss: 44.7080\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4354 - val_loss: 45.1740\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4539 - val_loss: 45.0620\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1790 - val_loss: 44.6113\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2426 - val_loss: 47.9968\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.5982 - val_loss: 45.9571\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.0166 - val_loss: 44.7141\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5887 - val_loss: 44.2262\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9361 - val_loss: 44.1934\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4613 - val_loss: 46.1774\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.4616 - val_loss: 52.1367\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 52.0784 - val_loss: 44.0771\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 48.3515 - val_loss: 44.0147\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.8154 - val_loss: 44.7267\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.1428 - val_loss: 44.4291\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2264 - val_loss: 44.3776\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8417 - val_loss: 44.0048\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.2278 - val_loss: 45.7170\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.0437 - val_loss: 45.7647\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.5072 - val_loss: 44.2669\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3335 - val_loss: 44.0883\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3799 - val_loss: 43.9868\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5075 - val_loss: 45.9702\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7804 - val_loss: 45.2447\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.2404 - val_loss: 44.0871\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1578 - val_loss: 44.9134\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.4378 - val_loss: 44.3810\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.4690 - val_loss: 45.0686\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.2901 - val_loss: 43.6896\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.4980 - val_loss: 44.5242\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.4947 - val_loss: 44.0091\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5009 - val_loss: 44.4468\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.8594 - val_loss: 44.7940\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.8431 - val_loss: 45.3643\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2696 - val_loss: 46.7406\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.9406 - val_loss: 44.8420\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.9766 - val_loss: 44.5599\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.8785 - val_loss: 44.3403\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.1188 - val_loss: 43.6747\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.9986 - val_loss: 46.4874\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.9893 - val_loss: 43.9017\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0578 - val_loss: 47.3468\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.8578 - val_loss: 44.0251\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5782 - val_loss: 43.9591\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0939 - val_loss: 46.2232\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.8935 - val_loss: 44.5637\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3968 - val_loss: 44.0787\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.0589 - val_loss: 53.0993\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 53.2121 - val_loss: 44.2741\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.2471 - val_loss: 46.1176\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 6ms/step - loss: 48.3023 - val_loss: 47.5529\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.4718 - val_loss: 43.8724\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8345 - val_loss: 46.2368\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.9584 - val_loss: 43.6956\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4983 - val_loss: 46.4024\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.7183 - val_loss: 45.0262\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.1140 - val_loss: 46.7119\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8968 - val_loss: 44.1355\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.3491 - val_loss: 49.1821\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 53.3667 - val_loss: 44.3783\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.1197 - val_loss: 44.8040\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 51.3501 - val_loss: 43.9618\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.4117 - val_loss: 47.2770\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.9982 - val_loss: 44.9954\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.9946 - val_loss: 46.2548\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.4291 - val_loss: 45.0752\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9801 - val_loss: 43.8795\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9542 - val_loss: 44.6830\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6180 - val_loss: 44.1426\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.8411 - val_loss: 43.7314\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.7294 - val_loss: 45.7767\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.7652 - val_loss: 44.3223\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7144 - val_loss: 44.0710\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4079 - val_loss: 45.7789\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.5548 - val_loss: 44.1477\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4456 - val_loss: 46.1877\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.9843 - val_loss: 46.6697\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.6896 - val_loss: 45.9963\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9791 - val_loss: 46.3744\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.6371 - val_loss: 47.7000\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 50.0302 - val_loss: 43.9927\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7672 - val_loss: 44.3301\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.5133 - val_loss: 45.1277\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.2156 - val_loss: 43.8163\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2302 - val_loss: 44.0721\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4583 - val_loss: 44.8475\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6044 - val_loss: 44.8621\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8368 - val_loss: 44.5622\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.9299 - val_loss: 43.7698\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0861 - val_loss: 45.6574\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6325 - val_loss: 44.0238\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.5660 - val_loss: 43.7302\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.2408 - val_loss: 45.0591\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.8047 - val_loss: 44.8264\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.3803 - val_loss: 46.8352\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 50.4610 - val_loss: 44.1310\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 53.5791 - val_loss: 50.4394\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 54.2973 - val_loss: 44.1875\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.4078 - val_loss: 49.7390\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 51.7614 - val_loss: 44.1591\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.7801 - val_loss: 43.8449\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4527 - val_loss: 44.5152\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8505 - val_loss: 44.3175\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3314 - val_loss: 44.0577\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0116 - val_loss: 44.2220\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.4999 - val_loss: 44.1834\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9336 - val_loss: 44.9836\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0563 - val_loss: 44.2962\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.2894 - val_loss: 44.0297\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4703 - val_loss: 44.8120\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7979 - val_loss: 44.0432\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8535 - val_loss: 47.0528\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 50.8292 - val_loss: 47.9140\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6231 - val_loss: 48.8572\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 53.4433 - val_loss: 43.9695\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.8540 - val_loss: 51.3969\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.6196 - val_loss: 45.1280\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.6316 - val_loss: 43.8394\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4077 - val_loss: 44.0646\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.9551 - val_loss: 44.0107\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 51.7341 - val_loss: 45.7722\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 53.8806 - val_loss: 49.3400\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8667 - val_loss: 44.7924\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.6712 - val_loss: 45.0933\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.9736 - val_loss: 45.2221\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5917 - val_loss: 44.1326\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0300 - val_loss: 43.6343\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1251 - val_loss: 45.0790\n",
      "Epoch 17/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 6ms/step - loss: 49.8036 - val_loss: 48.9001\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.4983 - val_loss: 44.4028\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.3242 - val_loss: 43.8679\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6968 - val_loss: 44.1983\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.3045 - val_loss: 43.7745\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1166 - val_loss: 44.7677\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.2439 - val_loss: 47.3972\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 50.0340 - val_loss: 44.1258\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.6638 - val_loss: 44.4331\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.7555 - val_loss: 43.7358\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.2771 - val_loss: 44.3296\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3088 - val_loss: 46.6242\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.6553 - val_loss: 45.6065\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3168 - val_loss: 44.7472\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.4817 - val_loss: 45.3346\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.5299 - val_loss: 47.2424\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 51.9549 - val_loss: 43.8052\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1205 - val_loss: 44.1759\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.0060 - val_loss: 44.2206\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1913 - val_loss: 44.5345\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4342 - val_loss: 45.4648\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4028 - val_loss: 44.6643\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5561 - val_loss: 45.4551\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.7334 - val_loss: 44.5655\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.1336 - val_loss: 45.4711\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0062 - val_loss: 43.7435\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.4129 - val_loss: 46.1256\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.1538 - val_loss: 44.7557\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5473 - val_loss: 44.0229\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.5603 - val_loss: 46.4810\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.1873 - val_loss: 45.0348\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4970 - val_loss: 44.0627\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.7909 - val_loss: 44.0241\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3392 - val_loss: 44.1726\n",
      "10/10 [==============================] - 0s 990us/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 48.4096 - val_loss: 44.4601\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6657 - val_loss: 45.8471\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.3721 - val_loss: 43.9583\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.7295 - val_loss: 44.1326\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4198 - val_loss: 44.6790\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3634 - val_loss: 45.7973\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.5984 - val_loss: 43.9595\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.2168 - val_loss: 46.2102\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1799 - val_loss: 44.6158\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2487 - val_loss: 44.3768\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 49.1495 - val_loss: 44.5953\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.4756 - val_loss: 43.7442\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5538 - val_loss: 44.3204\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.9830 - val_loss: 49.7738\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.6764 - val_loss: 46.3908\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5392 - val_loss: 44.0755\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7992 - val_loss: 46.1762\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.2087 - val_loss: 47.4259\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0642 - val_loss: 45.7243\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 50.0021 - val_loss: 44.5086\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.7498 - val_loss: 49.8963\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.3090 - val_loss: 44.6310\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 53.2065 - val_loss: 46.2698\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8445 - val_loss: 45.9718\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.6050 - val_loss: 44.2014\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.7710 - val_loss: 44.2814\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8197 - val_loss: 45.9066\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8314 - val_loss: 45.5730\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.9795 - val_loss: 44.3109\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.4372 - val_loss: 45.3412\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.5002 - val_loss: 43.8401\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.5590 - val_loss: 46.7697\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 52.1989 - val_loss: 44.1348\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.6297 - val_loss: 48.6147\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 52.6515 - val_loss: 44.1799\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.8715 - val_loss: 44.2661\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.5536 - val_loss: 44.5381\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8570 - val_loss: 43.8001\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8819 - val_loss: 44.1692\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.1026 - val_loss: 43.8968\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4095 - val_loss: 43.8082\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.0624 - val_loss: 46.4176\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0566 - val_loss: 44.1623\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3621 - val_loss: 43.9114\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.3808 - val_loss: 44.8341\n",
      "Epoch 46/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 49.7801 - val_loss: 48.1759\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 52.9822 - val_loss: 45.7745\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 50.0590 - val_loss: 53.7337\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.3750 - val_loss: 46.1262\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7447 - val_loss: 44.4626\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 50.8137 - val_loss: 44.4516\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0267 - val_loss: 44.8285\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.2041 - val_loss: 44.4204\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5092 - val_loss: 44.1291\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4678 - val_loss: 44.4089\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1805 - val_loss: 44.3099\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.6731 - val_loss: 45.5787\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.9972 - val_loss: 45.1341\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.2846 - val_loss: 46.4202\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.8729 - val_loss: 45.9393\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.3069 - val_loss: 45.3153\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.3249 - val_loss: 43.8982\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.5844 - val_loss: 44.5909\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.8423 - val_loss: 45.0891\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4888 - val_loss: 44.3983\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.3585 - val_loss: 43.8324\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5628 - val_loss: 44.1520\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.5110 - val_loss: 44.0802\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 49.1177 - val_loss: 44.6642\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.6057 - val_loss: 44.0713\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.1869 - val_loss: 45.8387\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.7188 - val_loss: 44.2038\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6363 - val_loss: 44.0165\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.0525 - val_loss: 43.8332\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.3167 - val_loss: 43.9557\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.4015 - val_loss: 44.1799\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.1851 - val_loss: 46.0477\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8739 - val_loss: 43.9906\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.7008 - val_loss: 46.3771\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.9734 - val_loss: 51.4191\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.7785 - val_loss: 50.0109\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.6482 - val_loss: 44.9170\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8223 - val_loss: 45.5948\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2038 - val_loss: 44.0210\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.2912 - val_loss: 44.3996\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.2850 - val_loss: 44.2910\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8373 - val_loss: 43.9613\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.2617 - val_loss: 44.8574\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.4335 - val_loss: 44.2206\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.0598 - val_loss: 44.1402\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 53.4508 - val_loss: 45.4285\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 53.2495 - val_loss: 45.7292\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 52.0313 - val_loss: 50.4677\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.6115 - val_loss: 46.9365\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0559 - val_loss: 44.0756\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.4213 - val_loss: 44.2990\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9211 - val_loss: 45.8123\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.4502 - val_loss: 43.9959\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.3332 - val_loss: 43.6709\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.5268 - val_loss: 43.8566\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 48.1176 - val_loss: 44.2846\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.2748 - val_loss: 44.0732\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.7407 - val_loss: 43.8227\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.9295 - val_loss: 44.0854\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7971 - val_loss: 43.8349\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.1541 - val_loss: 44.3750\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2147 - val_loss: 44.5082\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3865 - val_loss: 43.9566\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3545 - val_loss: 43.8788\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8485 - val_loss: 44.2334\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6857 - val_loss: 44.8793\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.5852 - val_loss: 43.8141\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.8672 - val_loss: 43.9905\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.9754 - val_loss: 44.4780\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.6796 - val_loss: 45.7029\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.9354 - val_loss: 49.4272\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.3057 - val_loss: 44.0087\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.5928 - val_loss: 44.4841\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.6048 - val_loss: 44.2051\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3224 - val_loss: 43.8008\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2404 - val_loss: 44.2464\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.9260 - val_loss: 43.8017\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6236 - val_loss: 44.0600\n",
      "Epoch 24/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 4ms/step - loss: 49.5132 - val_loss: 49.9467\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.8188 - val_loss: 47.2826\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5472 - val_loss: 44.5256\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.3985 - val_loss: 44.5511\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.0280 - val_loss: 44.1317\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4954 - val_loss: 43.8098\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.2060 - val_loss: 44.0835\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.2600 - val_loss: 47.0591\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.5673 - val_loss: 44.0562\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.7075 - val_loss: 45.9971\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8552 - val_loss: 44.1591\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 49.9007 - val_loss: 44.3729\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.4919 - val_loss: 45.3634\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1254 - val_loss: 43.9640\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6576 - val_loss: 44.2788\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5806 - val_loss: 44.2437\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6455 - val_loss: 45.0939\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.2520 - val_loss: 43.6658\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.7424 - val_loss: 44.6148\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6317 - val_loss: 44.9189\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.1937 - val_loss: 44.0828\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1161 - val_loss: 47.0333\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.8642 - val_loss: 43.9156\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 50.2728 - val_loss: 47.1542\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5337 - val_loss: 44.1423\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7585 - val_loss: 44.1799\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0321 - val_loss: 44.4514\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 49.4001 - val_loss: 44.0952\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.9649 - val_loss: 44.4581\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.3195 - val_loss: 45.0790\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.9908 - val_loss: 45.5249\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.5241 - val_loss: 44.7115\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6679 - val_loss: 44.2283\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1808 - val_loss: 47.2773\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.5722 - val_loss: 51.3066\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.6591 - val_loss: 43.9200\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.0763 - val_loss: 44.6935\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 51.2797 - val_loss: 44.5349\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3494 - val_loss: 43.7790\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4871 - val_loss: 43.8674\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.2436 - val_loss: 46.1376\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.4329 - val_loss: 44.1277\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.2776 - val_loss: 45.2189\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1896 - val_loss: 45.0231\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1533 - val_loss: 47.0469\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.8596 - val_loss: 44.0312\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1754 - val_loss: 45.7535\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.8794 - val_loss: 44.2826\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 50.7279 - val_loss: 43.6233\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.7018 - val_loss: 46.2455\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 51.7648 - val_loss: 48.5630\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.9884 - val_loss: 46.3582\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.3356 - val_loss: 43.8343\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.9299 - val_loss: 46.8619\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8535 - val_loss: 44.0932\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.7610 - val_loss: 48.9564\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.4335 - val_loss: 43.7661\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2077 - val_loss: 44.0027\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.6232 - val_loss: 48.9935\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8155 - val_loss: 47.5689\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 50.6564 - val_loss: 47.7016\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.2727 - val_loss: 43.7815\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.9204 - val_loss: 44.2285\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.8784 - val_loss: 51.3976\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 50.2374 - val_loss: 44.6165\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6643 - val_loss: 45.6647\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 50.4577 - val_loss: 43.9048\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.7626 - val_loss: 52.7488\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.5171 - val_loss: 44.6277\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1707 - val_loss: 44.6316\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2217 - val_loss: 44.1372\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.2119 - val_loss: 44.7104\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0920 - val_loss: 44.7226\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4663 - val_loss: 43.7433\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.6248 - val_loss: 44.9645\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.5541 - val_loss: 58.8449\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 55.5583 - val_loss: 53.1437\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 52.5358 - val_loss: 44.6616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2657 - val_loss: 44.9989\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5579 - val_loss: 44.0994\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.2535 - val_loss: 46.0658\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.8520 - val_loss: 43.9602\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.0812 - val_loss: 44.4492\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8170 - val_loss: 44.3094\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.6820 - val_loss: 44.3155\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3822 - val_loss: 44.1106\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 50.3312 - val_loss: 52.2770\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.1554 - val_loss: 43.9165\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.1601 - val_loss: 43.6941\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4050 - val_loss: 44.0041\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.4056 - val_loss: 48.5017\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8080 - val_loss: 44.4125\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2734 - val_loss: 43.7657\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.6657 - val_loss: 46.8070\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.7536 - val_loss: 44.5410\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.7196 - val_loss: 46.2032\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 52.3522 - val_loss: 44.8633\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.6406 - val_loss: 47.3193\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.6400 - val_loss: 43.6610\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.7774 - val_loss: 44.3037\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6758 - val_loss: 43.9858\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0551 - val_loss: 44.7248\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4882 - val_loss: 44.2159\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2891 - val_loss: 44.0179\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 48.7889 - val_loss: 45.1112\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.2179 - val_loss: 45.3064\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.3759 - val_loss: 44.2205\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5780 - val_loss: 43.9833\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5884 - val_loss: 43.9247\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.4074 - val_loss: 44.8840\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.8330 - val_loss: 44.2804\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 50.6059 - val_loss: 49.6478\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9297 - val_loss: 44.2991\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.3146 - val_loss: 43.9626\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8144 - val_loss: 46.2670\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5618 - val_loss: 45.5143\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.7421 - val_loss: 48.2316\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.0813 - val_loss: 44.2445\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2856 - val_loss: 45.8645\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7623 - val_loss: 47.7118\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.9648 - val_loss: 45.2250\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.2014 - val_loss: 43.9025\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.4031 - val_loss: 45.0365\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.3441 - val_loss: 45.6258\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9201 - val_loss: 44.1580\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.3676 - val_loss: 44.3711\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7591 - val_loss: 48.3601\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 50.1278 - val_loss: 43.8026\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9969 - val_loss: 45.4934\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.5281 - val_loss: 53.9962\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 53.1835 - val_loss: 43.8201\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6823 - val_loss: 49.8456\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.2788 - val_loss: 46.1303\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.1939 - val_loss: 45.0583\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.5597 - val_loss: 44.5808\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.5918 - val_loss: 44.4893\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1950 - val_loss: 44.0592\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.8441 - val_loss: 47.5914\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.2681 - val_loss: 50.8595\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.4012 - val_loss: 49.7846\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 54.7189 - val_loss: 47.2688\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 58.3820 - val_loss: 48.3733\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.9640 - val_loss: 44.1379\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.0923 - val_loss: 45.0841\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.5355 - val_loss: 44.4962\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.8290 - val_loss: 46.5379\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.7088 - val_loss: 43.8178\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8300 - val_loss: 44.0833\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0761 - val_loss: 45.4845\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9456 - val_loss: 44.1866\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0264 - val_loss: 43.9183\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.9054 - val_loss: 48.3176\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.4489 - val_loss: 43.8805\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1922 - val_loss: 43.6883\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.2353 - val_loss: 45.2640\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.7673 - val_loss: 44.3662\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2698 - val_loss: 43.7786\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 6ms/step - loss: 49.2679 - val_loss: 44.1807\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9068 - val_loss: 44.3765\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7622 - val_loss: 43.9941\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.6459 - val_loss: 45.6860\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7963 - val_loss: 44.3813\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3213 - val_loss: 44.5047\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1287 - val_loss: 44.3992\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7042 - val_loss: 44.1860\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5482 - val_loss: 46.8039\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.6161 - val_loss: 45.6523\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.2700 - val_loss: 46.1909\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.2077 - val_loss: 44.1216\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.0364 - val_loss: 46.7853\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.0871 - val_loss: 46.2543\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.7512 - val_loss: 48.4366\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.5945 - val_loss: 46.1430\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.0917 - val_loss: 44.0859\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1915 - val_loss: 43.9568\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.5498 - val_loss: 44.5772\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.0660 - val_loss: 44.8448\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.3525 - val_loss: 47.0763\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.8837 - val_loss: 43.7206\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4453 - val_loss: 44.0850\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.3178 - val_loss: 45.0576\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.5886 - val_loss: 43.7843\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.1834 - val_loss: 45.5179\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.2022 - val_loss: 45.6504\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.5065 - val_loss: 48.2582\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.9465 - val_loss: 44.2566\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1962 - val_loss: 43.9770\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.0055 - val_loss: 43.8772\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.2871 - val_loss: 44.2658\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.4633 - val_loss: 44.2205\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.3552 - val_loss: 43.7381\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.3084 - val_loss: 45.2959\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.0817 - val_loss: 47.0635\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.6345 - val_loss: 45.0618\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.0563 - val_loss: 45.2942\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.0211 - val_loss: 43.9412\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6133 - val_loss: 43.7653\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.7069 - val_loss: 43.7590\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.8878 - val_loss: 45.0135\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.6082 - val_loss: 48.3192\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 50.7581 - val_loss: 45.7244\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.2668 - val_loss: 44.2769\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.0698 - val_loss: 46.8771\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.6053 - val_loss: 45.6926\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.9530 - val_loss: 46.6128\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.6359 - val_loss: 44.4790\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0492 - val_loss: 44.1890\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.4192 - val_loss: 48.4196\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.2690 - val_loss: 44.9519\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.5152 - val_loss: 44.2046\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9226 - val_loss: 44.3780\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.9425 - val_loss: 43.9248\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.7284 - val_loss: 43.7900\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0398 - val_loss: 44.0355\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.4023 - val_loss: 44.4986\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2895 - val_loss: 44.6546\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4186 - val_loss: 44.4264\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.5496 - val_loss: 43.9398\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6619 - val_loss: 44.5216\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.0096 - val_loss: 44.9240\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0253 - val_loss: 44.4005\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7856 - val_loss: 45.1156\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.7998 - val_loss: 49.3820\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.2638 - val_loss: 43.8256\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.7624 - val_loss: 47.6030\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.8725 - val_loss: 45.3738\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 50.7065 - val_loss: 51.3598\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 51.3934 - val_loss: 45.8391\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.7916 - val_loss: 48.0683\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.3883 - val_loss: 45.7239\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 51.3945 - val_loss: 44.2428\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 52.2153 - val_loss: 50.4868\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.3796 - val_loss: 44.3892\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.2552 - val_loss: 46.8495\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.3607 - val_loss: 43.7338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5317 - val_loss: 44.0898\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9767 - val_loss: 44.0939\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.1179 - val_loss: 44.4809\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 50.9111 - val_loss: 44.9678\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.9035 - val_loss: 43.9958\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 48.3013 - val_loss: 43.7177\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.6742 - val_loss: 43.8495\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3354 - val_loss: 43.9992\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.1585 - val_loss: 44.4664\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.7138 - val_loss: 45.0429\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4897 - val_loss: 44.4134\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.6836 - val_loss: 44.9635\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.1849 - val_loss: 44.1557\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.9277 - val_loss: 43.9229\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5350 - val_loss: 44.7941\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1816 - val_loss: 43.9972\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.7972 - val_loss: 43.9480\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.6348 - val_loss: 43.7672\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.3103 - val_loss: 44.7834\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9126 - val_loss: 44.6468\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.3995 - val_loss: 44.7717\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1820 - val_loss: 44.2093\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8857 - val_loss: 46.3308\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3302 - val_loss: 45.0059\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.3554 - val_loss: 46.6337\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.2310 - val_loss: 44.3234\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4528 - val_loss: 44.9955\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.0181 - val_loss: 47.6114\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7451 - val_loss: 45.0640\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 50.6754 - val_loss: 44.1284\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.7448 - val_loss: 43.7611\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.3988 - val_loss: 47.0823\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6910 - val_loss: 44.6350\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7703 - val_loss: 47.8778\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 50.9321 - val_loss: 49.0464\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.0738 - val_loss: 44.2045\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6581 - val_loss: 43.7397\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.5503 - val_loss: 44.6681\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.8011 - val_loss: 44.8841\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2241 - val_loss: 44.0065\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.1888 - val_loss: 44.1069\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8143 - val_loss: 43.7268\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.9206 - val_loss: 43.9290\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1644 - val_loss: 49.1050\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.1987 - val_loss: 43.6144\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3391 - val_loss: 44.1234\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.5916 - val_loss: 44.5738\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5235 - val_loss: 44.0066\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3877 - val_loss: 43.6357\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0602 - val_loss: 44.4966\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3956 - val_loss: 43.7564\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.3471 - val_loss: 44.0574\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.7766 - val_loss: 43.9538\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.9741 - val_loss: 44.6174\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.2931 - val_loss: 45.1887\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 50.4156 - val_loss: 43.7259\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1044 - val_loss: 45.3950\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.2807 - val_loss: 43.7443\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.1516 - val_loss: 47.3785\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.2063 - val_loss: 44.3135\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.2722 - val_loss: 49.4467\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.4552 - val_loss: 44.5032\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1465 - val_loss: 50.8361\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.8084 - val_loss: 43.7521\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.9498 - val_loss: 45.1241\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4915 - val_loss: 47.8876\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1656 - val_loss: 44.5669\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.5541 - val_loss: 45.1682\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2162 - val_loss: 43.6153\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.2262 - val_loss: 45.2044\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4459 - val_loss: 47.4609\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.6345 - val_loss: 47.9865\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.2338 - val_loss: 43.8293\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5850 - val_loss: 44.5153\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.2425 - val_loss: 44.1099\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.6757 - val_loss: 45.7509\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.4442 - val_loss: 48.4193\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.4733 - val_loss: 45.4084\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0232 - val_loss: 45.7216\n",
      "Epoch 38/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0838 - val_loss: 44.6869\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 52.8985 - val_loss: 45.4186\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.6192 - val_loss: 44.4960\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.1184 - val_loss: 45.8769\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.8930 - val_loss: 44.5355\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0916 - val_loss: 43.6231\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0519 - val_loss: 44.1712\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1212 - val_loss: 44.0825\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.3357 - val_loss: 44.0599\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.7575 - val_loss: 44.4164\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8712 - val_loss: 44.5663\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1589 - val_loss: 44.3617\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.2479 - val_loss: 45.5316\n",
      "10/10 [==============================] - 0s 894us/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 48.2247 - val_loss: 44.0659\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.8203 - val_loss: 43.6857\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0337 - val_loss: 45.0193\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4710 - val_loss: 44.8785\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.7469 - val_loss: 43.9348\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.1408 - val_loss: 48.1868\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.2411 - val_loss: 48.4055\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.1592 - val_loss: 46.9065\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2615 - val_loss: 43.8792\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.7984 - val_loss: 44.6048\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.7078 - val_loss: 43.8048\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.4429 - val_loss: 46.9724\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.3596 - val_loss: 44.2448\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.9536 - val_loss: 47.2585\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0239 - val_loss: 44.5683\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.3583 - val_loss: 44.6563\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.1641 - val_loss: 43.9993\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 52.2951 - val_loss: 45.4315\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.2182 - val_loss: 44.3494\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9763 - val_loss: 46.4002\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.0356 - val_loss: 45.2280\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.3367 - val_loss: 44.5876\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.8986 - val_loss: 45.7703\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.4686 - val_loss: 46.2749\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.2320 - val_loss: 44.3532\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0265 - val_loss: 43.8671\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2262 - val_loss: 43.8368\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4938 - val_loss: 44.4967\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.0623 - val_loss: 46.0693\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.1575 - val_loss: 46.5047\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5575 - val_loss: 44.4368\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.9449 - val_loss: 44.9408\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3023 - val_loss: 43.8703\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8132 - val_loss: 43.8760\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.6361 - val_loss: 45.3737\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8353 - val_loss: 44.2929\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3419 - val_loss: 44.3623\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0440 - val_loss: 45.4329\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8349 - val_loss: 47.0627\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5206 - val_loss: 44.1910\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6850 - val_loss: 44.4815\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3240 - val_loss: 43.6205\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.7400 - val_loss: 43.9669\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.9941 - val_loss: 44.5148\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.5223 - val_loss: 44.0355\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.6600 - val_loss: 44.1016\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3750 - val_loss: 44.0520\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.2500 - val_loss: 46.6948\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.0181 - val_loss: 44.0492\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4616 - val_loss: 46.8681\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 49.0196 - val_loss: 43.8615\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2823 - val_loss: 44.0540\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.8958 - val_loss: 50.6861\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.9451 - val_loss: 43.9909\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.4649 - val_loss: 45.0923\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.7764 - val_loss: 44.5772\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.4869 - val_loss: 46.3859\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.8079 - val_loss: 43.8927\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.0917 - val_loss: 44.9960\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.9483 - val_loss: 45.2064\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4689 - val_loss: 43.8454\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.8953 - val_loss: 45.0152\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.0670 - val_loss: 44.2122\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3794 - val_loss: 43.9565\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4986 - val_loss: 47.6109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.9301 - val_loss: 44.4557\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.4833 - val_loss: 44.2929\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.4320 - val_loss: 44.0231\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8112 - val_loss: 45.0231\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3762 - val_loss: 44.7367\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4292 - val_loss: 44.7439\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5787 - val_loss: 43.7063\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1439 - val_loss: 43.8123\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.5843 - val_loss: 48.6454\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.6543 - val_loss: 46.1816\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7973 - val_loss: 43.7005\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1340 - val_loss: 44.4003\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7649 - val_loss: 43.8905\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1273 - val_loss: 44.0958\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2727 - val_loss: 43.9291\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.0195 - val_loss: 44.0231\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.2356 - val_loss: 45.1161\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.8857 - val_loss: 45.2647\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.3268 - val_loss: 45.7111\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8651 - val_loss: 44.0999\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2534 - val_loss: 44.4772\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.8017 - val_loss: 49.8150\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 51.9653 - val_loss: 44.2051\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.8659 - val_loss: 44.9537\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2831 - val_loss: 44.2584\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3698 - val_loss: 44.1751\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6018 - val_loss: 49.0386\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0221 - val_loss: 44.5216\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5561 - val_loss: 44.9302\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8103 - val_loss: 44.7660\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8052 - val_loss: 45.3032\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2962 - val_loss: 43.9079\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.1218 - val_loss: 44.0056\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.1701 - val_loss: 44.7901\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.2132 - val_loss: 50.7493\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.8399 - val_loss: 45.7778\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.1399 - val_loss: 43.4474\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.4484 - val_loss: 45.2430\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7459 - val_loss: 50.2149\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 50.4409 - val_loss: 43.6978\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.9520 - val_loss: 47.0092\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5061 - val_loss: 43.9925\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5274 - val_loss: 44.0605\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0563 - val_loss: 43.9020\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4365 - val_loss: 46.0465\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.2668 - val_loss: 43.9965\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.4854 - val_loss: 47.7925\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.0045 - val_loss: 45.8804\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1067 - val_loss: 49.8115\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.2886 - val_loss: 44.3122\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1681 - val_loss: 43.8353\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4825 - val_loss: 46.7737\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 50.8680 - val_loss: 45.7213\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.9285 - val_loss: 46.9377\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6539 - val_loss: 44.3303\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7199 - val_loss: 47.7611\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.2590 - val_loss: 44.4174\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 50.6857 - val_loss: 44.3635\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.7626 - val_loss: 43.5199\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.1637 - val_loss: 48.2743\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 51.5528 - val_loss: 44.2878\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.0983 - val_loss: 44.6146\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7640 - val_loss: 44.2635\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9202 - val_loss: 45.9197\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7202 - val_loss: 43.8337\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9033 - val_loss: 43.9604\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.3939 - val_loss: 45.6401\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.2916 - val_loss: 45.3280\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 52.3509 - val_loss: 46.5295\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.6867 - val_loss: 44.2049\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 50.0756 - val_loss: 45.5526\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0798 - val_loss: 44.2011\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.8918 - val_loss: 47.8510\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.4419 - val_loss: 46.5625\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3606 - val_loss: 45.2563\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9639 - val_loss: 45.5279\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2549 - val_loss: 44.3046\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.4451 - val_loss: 44.5295\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1437 - val_loss: 45.4889\n",
      "Epoch 45/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3166 - val_loss: 44.6257\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1911 - val_loss: 46.6781\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.5791 - val_loss: 45.3182\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 51.3987 - val_loss: 46.8956\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.6558 - val_loss: 43.8534\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3063 - val_loss: 44.3920\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.2682 - val_loss: 45.8080\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8193 - val_loss: 44.2764\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3664 - val_loss: 44.1787\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0967 - val_loss: 45.3407\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.3088 - val_loss: 45.6005\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.3414 - val_loss: 46.5553\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.2024 - val_loss: 45.8080\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6759 - val_loss: 44.2982\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.9933 - val_loss: 48.0440\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.9333 - val_loss: 44.0180\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8308 - val_loss: 44.7415\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5412 - val_loss: 43.8687\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7778 - val_loss: 44.8949\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.5773 - val_loss: 44.0497\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3494 - val_loss: 45.3482\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0578 - val_loss: 44.1520\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2543 - val_loss: 44.2570\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1591 - val_loss: 45.9223\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.5697 - val_loss: 47.3573\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 52.4936 - val_loss: 52.6119\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 52.6152 - val_loss: 49.7955\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.8672 - val_loss: 46.1727\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5073 - val_loss: 44.1113\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0180 - val_loss: 45.7777\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.4851 - val_loss: 45.1942\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6301 - val_loss: 44.5014\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9222 - val_loss: 45.4605\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.7774 - val_loss: 45.1194\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4129 - val_loss: 44.3562\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.7217 - val_loss: 43.9910\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.6569 - val_loss: 45.6671\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3266 - val_loss: 44.5214\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.2734 - val_loss: 43.8695\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1453 - val_loss: 43.6649\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.3556 - val_loss: 44.3825\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 50.1812 - val_loss: 44.4698\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 52.8474 - val_loss: 44.8792\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.0896 - val_loss: 44.3875\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.4291 - val_loss: 50.9324\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 54.2208 - val_loss: 52.3923\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 52.3767 - val_loss: 44.3708\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2222 - val_loss: 46.2019\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.3947 - val_loss: 45.4541\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.3392 - val_loss: 43.9723\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.1199 - val_loss: 44.1067\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.0064 - val_loss: 44.4869\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.6974 - val_loss: 44.8839\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6662 - val_loss: 43.9406\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.9363 - val_loss: 44.1898\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.9422 - val_loss: 45.2928\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 49.9092 - val_loss: 47.4760\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.3189 - val_loss: 46.3872\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 50.6151 - val_loss: 44.4775\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4649 - val_loss: 43.9626\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4472 - val_loss: 43.9892\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.3762 - val_loss: 44.8223\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.2512 - val_loss: 45.8665\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.6289 - val_loss: 44.4404\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1355 - val_loss: 44.0918\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.8632 - val_loss: 46.6300\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.0263 - val_loss: 47.3173\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.9859 - val_loss: 48.3957\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.7400 - val_loss: 43.8015\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.0942 - val_loss: 44.7728\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.3518 - val_loss: 45.3379\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.1427 - val_loss: 48.7938\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.5606 - val_loss: 48.6995\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.1976 - val_loss: 44.7319\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4686 - val_loss: 45.7387\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.1294 - val_loss: 46.7873\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.9820 - val_loss: 47.8805\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9610 - val_loss: 44.8323\n",
      "Epoch 23/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 49.6664 - val_loss: 43.7927\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3213 - val_loss: 44.3577\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4881 - val_loss: 43.8463\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0097 - val_loss: 47.3360\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.1733 - val_loss: 47.6800\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.1142 - val_loss: 47.1531\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5463 - val_loss: 46.6750\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1131 - val_loss: 44.1885\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.0800 - val_loss: 48.4426\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.7932 - val_loss: 45.2136\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3486 - val_loss: 45.3440\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8563 - val_loss: 43.7943\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4489 - val_loss: 44.2380\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6098 - val_loss: 44.0243\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1887 - val_loss: 44.4538\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.7771 - val_loss: 45.0449\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.9442 - val_loss: 44.5992\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5924 - val_loss: 44.0122\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.5389 - val_loss: 44.2619\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9357 - val_loss: 44.0612\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 48.0515 - val_loss: 44.2114\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2751 - val_loss: 44.8478\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.5186 - val_loss: 44.4671\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.1093 - val_loss: 59.4994\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.1681 - val_loss: 45.3066\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1865 - val_loss: 44.8120\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.5288 - val_loss: 44.0682\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3284 - val_loss: 44.5886\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 48.7750 - val_loss: 45.6199\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.1497 - val_loss: 44.0210\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1088 - val_loss: 45.7735\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.9881 - val_loss: 44.3690\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1784 - val_loss: 44.3202\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.1920 - val_loss: 47.7808\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.8708 - val_loss: 44.7392\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.9513 - val_loss: 53.9073\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 52.6301 - val_loss: 50.7747\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.2397 - val_loss: 44.0116\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1137 - val_loss: 46.0912\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.5867 - val_loss: 44.8167\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1489 - val_loss: 44.2112\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.1477 - val_loss: 44.4812\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4408 - val_loss: 44.3990\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.4354 - val_loss: 44.4196\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2589 - val_loss: 43.9502\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 48.2042 - val_loss: 49.3540\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.0804 - val_loss: 49.7204\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.3034 - val_loss: 47.1886\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.6608 - val_loss: 44.0256\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.1259 - val_loss: 46.0322\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4534 - val_loss: 44.5217\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.2184 - val_loss: 46.4117\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.4986 - val_loss: 46.7723\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 53.6171 - val_loss: 44.2146\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.5068 - val_loss: 49.1655\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.5423 - val_loss: 44.6032\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.4872 - val_loss: 44.2561\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1995 - val_loss: 43.6870\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4380 - val_loss: 45.8780\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.7624 - val_loss: 43.8566\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.7794 - val_loss: 44.1991\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3811 - val_loss: 44.8672\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4345 - val_loss: 44.0005\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.0846 - val_loss: 44.4732\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 50.4511 - val_loss: 43.8316\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.7725 - val_loss: 44.4836\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6486 - val_loss: 44.9458\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.0384 - val_loss: 44.3301\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.1329 - val_loss: 45.1792\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.6018 - val_loss: 45.7834\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.2171 - val_loss: 44.2730\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.7809 - val_loss: 44.3226\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 50.6262 - val_loss: 46.2851\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.2008 - val_loss: 58.8034\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 52.9698 - val_loss: 52.7127\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.5104 - val_loss: 44.8947\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7165 - val_loss: 43.5670\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6951 - val_loss: 43.6883\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 49.4439 - val_loss: 50.2195\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.9157 - val_loss: 46.1376\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.9032 - val_loss: 45.0930\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.0032 - val_loss: 47.4478\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.4166 - val_loss: 44.0306\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1089 - val_loss: 44.5386\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.4876 - val_loss: 44.1266\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8713 - val_loss: 44.4324\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.8259 - val_loss: 44.1179\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.7166 - val_loss: 44.0655\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 52.8717 - val_loss: 45.0680\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8678 - val_loss: 45.3727\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.1297 - val_loss: 46.5299\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0604 - val_loss: 43.9275\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5300 - val_loss: 44.5416\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9771 - val_loss: 45.8630\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.9531 - val_loss: 44.3297\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4156 - val_loss: 47.6974\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.0588 - val_loss: 45.5457\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.3421 - val_loss: 44.2716\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.5663 - val_loss: 44.6732\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.3640 - val_loss: 44.1283\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.3872 - val_loss: 44.1087\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1094 - val_loss: 44.5156\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.7859 - val_loss: 47.0256\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.3851 - val_loss: 45.8037\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3336 - val_loss: 44.5209\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5224 - val_loss: 45.7949\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.0188 - val_loss: 44.2024\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 52.4359 - val_loss: 45.6879\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 50.8460 - val_loss: 44.5277\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6142 - val_loss: 45.8225\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.3148 - val_loss: 44.4735\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.3974 - val_loss: 46.0314\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.0750 - val_loss: 44.1652\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.4745 - val_loss: 43.8949\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.0730 - val_loss: 44.2482\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8936 - val_loss: 45.4953\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.3254 - val_loss: 44.0810\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3774 - val_loss: 47.1434\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.1663 - val_loss: 46.2531\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6693 - val_loss: 44.0201\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6170 - val_loss: 50.3529\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.1389 - val_loss: 43.8715\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8464 - val_loss: 46.0746\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.5989 - val_loss: 44.0140\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.9588 - val_loss: 44.8934\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5836 - val_loss: 45.6473\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5430 - val_loss: 43.5198\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9374 - val_loss: 44.9446\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 48.6410 - val_loss: 44.5796\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 50.7867 - val_loss: 65.7602\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 54.0281 - val_loss: 50.9054\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.5003 - val_loss: 43.8071\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8529 - val_loss: 45.0106\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3896 - val_loss: 47.7542\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9472 - val_loss: 44.0868\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3082 - val_loss: 43.9720\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.3076 - val_loss: 44.0659\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2038 - val_loss: 45.9194\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5481 - val_loss: 43.9668\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3952 - val_loss: 45.6146\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.5401 - val_loss: 44.4218\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.9357 - val_loss: 46.2040\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.2235 - val_loss: 44.0185\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1491 - val_loss: 44.0200\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8062 - val_loss: 44.3848\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5604 - val_loss: 43.9986\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1769 - val_loss: 44.0954\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.5298 - val_loss: 45.3421\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9848 - val_loss: 44.5118\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.9012 - val_loss: 43.9714\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.6758 - val_loss: 44.0317\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 52.8504 - val_loss: 43.9279\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.2654 - val_loss: 44.0137\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.0359 - val_loss: 43.9399\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.9377 - val_loss: 44.2384\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.3484 - val_loss: 45.5669\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1641 - val_loss: 44.5966\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8326 - val_loss: 44.4932\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6064 - val_loss: 44.8516\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.2747 - val_loss: 45.1399\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.6515 - val_loss: 52.3909\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 52.5249 - val_loss: 44.1435\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3060 - val_loss: 45.8081\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.7690 - val_loss: 44.0542\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3204 - val_loss: 45.0109\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6074 - val_loss: 44.6973\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.9908 - val_loss: 43.6353\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.7818 - val_loss: 48.7536\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 50.4366 - val_loss: 48.5429\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.6394 - val_loss: 45.8057\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2641 - val_loss: 44.1181\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0909 - val_loss: 43.9080\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.0603 - val_loss: 45.9436\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 52.5364 - val_loss: 48.3398\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.6239 - val_loss: 43.8258\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.3161 - val_loss: 43.9128\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.7093 - val_loss: 44.0374\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.2932 - val_loss: 44.9708\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 48.5135 - val_loss: 45.1181\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.6258 - val_loss: 45.1197\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.0043 - val_loss: 43.9342\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.7760 - val_loss: 44.8971\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 50.3833 - val_loss: 46.1749\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.4465 - val_loss: 45.7150\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.8775 - val_loss: 45.6027\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.4317 - val_loss: 44.5004\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.8489 - val_loss: 45.3350\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 52.8047 - val_loss: 44.2658\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.4232 - val_loss: 43.7903\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.2660 - val_loss: 45.8081\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.3376 - val_loss: 43.7318\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.7000 - val_loss: 44.7446\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7756 - val_loss: 44.5213\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0069 - val_loss: 44.1606\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0129 - val_loss: 44.0680\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.0114 - val_loss: 44.3141\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4549 - val_loss: 44.1931\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.7503 - val_loss: 44.2403\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6425 - val_loss: 43.7120\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 48.2318 - val_loss: 44.2279\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.2064 - val_loss: 44.4050\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0374 - val_loss: 43.8481\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5065 - val_loss: 43.8743\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6685 - val_loss: 45.1975\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1011 - val_loss: 44.3900\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4798 - val_loss: 44.6718\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.3355 - val_loss: 47.5607\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.0044 - val_loss: 44.5653\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0695 - val_loss: 44.8390\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0470 - val_loss: 43.8986\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5992 - val_loss: 44.9917\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2541 - val_loss: 47.4483\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.1469 - val_loss: 44.3707\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5993 - val_loss: 44.0431\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3593 - val_loss: 43.9273\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.2265 - val_loss: 44.5850\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.7165 - val_loss: 48.9335\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.0554 - val_loss: 44.8807\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1298 - val_loss: 43.9867\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2046 - val_loss: 44.0002\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6276 - val_loss: 44.2023\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.5781 - val_loss: 43.8479\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.6093 - val_loss: 45.0734\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0084 - val_loss: 44.2574\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.3997 - val_loss: 48.9010\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7150 - val_loss: 44.4061\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8676 - val_loss: 43.7645\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1572 - val_loss: 44.2795\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 49.2270 - val_loss: 44.3930\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.3959 - val_loss: 46.0211\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.0196 - val_loss: 44.1291\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.3210 - val_loss: 44.4414\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.3415 - val_loss: 44.5816\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6267 - val_loss: 44.5386\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.7748 - val_loss: 43.7967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7452 - val_loss: 45.7318\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.2201 - val_loss: 45.9732\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4934 - val_loss: 44.1551\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8766 - val_loss: 45.7474\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.8135 - val_loss: 44.0975\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 52.8288 - val_loss: 47.9712\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 52.4548 - val_loss: 47.0402\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 52.5823 - val_loss: 45.6215\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.2915 - val_loss: 44.0063\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.7002 - val_loss: 44.9619\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.6389 - val_loss: 45.5966\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.3918 - val_loss: 44.0228\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2635 - val_loss: 44.0549\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.8164 - val_loss: 45.4379\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.2307 - val_loss: 45.5943\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4548 - val_loss: 44.9512\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 52.0796 - val_loss: 46.1153\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.8282 - val_loss: 44.6971\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.7389 - val_loss: 44.4458\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4939 - val_loss: 44.6064\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0236 - val_loss: 50.5505\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.9698 - val_loss: 44.9920\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.1555 - val_loss: 47.0719\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4437 - val_loss: 44.5650\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.4083 - val_loss: 46.2147\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2523 - val_loss: 43.8636\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.7429 - val_loss: 43.7443\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5333 - val_loss: 46.8969\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.2784 - val_loss: 44.7209\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5701 - val_loss: 44.4208\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.0440 - val_loss: 44.7670\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.1438 - val_loss: 43.8646\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.9429 - val_loss: 45.4248\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.6967 - val_loss: 45.9561\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.8924 - val_loss: 50.1351\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.7762 - val_loss: 45.1202\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.9125 - val_loss: 45.2188\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.7528 - val_loss: 55.1314\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6788 - val_loss: 44.8782\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.7041 - val_loss: 45.2630\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.7609 - val_loss: 46.1284\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.9500 - val_loss: 43.9425\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4909 - val_loss: 45.5608\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.0464 - val_loss: 45.2456\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.9820 - val_loss: 45.1319\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3707 - val_loss: 45.3983\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.7781 - val_loss: 44.3476\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.6959 - val_loss: 44.1384\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1203 - val_loss: 44.4901\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8586 - val_loss: 44.5170\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3963 - val_loss: 44.0563\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.3671 - val_loss: 46.8296\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.6029 - val_loss: 45.7858\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.9331 - val_loss: 45.5577\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.4872 - val_loss: 44.2999\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.1789 - val_loss: 45.9603\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6082 - val_loss: 44.5308\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.7290 - val_loss: 45.0484\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.1074 - val_loss: 44.3340\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.6899 - val_loss: 46.7426\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0737 - val_loss: 44.5574\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.0794 - val_loss: 47.8927\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5640 - val_loss: 45.7786\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.3266 - val_loss: 46.2706\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.3996 - val_loss: 46.2812\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.4663 - val_loss: 44.9148\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.1667 - val_loss: 48.3212\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.0486 - val_loss: 44.6124\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9150 - val_loss: 44.8045\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.9827 - val_loss: 49.3680\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.7547 - val_loss: 44.0548\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5087 - val_loss: 46.1587\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.0486 - val_loss: 44.1579\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5524 - val_loss: 44.7396\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.1674 - val_loss: 46.8149\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.9199 - val_loss: 44.4279\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.8580 - val_loss: 44.0539\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8881 - val_loss: 43.8944\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5627 - val_loss: 45.0461\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 4ms/step - loss: 48.7714 - val_loss: 45.0496\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.0313 - val_loss: 47.2220\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.4678 - val_loss: 45.4973\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.5659 - val_loss: 45.3551\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6031 - val_loss: 44.2496\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6506 - val_loss: 44.2259\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9119 - val_loss: 44.7138\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1615 - val_loss: 43.9586\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5156 - val_loss: 44.9021\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2835 - val_loss: 44.1015\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.5017 - val_loss: 44.1735\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8500 - val_loss: 47.7477\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.6860 - val_loss: 48.5664\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7299 - val_loss: 44.6814\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.6272 - val_loss: 44.9813\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.9414 - val_loss: 46.8024\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 51.4086 - val_loss: 47.1410\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.5995 - val_loss: 46.2872\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0873 - val_loss: 46.1907\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.5894 - val_loss: 44.3309\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0466 - val_loss: 43.8677\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.9272 - val_loss: 46.3572\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.3639 - val_loss: 45.7189\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.2294 - val_loss: 44.0473\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4033 - val_loss: 43.8053\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.7693 - val_loss: 46.2852\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.5344 - val_loss: 50.6401\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.0236 - val_loss: 50.9907\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.3111 - val_loss: 47.2637\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2617 - val_loss: 44.2485\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2225 - val_loss: 44.3438\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6625 - val_loss: 45.4190\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.1557 - val_loss: 45.1707\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.2728 - val_loss: 46.4066\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5668 - val_loss: 44.1925\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5156 - val_loss: 46.8816\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 52.1683 - val_loss: 44.2476\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3282 - val_loss: 44.1738\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3532 - val_loss: 48.0464\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.2811 - val_loss: 49.3769\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.0582 - val_loss: 44.8233\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.3833 - val_loss: 46.5568\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3150 - val_loss: 44.3197\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2915 - val_loss: 44.6859\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8574 - val_loss: 45.3053\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4022 - val_loss: 44.7789\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0894 - val_loss: 43.9413\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5607 - val_loss: 44.9919\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.5180 - val_loss: 44.6476\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1337 - val_loss: 44.7305\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4599 - val_loss: 45.0704\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.6548 - val_loss: 45.4649\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7631 - val_loss: 45.9616\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.6162 - val_loss: 44.4370\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5992 - val_loss: 44.0157\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7626 - val_loss: 44.1723\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.9153 - val_loss: 44.3742\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3931 - val_loss: 45.3388\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.3470 - val_loss: 44.3436\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8956 - val_loss: 44.4876\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4419 - val_loss: 43.7444\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4030 - val_loss: 45.2279\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3848 - val_loss: 44.0472\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1962 - val_loss: 44.2242\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8065 - val_loss: 46.9810\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.5496 - val_loss: 44.3007\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6412 - val_loss: 45.2342\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.3442 - val_loss: 45.7036\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4930 - val_loss: 45.3437\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.9035 - val_loss: 45.5482\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1023 - val_loss: 45.3863\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0811 - val_loss: 44.3716\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8088 - val_loss: 43.9772\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5002 - val_loss: 44.5990\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.9266 - val_loss: 44.4480\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.9355 - val_loss: 44.2349\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.3852 - val_loss: 44.1255\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5700 - val_loss: 44.1807\n",
      "Epoch 15/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2845 - val_loss: 50.9037\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.4319 - val_loss: 47.0615\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 50.5337 - val_loss: 44.7227\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 51.2385 - val_loss: 47.6881\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.4439 - val_loss: 46.4162\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0734 - val_loss: 44.8974\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.0830 - val_loss: 46.9720\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.7812 - val_loss: 44.4582\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.3615 - val_loss: 45.2644\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.7911 - val_loss: 44.3594\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.5400 - val_loss: 50.5480\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.9822 - val_loss: 44.3927\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.7436 - val_loss: 48.8036\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.1448 - val_loss: 44.3107\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4984 - val_loss: 44.2492\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.9274 - val_loss: 44.3558\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.3209 - val_loss: 44.4717\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1817 - val_loss: 44.6975\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.2667 - val_loss: 44.2722\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5507 - val_loss: 44.3057\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.3432 - val_loss: 43.9491\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.9415 - val_loss: 45.4373\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.4392 - val_loss: 45.1828\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9151 - val_loss: 44.2127\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 48.5660 - val_loss: 47.6521\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.4328 - val_loss: 43.8883\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.4277 - val_loss: 49.3167\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 51.7089 - val_loss: 44.6524\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3193 - val_loss: 43.9162\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1153 - val_loss: 44.1053\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7117 - val_loss: 44.3559\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.0829 - val_loss: 45.7609\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 50.4176 - val_loss: 45.2350\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5953 - val_loss: 43.4692\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.5189 - val_loss: 44.7481\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.3521 - val_loss: 43.8863\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 48.4404 - val_loss: 43.9497\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5791 - val_loss: 44.0093\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.2347 - val_loss: 44.5611\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.4300 - val_loss: 45.3737\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.3210 - val_loss: 43.8676\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8973 - val_loss: 44.1340\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.3023 - val_loss: 44.3833\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.9242 - val_loss: 47.1735\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 52.9499 - val_loss: 47.5231\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.7105 - val_loss: 46.0864\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8500 - val_loss: 45.9932\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5029 - val_loss: 44.3699\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9729 - val_loss: 45.8768\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2260 - val_loss: 46.1761\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.7247 - val_loss: 43.8553\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 48.6777 - val_loss: 44.3667\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.5316 - val_loss: 44.1173\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.0639 - val_loss: 44.2341\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.5137 - val_loss: 43.8449\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.1729 - val_loss: 44.0653\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.9271 - val_loss: 47.9440\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 51.7408 - val_loss: 50.5688\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.2429 - val_loss: 54.6602\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 52.9444 - val_loss: 45.5194\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1023 - val_loss: 45.1135\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.3576 - val_loss: 44.2441\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9545 - val_loss: 45.3234\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2769 - val_loss: 44.0023\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6452 - val_loss: 45.3105\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.6852 - val_loss: 44.0154\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.2674 - val_loss: 43.9787\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5891 - val_loss: 44.8456\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.9226 - val_loss: 46.2400\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.7475 - val_loss: 44.0329\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6156 - val_loss: 44.2582\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.7602 - val_loss: 43.9687\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1321 - val_loss: 43.8863\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1485 - val_loss: 44.4369\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4154 - val_loss: 44.2103\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.5981 - val_loss: 47.3031\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.5044 - val_loss: 45.4571\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.1685 - val_loss: 44.2521\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1621 - val_loss: 44.5384\n",
      "Epoch 44/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 48.4621 - val_loss: 44.7184\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2153 - val_loss: 44.8636\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.2187 - val_loss: 44.0396\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3562 - val_loss: 44.9918\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.4172 - val_loss: 50.0608\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.4071 - val_loss: 45.3023\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.2278 - val_loss: 44.4488\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 48.4171 - val_loss: 47.0118\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8052 - val_loss: 44.4575\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1704 - val_loss: 45.7944\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1567 - val_loss: 44.3751\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8121 - val_loss: 44.7486\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 48.3382 - val_loss: 47.2050\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.8892 - val_loss: 45.3650\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.7675 - val_loss: 44.9791\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 50.5374 - val_loss: 51.6481\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.5888 - val_loss: 44.1496\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8693 - val_loss: 45.1739\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.9268 - val_loss: 44.5944\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3016 - val_loss: 44.4113\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5532 - val_loss: 44.3322\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8014 - val_loss: 44.8090\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4553 - val_loss: 44.4668\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.9114 - val_loss: 43.9929\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4806 - val_loss: 44.2702\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1495 - val_loss: 45.6477\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.7661 - val_loss: 46.2933\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.8032 - val_loss: 44.0556\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4549 - val_loss: 46.2360\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1297 - val_loss: 49.3898\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.3267 - val_loss: 51.1247\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.9155 - val_loss: 44.3074\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6189 - val_loss: 44.3044\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.2734 - val_loss: 45.4001\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.6641 - val_loss: 44.4579\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.4593 - val_loss: 44.1478\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2008 - val_loss: 44.4263\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.6748 - val_loss: 45.3057\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.5895 - val_loss: 45.0459\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.2852 - val_loss: 53.4685\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.2919 - val_loss: 45.2648\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.8690 - val_loss: 44.1799\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2072 - val_loss: 44.3257\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.7614 - val_loss: 48.0649\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.4566 - val_loss: 44.2788\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.4089 - val_loss: 44.3964\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.4540 - val_loss: 44.0586\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9450 - val_loss: 45.0500\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9236 - val_loss: 43.8976\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9124 - val_loss: 44.7333\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4690 - val_loss: 45.6097\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.4333 - val_loss: 44.4759\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.5567 - val_loss: 45.4950\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.9037 - val_loss: 46.4156\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.0096 - val_loss: 48.7521\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.3570 - val_loss: 44.7469\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8851 - val_loss: 44.4576\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 49.2449 - val_loss: 44.6518\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5283 - val_loss: 44.4043\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6943 - val_loss: 44.8306\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.0571 - val_loss: 45.8461\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.8018 - val_loss: 48.6014\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.7996 - val_loss: 44.5468\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.1863 - val_loss: 44.5561\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.0172 - val_loss: 44.0595\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9248 - val_loss: 45.3086\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6815 - val_loss: 44.2252\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1546 - val_loss: 44.4929\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2734 - val_loss: 44.2579\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.7749 - val_loss: 44.9158\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5749 - val_loss: 44.6747\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2525 - val_loss: 45.9081\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.3420 - val_loss: 44.1976\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.1987 - val_loss: 47.1351\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.9629 - val_loss: 43.9598\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9937 - val_loss: 48.9769\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.1672 - val_loss: 46.8490\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.1969 - val_loss: 46.4142\n",
      "Epoch 22/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7937 - val_loss: 43.9539\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.9809 - val_loss: 44.3698\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6392 - val_loss: 45.0945\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0253 - val_loss: 45.2990\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.5523 - val_loss: 45.7686\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4649 - val_loss: 44.7787\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.3108 - val_loss: 45.4632\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.2236 - val_loss: 45.7530\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4842 - val_loss: 44.0837\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.7676 - val_loss: 45.1689\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2851 - val_loss: 49.1352\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 50.5836 - val_loss: 44.7782\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9432 - val_loss: 46.1953\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.3710 - val_loss: 44.5809\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.1284 - val_loss: 43.8976\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.9562 - val_loss: 48.3917\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3897 - val_loss: 43.8475\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.3990 - val_loss: 44.3892\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.7981 - val_loss: 43.9555\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7164 - val_loss: 45.2539\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 51.0232 - val_loss: 44.7371\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.7020 - val_loss: 46.5937\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.5497 - val_loss: 44.9850\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4991 - val_loss: 45.7190\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6847 - val_loss: 45.6957\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.1780 - val_loss: 44.9931\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 50.3490 - val_loss: 43.9454\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3229 - val_loss: 44.0295\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0789 - val_loss: 46.1663\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.7098 - val_loss: 45.6021\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 50.5304 - val_loss: 44.1440\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6414 - val_loss: 44.9671\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.8475 - val_loss: 45.8816\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.5120 - val_loss: 45.1576\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.5526 - val_loss: 43.8896\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6860 - val_loss: 43.9284\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.3934 - val_loss: 44.3708\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.0765 - val_loss: 44.1612\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0586 - val_loss: 43.9682\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3317 - val_loss: 44.3735\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.3131 - val_loss: 52.4755\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.2164 - val_loss: 44.4249\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.6597 - val_loss: 44.8470\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3240 - val_loss: 44.4824\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.7863 - val_loss: 44.3257\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1565 - val_loss: 49.8496\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 51.6967 - val_loss: 44.7031\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.0204 - val_loss: 45.4537\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1907 - val_loss: 44.0876\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.2648 - val_loss: 47.4417\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4979 - val_loss: 44.3464\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0987 - val_loss: 44.1557\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.3597 - val_loss: 46.4506\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.1547 - val_loss: 45.2285\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.7497 - val_loss: 44.7179\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6551 - val_loss: 44.2901\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8352 - val_loss: 44.8041\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9005 - val_loss: 44.3767\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4122 - val_loss: 44.0736\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2047 - val_loss: 44.2663\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.3618 - val_loss: 44.0113\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6241 - val_loss: 48.7628\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.8358 - val_loss: 47.7584\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 48.6219 - val_loss: 46.1218\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.4977 - val_loss: 47.8482\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.6103 - val_loss: 43.9136\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1993 - val_loss: 45.3794\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.8789 - val_loss: 46.6994\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.4532 - val_loss: 47.2521\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.4121 - val_loss: 46.9573\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 50.8105 - val_loss: 47.4476\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 52.3071 - val_loss: 44.2558\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.8050 - val_loss: 47.6154\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.4952 - val_loss: 45.1500\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8736 - val_loss: 44.2016\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2031 - val_loss: 44.2594\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4745 - val_loss: 53.9385\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.6298 - val_loss: 47.3215\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.2454 - val_loss: 44.8296\n",
      "10/10 [==============================] - 0s 0s/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 49.2498 - val_loss: 44.8631\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2174 - val_loss: 47.0995\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4603 - val_loss: 44.5240\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8145 - val_loss: 44.4888\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 50.0106 - val_loss: 46.6524\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.6450 - val_loss: 49.7115\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.8371 - val_loss: 44.2866\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3026 - val_loss: 44.0654\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.2344 - val_loss: 43.9992\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.1361 - val_loss: 44.2026\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6833 - val_loss: 43.8595\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.4901 - val_loss: 45.2435\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.8014 - val_loss: 46.8225\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 51.1774 - val_loss: 52.4295\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 53.8915 - val_loss: 45.2026\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.1051 - val_loss: 45.5241\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.1860 - val_loss: 45.4764\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8813 - val_loss: 48.4905\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.8803 - val_loss: 44.2652\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.9568 - val_loss: 46.2485\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.5961 - val_loss: 44.2332\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3046 - val_loss: 45.2310\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8840 - val_loss: 44.4344\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 50.6227 - val_loss: 43.5990\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2389 - val_loss: 43.9848\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2717 - val_loss: 44.4497\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1186 - val_loss: 46.4899\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1666 - val_loss: 44.0472\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.2407 - val_loss: 45.2382\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.3864 - val_loss: 44.0952\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 48.3536 - val_loss: 44.5607\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3281 - val_loss: 43.7584\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1376 - val_loss: 44.2419\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0923 - val_loss: 44.3746\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1737 - val_loss: 43.9325\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.4218 - val_loss: 43.8113\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2272 - val_loss: 44.1993\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6944 - val_loss: 44.0807\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2320 - val_loss: 44.0709\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.0070 - val_loss: 46.9205\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.1832 - val_loss: 44.9338\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8657 - val_loss: 43.9674\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2875 - val_loss: 44.1232\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.1168 - val_loss: 45.8239\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.5327 - val_loss: 44.8046\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5290 - val_loss: 44.3165\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.0650 - val_loss: 46.2208\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.3907 - val_loss: 44.2683\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5000 - val_loss: 51.0004\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.9795 - val_loss: 44.0016\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 48.1625 - val_loss: 44.3005\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.5031 - val_loss: 44.6573\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6042 - val_loss: 44.2885\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.8039 - val_loss: 48.2648\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 53.9180 - val_loss: 44.6660\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.7720 - val_loss: 44.1450\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9827 - val_loss: 44.3060\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 49.1820 - val_loss: 44.0856\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.5882 - val_loss: 44.3582\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0237 - val_loss: 44.9671\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.9477 - val_loss: 46.3025\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.8278 - val_loss: 49.2193\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.5272 - val_loss: 44.9767\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7958 - val_loss: 44.5174\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6592 - val_loss: 44.5156\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7328 - val_loss: 44.4022\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7228 - val_loss: 43.9698\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.5436 - val_loss: 46.0631\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.4550 - val_loss: 45.3082\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.6601 - val_loss: 45.2896\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.5256 - val_loss: 46.0360\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.4855 - val_loss: 44.2052\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1782 - val_loss: 44.0457\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.7887 - val_loss: 44.2439\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0043 - val_loss: 44.9130\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7853 - val_loss: 44.5468\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.2251 - val_loss: 48.6892\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.8977 - val_loss: 45.4448\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2989 - val_loss: 44.3181\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6750 - val_loss: 43.8255\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5542 - val_loss: 44.0196\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.9304 - val_loss: 44.1528\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.9741 - val_loss: 45.3724\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.2445 - val_loss: 45.6285\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.6978 - val_loss: 45.0695\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.7502 - val_loss: 45.0533\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.6271 - val_loss: 44.2933\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0752 - val_loss: 43.8583\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8376 - val_loss: 46.2985\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6580 - val_loss: 43.8738\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0667 - val_loss: 44.8433\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.9361 - val_loss: 45.9166\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5495 - val_loss: 45.0864\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.9799 - val_loss: 44.3238\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.8763 - val_loss: 50.3213\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.3366 - val_loss: 44.0205\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.0737 - val_loss: 47.6167\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.9180 - val_loss: 48.8945\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.7897 - val_loss: 43.8976\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.0111 - val_loss: 44.0007\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 50.0111 - val_loss: 43.7045\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.9093 - val_loss: 44.6032\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.6647 - val_loss: 44.7055\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.7374 - val_loss: 46.1473\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.5193 - val_loss: 46.0691\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 53.3473 - val_loss: 49.8287\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5085 - val_loss: 44.1268\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.3946 - val_loss: 45.0560\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 51.3591 - val_loss: 44.9718\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.8790 - val_loss: 44.8749\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6479 - val_loss: 45.8920\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.1173 - val_loss: 46.5867\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.0593 - val_loss: 52.8064\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.0499 - val_loss: 46.3015\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.4582 - val_loss: 44.5170\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6890 - val_loss: 44.8423\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.2060 - val_loss: 44.1231\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.1317 - val_loss: 50.1247\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.1530 - val_loss: 43.9427\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.3766 - val_loss: 45.9428\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.7710 - val_loss: 46.3825\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1429 - val_loss: 51.8801\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 50.0793 - val_loss: 44.2389\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5992 - val_loss: 44.1034\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9960 - val_loss: 51.9919\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.7404 - val_loss: 47.6098\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5545 - val_loss: 44.4139\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9008 - val_loss: 43.8447\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.0802 - val_loss: 44.8950\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9746 - val_loss: 45.4213\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.2797 - val_loss: 45.5712\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.5083 - val_loss: 50.4046\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.7763 - val_loss: 46.4133\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.7097 - val_loss: 44.1756\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1693 - val_loss: 44.2396\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2641 - val_loss: 44.0959\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.9274 - val_loss: 44.1492\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1659 - val_loss: 44.7725\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6196 - val_loss: 44.3720\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.2779 - val_loss: 45.6671\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.2437 - val_loss: 44.2031\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3702 - val_loss: 43.8678\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3882 - val_loss: 44.1603\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5478 - val_loss: 44.5073\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.2864 - val_loss: 45.4144\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6696 - val_loss: 44.4132\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0898 - val_loss: 43.9334\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2354 - val_loss: 44.3943\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6472 - val_loss: 44.9786\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1811 - val_loss: 44.0526\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "mse2 = [] # Initializing the list for appending the MSE upon each iteration\n",
    "for i in range(50):\n",
    "    mse2.append(MSE(model, X_norm, Y, 50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reporting Mean and Standard Deviation of the Mean Squared Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the mean squared error\n",
    "x = ['{0}'.format(i+1) for i in range(50)]\n",
    "plt.bar(x,mse2)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Mean Squared Error - MSE')\n",
    "plt.title('Evolution of MSE of normalized data over the iterations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of the MSE's: 57.2759672337988\n",
      "Standard deviation of the MSE's: 15.37555302461574\n"
     ]
    }
   ],
   "source": [
    "# Mean of the MSE's\n",
    "mean_partB = np.array(mse2).mean()\n",
    "print(\"Mean of the MSE's:\",mean_partB)\n",
    "\n",
    "# Standard deviation of the MSE'S\n",
    "std_partB = np.array(mse2).std()\n",
    "print(\"Standard deviation of the MSE's:\",std_partB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison between the Mean of the Mean Squared Errors when unnormalized and normalized data are fed to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(['Unnormalized data','Normalized data'],[mean_partA,mean_partB])\n",
    "plt.xlabel('Type of data fed to the model')\n",
    "plt.ylabel(\"Mean of the MSE's\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-55.57496544285652"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Difference between both mean of the MSE's\n",
    "mean_partB-mean_partA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus it can be observed that on making the data normalized, the error reduces and  accuracy of the prediction incresases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Reporting mean of the MSE using normalized version of the data by increasing the number of epochs to 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5393 - val_loss: 43.9296\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6071 - val_loss: 44.3041\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9601 - val_loss: 44.2068\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.5325 - val_loss: 48.0857\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.4528 - val_loss: 44.0241\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.6271 - val_loss: 45.7502\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7767 - val_loss: 44.2140\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5065 - val_loss: 45.7665\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.6004 - val_loss: 45.7890\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.6232 - val_loss: 44.1255\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.2026 - val_loss: 43.9567\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6760 - val_loss: 44.2410\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.6807 - val_loss: 45.4625\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.7422 - val_loss: 44.2294\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6419 - val_loss: 44.6636\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.7141 - val_loss: 44.0107\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.2678 - val_loss: 44.1005\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2437 - val_loss: 47.1637\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.6091 - val_loss: 47.8105\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 52.2472 - val_loss: 44.0797\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2249 - val_loss: 44.2763\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8412 - val_loss: 45.5815\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.4951 - val_loss: 44.6467\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 50.8989 - val_loss: 46.6956\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.7483 - val_loss: 46.6105\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.9671 - val_loss: 45.6117\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9442 - val_loss: 43.8941\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6388 - val_loss: 44.2021\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0360 - val_loss: 45.5316\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.0446 - val_loss: 44.4962\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2404 - val_loss: 44.1554\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.6540 - val_loss: 44.5870\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6355 - val_loss: 47.0076\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.0917 - val_loss: 44.5255\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1615 - val_loss: 44.2218\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.7122 - val_loss: 44.5342\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.1848 - val_loss: 46.3761\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.8946 - val_loss: 46.7477\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 50.3758 - val_loss: 46.2923\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 50.1301 - val_loss: 43.9990\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.3561 - val_loss: 43.9612\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8993 - val_loss: 44.0320\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.6535 - val_loss: 46.9924\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5785 - val_loss: 47.9211\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.3301 - val_loss: 44.5466\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9790 - val_loss: 50.9084\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5260 - val_loss: 43.9628\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2590 - val_loss: 44.4489\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5759 - val_loss: 44.0188\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.4856 - val_loss: 45.9400\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 50.5842 - val_loss: 46.8920\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 51.0115 - val_loss: 44.4081\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.8587 - val_loss: 44.5749\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 50.0398 - val_loss: 44.2956\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5388 - val_loss: 43.9272\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3719 - val_loss: 49.1324\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.7801 - val_loss: 44.5550\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.9781 - val_loss: 45.7822\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.2571 - val_loss: 45.1202\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.9585 - val_loss: 47.5098\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.7871 - val_loss: 45.8087\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4643 - val_loss: 44.3144\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4316 - val_loss: 44.0229\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.4054 - val_loss: 44.7736\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.1727 - val_loss: 44.7810\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7729 - val_loss: 44.0430\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0551 - val_loss: 43.9166\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.3512 - val_loss: 44.3436\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3883 - val_loss: 44.0908\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0742 - val_loss: 44.5833\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0567 - val_loss: 44.5261\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1972 - val_loss: 44.6505\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7266 - val_loss: 44.0783\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8236 - val_loss: 45.3538\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.7293 - val_loss: 44.3703\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 52.0404 - val_loss: 44.2092\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.3082 - val_loss: 45.0414\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.7293 - val_loss: 44.9341\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.3674 - val_loss: 44.8772\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 4ms/step - loss: 48.7257 - val_loss: 44.4208\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3864 - val_loss: 43.8365\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.9120 - val_loss: 44.1086\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8028 - val_loss: 44.4043\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.3083 - val_loss: 46.4179\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.7078 - val_loss: 44.0375\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4736 - val_loss: 43.9709\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8716 - val_loss: 44.7477\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1938 - val_loss: 45.0681\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1890 - val_loss: 44.0952\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5560 - val_loss: 43.9468\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.5878 - val_loss: 45.5882\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.8013 - val_loss: 45.0673\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.7617 - val_loss: 46.7012\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8066 - val_loss: 44.4119\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4456 - val_loss: 44.5926\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3965 - val_loss: 44.0050\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5928 - val_loss: 44.3571\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.4558 - val_loss: 46.2273\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9734 - val_loss: 44.6326\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0622 - val_loss: 45.7644\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 50.6011 - val_loss: 44.6198\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4604 - val_loss: 46.5121\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0147 - val_loss: 44.0047\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4177 - val_loss: 44.7549\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.7283 - val_loss: 44.0577\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.4521 - val_loss: 44.0856\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6020 - val_loss: 44.1427\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.9652 - val_loss: 43.9304\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.8284 - val_loss: 45.1410\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.7735 - val_loss: 44.8197\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0361 - val_loss: 44.1204\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.3780 - val_loss: 45.5446\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1926 - val_loss: 43.9317\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.4316 - val_loss: 44.2760\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2165 - val_loss: 44.5081\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6000 - val_loss: 44.8006\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.8368 - val_loss: 43.8571\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0397 - val_loss: 44.0608\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2795 - val_loss: 44.3178\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2314 - val_loss: 44.7860\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1295 - val_loss: 43.7897\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.5849 - val_loss: 44.1761\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.4232 - val_loss: 44.1776\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 52.1770 - val_loss: 45.1435\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.5916 - val_loss: 44.7922\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.6282 - val_loss: 44.3528\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.2356 - val_loss: 43.7219\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2569 - val_loss: 44.4056\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.2279 - val_loss: 45.7695\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1753 - val_loss: 44.5059\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3504 - val_loss: 44.1037\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2124 - val_loss: 44.6061\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0970 - val_loss: 43.9945\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3536 - val_loss: 43.9924\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7303 - val_loss: 44.6887\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.2184 - val_loss: 45.6467\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.1678 - val_loss: 46.0939\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.9594 - val_loss: 44.3362\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.2407 - val_loss: 44.0100\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.4595 - val_loss: 44.0499\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1312 - val_loss: 44.2536\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1202 - val_loss: 44.5982\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.9736 - val_loss: 48.2992\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.3467 - val_loss: 48.5540\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.5006 - val_loss: 44.6844\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.9236 - val_loss: 44.3379\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.4091 - val_loss: 43.7640\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.3348 - val_loss: 49.9400\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 52.7417 - val_loss: 45.3391\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.0786 - val_loss: 44.1228\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 53.0662 - val_loss: 44.4202\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4978 - val_loss: 44.9767\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4308 - val_loss: 45.7886\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.5032 - val_loss: 44.5210\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8861 - val_loss: 44.0467\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.4367 - val_loss: 44.7599\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8408 - val_loss: 44.5481\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3929 - val_loss: 43.8370\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.4209 - val_loss: 44.0138\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4525 - val_loss: 45.1984\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.1000 - val_loss: 44.3386\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.4807 - val_loss: 44.3572\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.4625 - val_loss: 44.2112\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5742 - val_loss: 44.0368\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.6078 - val_loss: 47.0594\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.2658 - val_loss: 45.7913\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7589 - val_loss: 44.1067\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4268 - val_loss: 44.1298\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4885 - val_loss: 46.0413\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.1419 - val_loss: 44.6256\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.5064 - val_loss: 47.5698\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8992 - val_loss: 43.8245\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0824 - val_loss: 45.5658\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.7894 - val_loss: 44.1910\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3139 - val_loss: 43.9934\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.7882 - val_loss: 44.3921\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8076 - val_loss: 44.0767\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5183 - val_loss: 44.8523\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4742 - val_loss: 45.9319\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2619 - val_loss: 44.3705\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1965 - val_loss: 44.2729\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.1644 - val_loss: 47.9283\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.2268 - val_loss: 44.3132\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0679 - val_loss: 44.7405\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8667 - val_loss: 43.9463\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.3662 - val_loss: 49.5663\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.2156 - val_loss: 54.2486\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.9005 - val_loss: 44.0043\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.6535 - val_loss: 45.2710\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4323 - val_loss: 44.3855\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9917 - val_loss: 44.0725\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.5081 - val_loss: 46.6519\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1905 - val_loss: 44.2269\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1109 - val_loss: 43.8520\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.1882 - val_loss: 44.0652\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.5768 - val_loss: 44.1145\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3472 - val_loss: 47.6736\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.8320 - val_loss: 44.6444\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7341 - val_loss: 44.4369\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 48.7643 - val_loss: 45.2357\n",
      "10/10 [==============================] - 0s 0s/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.5743 - val_loss: 44.1645\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.9822 - val_loss: 46.4795\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.3535 - val_loss: 44.5885\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.7983 - val_loss: 43.8729\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8894 - val_loss: 44.3907\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.5923 - val_loss: 46.7093\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.0474 - val_loss: 44.1514\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3189 - val_loss: 44.1582\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2658 - val_loss: 44.3087\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3492 - val_loss: 44.9163\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9032 - val_loss: 44.9360\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.0661 - val_loss: 45.2481\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7878 - val_loss: 44.0441\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.8824 - val_loss: 47.9181\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.9608 - val_loss: 45.7206\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7546 - val_loss: 43.9958\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8745 - val_loss: 44.0152\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4866 - val_loss: 44.3297\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2962 - val_loss: 45.4416\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.0509 - val_loss: 44.4070\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.6469 - val_loss: 44.0414\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0790 - val_loss: 43.8980\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9171 - val_loss: 44.1932\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3501 - val_loss: 44.3737\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1543 - val_loss: 44.4908\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7831 - val_loss: 43.7401\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.4455 - val_loss: 44.7315\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.1663 - val_loss: 44.8989\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.6995 - val_loss: 44.4507\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.8072 - val_loss: 46.9659\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.3987 - val_loss: 49.0086\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.7798 - val_loss: 43.8014\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6262 - val_loss: 44.2620\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5032 - val_loss: 45.1763\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.4856 - val_loss: 45.9108\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 50.1794 - val_loss: 45.2985\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 48.3360 - val_loss: 44.7296\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9279 - val_loss: 44.4541\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 48.4029 - val_loss: 44.1359\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.2878 - val_loss: 45.2294\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.1110 - val_loss: 43.9623\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1671 - val_loss: 46.3364\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.7378 - val_loss: 45.8754\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7163 - val_loss: 44.3154\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1634 - val_loss: 44.3103\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.4578 - val_loss: 43.9623\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.8653 - val_loss: 48.8089\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 52.7600 - val_loss: 44.2821\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6096 - val_loss: 44.1808\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.6330 - val_loss: 49.6811\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 50.4865 - val_loss: 45.2259\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.5353 - val_loss: 47.1857\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.3933 - val_loss: 43.8191\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8288 - val_loss: 46.7074\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 50.2388 - val_loss: 46.1097\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2055 - val_loss: 46.3637\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 49.5457 - val_loss: 44.9423\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0438 - val_loss: 43.8006\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.6105 - val_loss: 45.0661\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 50.3576 - val_loss: 44.8280\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.8029 - val_loss: 45.8600\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7235 - val_loss: 50.8474\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 52.0745 - val_loss: 48.3095\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.3736 - val_loss: 45.7033\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7707 - val_loss: 44.3373\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8535 - val_loss: 46.6688\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.2819 - val_loss: 51.2243\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.0627 - val_loss: 44.9184\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.3008 - val_loss: 44.8020\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.7144 - val_loss: 44.2188\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0528 - val_loss: 44.7022\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.9439 - val_loss: 44.2636\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5912 - val_loss: 44.9973\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4602 - val_loss: 44.9382\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 48.1641 - val_loss: 44.2279\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5700 - val_loss: 45.2664\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.4814 - val_loss: 44.2114\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.8520 - val_loss: 45.3250\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3145 - val_loss: 45.5777\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.0710 - val_loss: 43.7729\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9229 - val_loss: 47.1670\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 52.9660 - val_loss: 52.6337\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 52.1024 - val_loss: 44.0208\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3576 - val_loss: 44.1130\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.9021 - val_loss: 44.3780\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7279 - val_loss: 55.9373\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.2725 - val_loss: 43.7459\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3308 - val_loss: 44.2006\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9863 - val_loss: 43.9427\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.6985 - val_loss: 45.4164\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.7325 - val_loss: 44.5277\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.0128 - val_loss: 43.9224\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.2027 - val_loss: 44.8137\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.2729 - val_loss: 46.9273\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.4837 - val_loss: 45.1102\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.7294 - val_loss: 46.2261\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1080 - val_loss: 45.3525\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8579 - val_loss: 45.4734\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3127 - val_loss: 46.7742\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.1125 - val_loss: 44.4744\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1676 - val_loss: 44.3051\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3105 - val_loss: 44.6614\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.4668 - val_loss: 44.4345\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0368 - val_loss: 44.7406\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.7887 - val_loss: 45.2383\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.9768 - val_loss: 44.0991\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7224 - val_loss: 44.4617\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 50.0072 - val_loss: 49.0236\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.5212 - val_loss: 46.3268\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.4362 - val_loss: 44.3285\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.0834 - val_loss: 45.5026\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3056 - val_loss: 44.1550\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6707 - val_loss: 44.2031\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.1848 - val_loss: 44.1698\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7278 - val_loss: 43.9373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 50.1693 - val_loss: 44.4328\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.5702 - val_loss: 46.2010\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.9103 - val_loss: 44.4308\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4723 - val_loss: 44.5270\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.9280 - val_loss: 44.9975\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9489 - val_loss: 44.0206\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9309 - val_loss: 45.8602\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8567 - val_loss: 45.4550\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.0054 - val_loss: 46.8280\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.2927 - val_loss: 44.6477\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3868 - val_loss: 44.0879\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1319 - val_loss: 43.9669\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7330 - val_loss: 44.3253\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3096 - val_loss: 44.2237\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.8485 - val_loss: 44.2412\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.5390 - val_loss: 44.4471\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8213 - val_loss: 43.7606\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.5496 - val_loss: 44.0891\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.9093 - val_loss: 46.9864\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.9214 - val_loss: 44.9497\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2710 - val_loss: 44.4705\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0689 - val_loss: 44.4545\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9116 - val_loss: 44.3884\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4613 - val_loss: 44.2906\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1122 - val_loss: 43.9616\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.5023 - val_loss: 45.3508\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.5466 - val_loss: 44.2518\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3130 - val_loss: 45.5378\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2371 - val_loss: 43.7391\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7216 - val_loss: 45.6959\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4747 - val_loss: 44.8228\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.9433 - val_loss: 43.9929\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.5164 - val_loss: 44.3680\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.1182 - val_loss: 45.2570\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.5760 - val_loss: 45.3137\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.0225 - val_loss: 43.8912\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 52.0974 - val_loss: 48.6311\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.7397 - val_loss: 46.4851\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9145 - val_loss: 44.1924\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7867 - val_loss: 45.1489\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6637 - val_loss: 48.2627\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0957 - val_loss: 44.4478\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.0125 - val_loss: 49.6420\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.2438 - val_loss: 44.4124\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3316 - val_loss: 44.6039\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1377 - val_loss: 44.4706\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.6465 - val_loss: 45.2252\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1680 - val_loss: 44.6329\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8732 - val_loss: 46.4362\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6791 - val_loss: 46.6866\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.5088 - val_loss: 45.8897\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.7133 - val_loss: 44.7036\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1388 - val_loss: 44.9736\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0623 - val_loss: 44.8525\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4271 - val_loss: 44.7756\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5213 - val_loss: 45.0441\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7419 - val_loss: 46.3954\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.5691 - val_loss: 45.2882\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4426 - val_loss: 46.5787\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2782 - val_loss: 44.6661\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1271 - val_loss: 44.4064\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.0461 - val_loss: 44.6772\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.4550 - val_loss: 44.8331\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4623 - val_loss: 44.8765\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.1435 - val_loss: 55.8557\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 53.6769 - val_loss: 47.5398\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0372 - val_loss: 44.8217\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6464 - val_loss: 48.2217\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.7587 - val_loss: 44.9309\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.7031 - val_loss: 47.6386\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 53.0727 - val_loss: 58.8009\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 52.4109 - val_loss: 50.5988\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3147 - val_loss: 45.1870\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.9883 - val_loss: 45.3752\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6613 - val_loss: 44.6945\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6181 - val_loss: 46.4644\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1612 - val_loss: 44.6785\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1693 - val_loss: 44.7480\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.0779 - val_loss: 45.0154\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2817 - val_loss: 49.5965\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8110 - val_loss: 45.0989\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0567 - val_loss: 45.2225\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6524 - val_loss: 45.9836\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6657 - val_loss: 44.9669\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.5063 - val_loss: 45.4800\n",
      "10/10 [==============================] - 0s 0s/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.1992 - val_loss: 45.1809\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.2380 - val_loss: 44.8807\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.6877 - val_loss: 45.4564\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8598 - val_loss: 47.3125\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0096 - val_loss: 50.2247\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 53.8695 - val_loss: 52.2164\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 49.9717 - val_loss: 45.5277\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.9089 - val_loss: 46.1283\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0576 - val_loss: 45.5969\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.7150 - val_loss: 53.4325\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 53.4094 - val_loss: 67.1305\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.5981 - val_loss: 45.7004\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.6599 - val_loss: 46.6644\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.8151 - val_loss: 44.9331\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.0920 - val_loss: 45.0667\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.2194 - val_loss: 45.2218\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0200 - val_loss: 45.5814\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.2698 - val_loss: 44.7029\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7208 - val_loss: 44.9582\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.0885 - val_loss: 45.1238\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8055 - val_loss: 44.8051\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.3128 - val_loss: 46.1462\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0553 - val_loss: 46.0445\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0687 - val_loss: 47.1029\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.9006 - val_loss: 45.1457\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 51.8413 - val_loss: 44.9294\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 50.4840 - val_loss: 44.9719\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.2008 - val_loss: 47.2479\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0192 - val_loss: 45.4510\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.1136 - val_loss: 44.7398\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.0457 - val_loss: 46.4100\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.0301 - val_loss: 45.3784\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.9755 - val_loss: 45.7635\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7020 - val_loss: 47.2930\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6868 - val_loss: 44.6908\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0529 - val_loss: 45.5285\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3754 - val_loss: 44.7748\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.3602 - val_loss: 45.2547\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.6189 - val_loss: 45.5523\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.6790 - val_loss: 44.7971\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3616 - val_loss: 44.8586\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.4624 - val_loss: 45.3581\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1126 - val_loss: 44.9771\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.7626 - val_loss: 44.8743\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.9806 - val_loss: 44.9492\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0326 - val_loss: 44.7597\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9769 - val_loss: 46.9741\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4164 - val_loss: 45.3751\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.7349 - val_loss: 44.8784\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0457 - val_loss: 44.8542\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5030 - val_loss: 44.7989\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6454 - val_loss: 45.9333\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.2913 - val_loss: 46.2116\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 49.1378 - val_loss: 44.9361\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8555 - val_loss: 46.0620\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.3903 - val_loss: 45.0264\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9671 - val_loss: 45.4012\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3617 - val_loss: 45.5359\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2820 - val_loss: 45.5883\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7538 - val_loss: 45.7516\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9051 - val_loss: 44.8019\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7751 - val_loss: 44.7611\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1010 - val_loss: 46.4741\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.8178 - val_loss: 45.8057\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.2972 - val_loss: 48.3431\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.6141 - val_loss: 46.0369\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.1034 - val_loss: 47.7457\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.2306 - val_loss: 45.8350\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.1665 - val_loss: 45.3369\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6716 - val_loss: 45.2236\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.6187 - val_loss: 46.9118\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2377 - val_loss: 44.8005\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.4361 - val_loss: 48.1577\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.2968 - val_loss: 49.5147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.7023 - val_loss: 44.7948\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.7650 - val_loss: 44.6943\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1097 - val_loss: 45.5201\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.9525 - val_loss: 45.2521\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3628 - val_loss: 48.3499\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.5698 - val_loss: 49.3044\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 52.5629 - val_loss: 44.9040\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 51.6979 - val_loss: 44.9479\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0146 - val_loss: 45.3099\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.0339 - val_loss: 46.6330\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6991 - val_loss: 45.2692\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.4662 - val_loss: 50.0275\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 52.1344 - val_loss: 52.5193\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.1442 - val_loss: 46.0897\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9897 - val_loss: 45.1054\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.9569 - val_loss: 45.9872\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8803 - val_loss: 50.3304\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5177 - val_loss: 44.7288\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4669 - val_loss: 45.5592\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.0693 - val_loss: 45.0771\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4292 - val_loss: 46.0841\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.3721 - val_loss: 45.0137\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0096 - val_loss: 45.6997\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3048 - val_loss: 45.1053\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5932 - val_loss: 50.1569\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.5709 - val_loss: 46.5730\n",
      "10/10 [==============================] - 0s 0s/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.0138 - val_loss: 45.0600\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0779 - val_loss: 45.3525\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9334 - val_loss: 44.8546\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9988 - val_loss: 45.9116\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9520 - val_loss: 46.1661\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0453 - val_loss: 44.8930\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9997 - val_loss: 45.5183\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.5784 - val_loss: 44.8637\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2475 - val_loss: 46.2660\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4935 - val_loss: 45.0307\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.5776 - val_loss: 45.0660\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2015 - val_loss: 45.8856\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.3849 - val_loss: 45.3725\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.3867 - val_loss: 48.2291\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.3656 - val_loss: 44.9515\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.2371 - val_loss: 45.8426\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0887 - val_loss: 45.0622\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.2101 - val_loss: 44.9894\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.7953 - val_loss: 44.6600\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.9994 - val_loss: 46.1660\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.1037 - val_loss: 44.8561\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.2344 - val_loss: 44.7189\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9144 - val_loss: 49.5832\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.2338 - val_loss: 45.7687\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.0500 - val_loss: 49.4114\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.1676 - val_loss: 46.0938\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0805 - val_loss: 48.2730\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.2488 - val_loss: 47.9692\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5257 - val_loss: 44.6963\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5697 - val_loss: 44.9482\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.0309 - val_loss: 44.7964\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8741 - val_loss: 45.2419\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.7248 - val_loss: 44.6279\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.2201 - val_loss: 45.0053\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.6626 - val_loss: 45.3158\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6727 - val_loss: 46.5943\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8623 - val_loss: 45.7533\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.7331 - val_loss: 47.3875\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.8781 - val_loss: 45.3157\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 55.6413 - val_loss: 44.9790\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.2248 - val_loss: 46.4686\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 52.6055 - val_loss: 48.2987\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.0007 - val_loss: 44.9813\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2733 - val_loss: 45.6350\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3447 - val_loss: 44.6329\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 51.0475 - val_loss: 45.1555\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.0280 - val_loss: 47.4582\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 49.2121 - val_loss: 46.0273\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.9725 - val_loss: 44.9283\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8576 - val_loss: 44.9943\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.7479 - val_loss: 45.5549\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.2892 - val_loss: 45.0882\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 4ms/step - loss: 49.8637 - val_loss: 45.1337\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0515 - val_loss: 44.8697\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.8894 - val_loss: 45.1513\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1258 - val_loss: 45.0039\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5841 - val_loss: 45.8531\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.2045 - val_loss: 45.8587\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3964 - val_loss: 44.7967\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3835 - val_loss: 46.0350\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.5110 - val_loss: 44.8745\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1415 - val_loss: 45.1840\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9844 - val_loss: 45.0618\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.4823 - val_loss: 45.6514\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.0450 - val_loss: 46.2858\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.9000 - val_loss: 47.0757\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.7957 - val_loss: 47.2275\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2993 - val_loss: 45.6002\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7345 - val_loss: 45.2464\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.6848 - val_loss: 50.4313\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.6568 - val_loss: 47.7114\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1497 - val_loss: 45.3013\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.1959 - val_loss: 46.0619\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.7514 - val_loss: 45.5984\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.5516 - val_loss: 44.9689\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6687 - val_loss: 46.7850\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 51.2210 - val_loss: 47.2112\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5998 - val_loss: 45.1646\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.9738 - val_loss: 47.0719\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2120 - val_loss: 45.1431\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0333 - val_loss: 46.5082\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.1025 - val_loss: 45.5182\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.7446 - val_loss: 45.1251\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.6131 - val_loss: 44.7042\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2768 - val_loss: 45.0114\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1178 - val_loss: 46.0741\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0401 - val_loss: 45.3525\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.1319 - val_loss: 44.8573\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.5486 - val_loss: 45.1178\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8175 - val_loss: 44.7165\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4920 - val_loss: 45.1692\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7082 - val_loss: 45.0980\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0000 - val_loss: 45.2938\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.9054 - val_loss: 46.7397\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.4011 - val_loss: 44.8751\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.3399 - val_loss: 45.2085\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.4379 - val_loss: 45.2587\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5085 - val_loss: 46.2251\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3195 - val_loss: 44.7042\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.6581 - val_loss: 50.8639\n",
      "10/10 [==============================] - 0s 0s/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 50.1645 - val_loss: 48.0853\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.0774 - val_loss: 45.6364\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.7062 - val_loss: 44.9494\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5101 - val_loss: 44.7332\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.9357 - val_loss: 45.8098\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 48.4387 - val_loss: 44.8500\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9583 - val_loss: 45.4076\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1112 - val_loss: 45.8511\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.6813 - val_loss: 47.6481\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.7572 - val_loss: 48.8868\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.8995 - val_loss: 45.4559\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.9653 - val_loss: 44.5172\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.1922 - val_loss: 45.2550\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.1025 - val_loss: 45.0757\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0079 - val_loss: 47.6375\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.0564 - val_loss: 45.2724\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5349 - val_loss: 44.8017\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3568 - val_loss: 54.9930\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.9671 - val_loss: 48.4430\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 51.1004 - val_loss: 45.3894\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4335 - val_loss: 45.2782\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.7459 - val_loss: 44.6900\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4534 - val_loss: 44.8096\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4837 - val_loss: 44.9229\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.4777 - val_loss: 49.1636\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.2105 - val_loss: 46.5858\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.1482 - val_loss: 44.8118\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0163 - val_loss: 45.0859\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7610 - val_loss: 45.0413\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 47.8640 - val_loss: 44.8551\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7299 - val_loss: 44.8599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.8404 - val_loss: 45.3429\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0967 - val_loss: 44.8403\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3914 - val_loss: 48.4752\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.1563 - val_loss: 46.0640\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.2557 - val_loss: 47.0917\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1077 - val_loss: 44.8497\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.9104 - val_loss: 44.9977\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.0799 - val_loss: 45.1551\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7124 - val_loss: 46.0906\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5055 - val_loss: 44.7769\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9101 - val_loss: 46.1092\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1031 - val_loss: 45.4240\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8190 - val_loss: 44.5757\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.1157 - val_loss: 44.8153\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1715 - val_loss: 47.0349\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5353 - val_loss: 45.7173\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1837 - val_loss: 44.9458\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5888 - val_loss: 46.8905\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.5470 - val_loss: 45.0158\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.3207 - val_loss: 45.5626\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5757 - val_loss: 44.6335\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8752 - val_loss: 45.8752\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.1957 - val_loss: 47.8016\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.9284 - val_loss: 48.8869\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.1791 - val_loss: 44.8831\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2969 - val_loss: 45.2391\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1162 - val_loss: 44.8925\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6311 - val_loss: 46.3511\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7058 - val_loss: 46.6696\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9782 - val_loss: 44.9649\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3978 - val_loss: 44.8362\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5300 - val_loss: 46.9227\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.0654 - val_loss: 45.0030\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8061 - val_loss: 45.0246\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9486 - val_loss: 46.6911\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3082 - val_loss: 46.2992\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.9884 - val_loss: 45.4003\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.8917 - val_loss: 44.6717\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3488 - val_loss: 46.0879\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1469 - val_loss: 46.6016\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.7298 - val_loss: 45.1410\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.0616 - val_loss: 45.0194\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3924 - val_loss: 45.2170\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7964 - val_loss: 44.5840\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.4548 - val_loss: 45.3348\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8493 - val_loss: 45.0182\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.9781 - val_loss: 45.1794\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2788 - val_loss: 44.8625\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.9714 - val_loss: 46.2905\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0402 - val_loss: 44.6301\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.1705 - val_loss: 48.5066\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.8818 - val_loss: 48.8318\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.2000 - val_loss: 47.1647\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 50.8987 - val_loss: 47.2321\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6526 - val_loss: 44.6297\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3474 - val_loss: 45.2449\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2546 - val_loss: 45.9663\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.2615 - val_loss: 46.2211\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.0775 - val_loss: 44.9812\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.4933 - val_loss: 46.4921\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4275 - val_loss: 44.7951\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5064 - val_loss: 45.0145\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2256 - val_loss: 45.1376\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1274 - val_loss: 45.6092\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 48.3434 - val_loss: 45.3192\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5930 - val_loss: 45.1454\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.2009 - val_loss: 45.2296\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0164 - val_loss: 44.9371\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7982 - val_loss: 44.9316\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7655 - val_loss: 46.8347\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2554 - val_loss: 45.0117\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7401 - val_loss: 45.2738\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9021 - val_loss: 44.7588\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7138 - val_loss: 44.9567\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.7041 - val_loss: 44.6295\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2449 - val_loss: 45.0275\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8094 - val_loss: 44.7917\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.0927 - val_loss: 45.5060\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 4ms/step - loss: 50.3386 - val_loss: 45.0819\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4006 - val_loss: 45.6628\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1056 - val_loss: 44.7980\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6835 - val_loss: 48.3858\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6556 - val_loss: 45.9336\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0505 - val_loss: 44.6871\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9942 - val_loss: 45.0248\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.4199 - val_loss: 45.8414\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.4923 - val_loss: 45.0631\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9250 - val_loss: 46.8628\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2297 - val_loss: 44.8003\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.1870 - val_loss: 45.7737\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5907 - val_loss: 44.7437\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7986 - val_loss: 45.4706\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9947 - val_loss: 48.2046\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.7194 - val_loss: 45.2646\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.6905 - val_loss: 45.0618\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5744 - val_loss: 45.3470\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7136 - val_loss: 47.6324\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.4608 - val_loss: 45.5136\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0188 - val_loss: 45.0821\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0413 - val_loss: 45.1048\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1980 - val_loss: 48.4845\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6545 - val_loss: 47.5797\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.3113 - val_loss: 44.8366\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0362 - val_loss: 45.0390\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4158 - val_loss: 45.3986\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6616 - val_loss: 44.8494\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.2021 - val_loss: 44.9587\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0408 - val_loss: 44.9342\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1550 - val_loss: 47.8927\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8986 - val_loss: 46.4852\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3593 - val_loss: 45.2777\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.9392 - val_loss: 45.3513\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.5701 - val_loss: 45.3824\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 50.1664 - val_loss: 48.5366\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.9296 - val_loss: 49.1709\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.5949 - val_loss: 45.0587\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.1680 - val_loss: 45.6717\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2637 - val_loss: 49.0365\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5253 - val_loss: 44.9467\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.3831 - val_loss: 47.6421\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.4285 - val_loss: 46.8483\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3087 - val_loss: 48.4715\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4505 - val_loss: 44.6937\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8283 - val_loss: 46.8150\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.7282 - val_loss: 49.7444\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.3338 - val_loss: 45.4336\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8654 - val_loss: 46.9826\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.8058 - val_loss: 45.9105\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2659 - val_loss: 45.1587\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9179 - val_loss: 45.1419\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7643 - val_loss: 45.8702\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.7132 - val_loss: 44.7618\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8098 - val_loss: 46.4700\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6983 - val_loss: 44.8177\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.6301 - val_loss: 44.8553\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.6718 - val_loss: 45.4235\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 50.7261 - val_loss: 45.8445\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.0963 - val_loss: 45.3788\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.5312 - val_loss: 45.1570\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.3930 - val_loss: 44.8632\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3672 - val_loss: 45.5226\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.7298 - val_loss: 44.6743\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5898 - val_loss: 45.0957\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2816 - val_loss: 46.1839\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.2412 - val_loss: 46.0108\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.0038 - val_loss: 45.4305\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.7605 - val_loss: 46.1052\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6966 - val_loss: 44.7748\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9911 - val_loss: 45.9746\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.2052 - val_loss: 49.8641\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.6771 - val_loss: 45.5556\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7111 - val_loss: 44.9825\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7393 - val_loss: 46.4820\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8996 - val_loss: 48.4746\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.6591 - val_loss: 45.6685\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.5782 - val_loss: 44.8825\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.9154 - val_loss: 44.8365\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 47.9603 - val_loss: 45.3842\n",
      "Epoch 90/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 4ms/step - loss: 49.1768 - val_loss: 45.2336\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.0575 - val_loss: 44.7792\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2705 - val_loss: 47.2450\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6176 - val_loss: 44.8506\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1767 - val_loss: 45.7524\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7814 - val_loss: 45.0568\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.1097 - val_loss: 47.1189\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.3406 - val_loss: 44.5859\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.0669 - val_loss: 45.0046\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4550 - val_loss: 45.6058\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.5481 - val_loss: 47.3194\n",
      "10/10 [==============================] - 0s 0s/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 50.7366 - val_loss: 45.4175\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.9707 - val_loss: 44.8273\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.5461 - val_loss: 44.8854\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.3864 - val_loss: 46.4408\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5944 - val_loss: 45.1980\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8818 - val_loss: 47.7573\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8429 - val_loss: 45.1124\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8690 - val_loss: 44.8224\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3015 - val_loss: 45.2784\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4073 - val_loss: 45.8406\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0649 - val_loss: 45.3205\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2979 - val_loss: 44.6566\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.7371 - val_loss: 46.7750\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.9307 - val_loss: 47.2421\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0471 - val_loss: 48.6381\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.4042 - val_loss: 45.0556\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0695 - val_loss: 45.3236\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.8915 - val_loss: 46.2928\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.1118 - val_loss: 49.5932\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8225 - val_loss: 45.6182\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7956 - val_loss: 45.0213\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0151 - val_loss: 45.6933\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9091 - val_loss: 44.6929\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8626 - val_loss: 45.3209\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3460 - val_loss: 46.7878\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4244 - val_loss: 45.0127\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.4514 - val_loss: 46.6609\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1374 - val_loss: 44.6424\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3873 - val_loss: 44.7669\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2657 - val_loss: 44.8732\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.9709 - val_loss: 45.7526\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9302 - val_loss: 45.0033\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.8519 - val_loss: 44.8848\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7974 - val_loss: 44.7259\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9798 - val_loss: 44.8775\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.1084 - val_loss: 45.4583\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.5849 - val_loss: 45.6981\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0958 - val_loss: 44.6956\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3689 - val_loss: 45.9292\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2329 - val_loss: 44.7426\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6837 - val_loss: 46.2356\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.8039 - val_loss: 45.2340\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.9271 - val_loss: 46.4720\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.7431 - val_loss: 45.2794\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4063 - val_loss: 45.1403\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.4861 - val_loss: 45.8746\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1191 - val_loss: 44.5567\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2466 - val_loss: 44.6887\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8748 - val_loss: 45.6712\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5860 - val_loss: 44.7338\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.4535 - val_loss: 44.7719\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8881 - val_loss: 45.7847\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2826 - val_loss: 45.4751\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0881 - val_loss: 45.0609\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0766 - val_loss: 44.7581\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9760 - val_loss: 44.5337\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8129 - val_loss: 47.9237\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.6730 - val_loss: 45.1756\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 50.6128 - val_loss: 45.5383\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 50.4575 - val_loss: 45.1623\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6743 - val_loss: 47.3071\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.2389 - val_loss: 46.9003\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 49.6673 - val_loss: 44.6506\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.8146 - val_loss: 46.2092\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 52.3719 - val_loss: 45.7454\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.5431 - val_loss: 45.3918\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9464 - val_loss: 46.2476\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.2152 - val_loss: 44.5421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9814 - val_loss: 45.2977\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7273 - val_loss: 44.6903\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.7402 - val_loss: 44.8303\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.0151 - val_loss: 46.1112\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.4415 - val_loss: 47.8591\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 50.1641 - val_loss: 44.8518\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9883 - val_loss: 44.8478\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5993 - val_loss: 45.1341\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 51.5275 - val_loss: 46.1559\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0028 - val_loss: 46.3528\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7201 - val_loss: 44.5604\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.2301 - val_loss: 45.8511\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6128 - val_loss: 44.9296\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6854 - val_loss: 44.8994\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8557 - val_loss: 44.9083\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8355 - val_loss: 46.6096\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.6721 - val_loss: 46.5893\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5496 - val_loss: 44.7477\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.2396 - val_loss: 45.0120\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1570 - val_loss: 47.6772\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.3980 - val_loss: 45.9503\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5036 - val_loss: 45.3419\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.1578 - val_loss: 46.8838\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5043 - val_loss: 44.6934\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9000 - val_loss: 45.0625\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0957 - val_loss: 45.0016\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.6267 - val_loss: 49.8966\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 52.2880 - val_loss: 52.4580\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.9922 - val_loss: 45.5734\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.3587 - val_loss: 45.2751\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.6448 - val_loss: 45.5053\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.3800 - val_loss: 44.8614\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 47.9272 - val_loss: 45.1970\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.1450 - val_loss: 44.4981\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.6402 - val_loss: 45.2782\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9680 - val_loss: 44.7463\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5071 - val_loss: 51.5723\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.7647 - val_loss: 45.7013\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.6501 - val_loss: 49.2688\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8996 - val_loss: 48.8209\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2259 - val_loss: 44.7739\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.9947 - val_loss: 45.6820\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5218 - val_loss: 44.9081\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.6204 - val_loss: 45.0046\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9456 - val_loss: 45.0960\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2019 - val_loss: 47.0118\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.4121 - val_loss: 49.5485\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.9440 - val_loss: 45.2575\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4413 - val_loss: 45.1956\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4433 - val_loss: 44.9209\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.5027 - val_loss: 45.6482\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3515 - val_loss: 45.6789\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0598 - val_loss: 44.7681\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4636 - val_loss: 44.9694\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8785 - val_loss: 44.7402\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.8099 - val_loss: 47.0199\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5204 - val_loss: 44.9541\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.8792 - val_loss: 45.5852\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.6189 - val_loss: 45.4037\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4847 - val_loss: 45.2638\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8190 - val_loss: 44.6385\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.8510 - val_loss: 45.0131\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.9224 - val_loss: 47.4334\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.8024 - val_loss: 47.4070\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.6115 - val_loss: 45.7725\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0259 - val_loss: 44.7094\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2737 - val_loss: 45.2646\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.4619 - val_loss: 45.3363\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0635 - val_loss: 45.1554\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2231 - val_loss: 44.7261\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.5405 - val_loss: 44.7448\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9730 - val_loss: 45.2345\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.3922 - val_loss: 44.8855\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9595 - val_loss: 45.7239\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4947 - val_loss: 46.1493\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.3110 - val_loss: 44.6230\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.2853 - val_loss: 45.2478\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4700 - val_loss: 46.2298\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9235 - val_loss: 46.1324\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8044 - val_loss: 52.2315\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 52.0067 - val_loss: 50.6284\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.0618 - val_loss: 50.0159\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.4976 - val_loss: 45.0664\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6623 - val_loss: 45.1086\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.8081 - val_loss: 47.4949\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2925 - val_loss: 44.5135\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3041 - val_loss: 50.5597\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.5554 - val_loss: 45.7760\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6172 - val_loss: 51.6282\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.2232 - val_loss: 51.8209\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.9195 - val_loss: 44.8078\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.7078 - val_loss: 45.1416\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0995 - val_loss: 44.6594\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0934 - val_loss: 49.1197\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9832 - val_loss: 47.2479\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.9599 - val_loss: 45.1474\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0720 - val_loss: 44.6491\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1558 - val_loss: 45.4004\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4628 - val_loss: 45.9263\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1651 - val_loss: 44.6101\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0661 - val_loss: 44.6956\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6203 - val_loss: 44.7122\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1773 - val_loss: 46.3296\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6053 - val_loss: 45.2583\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1332 - val_loss: 45.8347\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.4170 - val_loss: 50.3442\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.0990 - val_loss: 48.0899\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3594 - val_loss: 44.4952\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.1924 - val_loss: 45.0179\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.4802 - val_loss: 45.6410\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.6681 - val_loss: 44.8020\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.7098 - val_loss: 45.1332\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9034 - val_loss: 45.9070\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.0384 - val_loss: 45.0325\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9062 - val_loss: 44.7622\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7103 - val_loss: 47.8356\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.4047 - val_loss: 47.8899\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.4936 - val_loss: 46.5034\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9674 - val_loss: 45.9466\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6694 - val_loss: 45.3939\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3168 - val_loss: 45.6384\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1156 - val_loss: 44.8373\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5450 - val_loss: 45.1191\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2727 - val_loss: 45.6148\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0151 - val_loss: 46.7150\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7536 - val_loss: 44.5690\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8301 - val_loss: 45.5084\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9510 - val_loss: 44.9431\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1311 - val_loss: 44.8190\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0317 - val_loss: 44.8666\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.9259 - val_loss: 45.2043\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9014 - val_loss: 45.1677\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 47.8332 - val_loss: 44.6842\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3894 - val_loss: 44.7554\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1263 - val_loss: 44.4585\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1877 - val_loss: 44.7573\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4813 - val_loss: 46.4440\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9732 - val_loss: 44.6021\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9462 - val_loss: 44.9942\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.7068 - val_loss: 46.1831\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8191 - val_loss: 44.6969\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 51.0897 - val_loss: 46.7894\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.9117 - val_loss: 46.1346\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0254 - val_loss: 44.5794\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8901 - val_loss: 50.8969\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.2609 - val_loss: 44.9823\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1512 - val_loss: 44.8156\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0001 - val_loss: 47.2217\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.7579 - val_loss: 46.8553\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7297 - val_loss: 45.0082\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7923 - val_loss: 44.5326\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.4455 - val_loss: 46.4157\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5013 - val_loss: 44.9454\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3856 - val_loss: 45.2453\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.3246 - val_loss: 50.4818\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.4890 - val_loss: 46.1823\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8136 - val_loss: 45.2637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4126 - val_loss: 47.7965\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8201 - val_loss: 45.8290\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8924 - val_loss: 45.1297\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2856 - val_loss: 44.9326\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7955 - val_loss: 44.7216\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2086 - val_loss: 44.7337\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5749 - val_loss: 47.5149\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5943 - val_loss: 45.5629\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5192 - val_loss: 50.6092\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.5370 - val_loss: 46.9147\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.9950 - val_loss: 45.0723\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4437 - val_loss: 44.7648\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.1431 - val_loss: 49.6642\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8572 - val_loss: 46.0335\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.2292 - val_loss: 44.6506\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8860 - val_loss: 46.9641\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.5033 - val_loss: 45.9649\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5935 - val_loss: 44.5781\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6584 - val_loss: 45.1863\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0208 - val_loss: 46.2690\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9300 - val_loss: 45.1996\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9541 - val_loss: 44.6792\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.2594 - val_loss: 44.7167\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1477 - val_loss: 44.6158\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7614 - val_loss: 45.8706\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5818 - val_loss: 45.0143\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9995 - val_loss: 44.6705\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5543 - val_loss: 45.1744\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9793 - val_loss: 44.9731\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9091 - val_loss: 44.8674\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6787 - val_loss: 45.0254\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8805 - val_loss: 44.7233\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.9875 - val_loss: 49.4741\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4631 - val_loss: 45.0764\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7637 - val_loss: 44.8510\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6911 - val_loss: 45.3347\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5473 - val_loss: 45.3985\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3791 - val_loss: 44.5561\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5406 - val_loss: 48.4415\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7673 - val_loss: 45.5520\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3787 - val_loss: 44.7597\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9295 - val_loss: 44.8191\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4121 - val_loss: 47.4917\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8304 - val_loss: 47.0072\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5419 - val_loss: 48.1302\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1314 - val_loss: 46.1598\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8229 - val_loss: 45.7669\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4466 - val_loss: 46.7081\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2318 - val_loss: 45.6452\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.3635 - val_loss: 49.2785\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.6409 - val_loss: 44.7008\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.5383 - val_loss: 44.9190\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6511 - val_loss: 45.5451\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.3860 - val_loss: 45.0712\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8844 - val_loss: 44.6611\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5925 - val_loss: 47.9602\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2008 - val_loss: 45.0398\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4894 - val_loss: 44.6829\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5671 - val_loss: 44.8937\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.6461 - val_loss: 48.1893\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4176 - val_loss: 44.7472\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6316 - val_loss: 45.4942\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6216 - val_loss: 44.7750\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3368 - val_loss: 45.8465\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7722 - val_loss: 45.9384\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.9310 - val_loss: 52.5006\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.7792 - val_loss: 46.0149\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7818 - val_loss: 45.3759\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5738 - val_loss: 44.8214\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.4203 - val_loss: 44.8888\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.2472 - val_loss: 45.3600\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6189 - val_loss: 44.8504\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9713 - val_loss: 51.4676\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.1611 - val_loss: 45.5211\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3352 - val_loss: 45.1870\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 48.3321 - val_loss: 45.5685\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.0658 - val_loss: 44.7911\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9174 - val_loss: 45.7841\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9796 - val_loss: 44.8494\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4741 - val_loss: 44.8280\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5716 - val_loss: 46.8435\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0157 - val_loss: 45.0300\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3295 - val_loss: 44.4206\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3312 - val_loss: 44.7748\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4258 - val_loss: 47.9527\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.3432 - val_loss: 46.2719\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8911 - val_loss: 44.7725\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3398 - val_loss: 46.3053\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.3989 - val_loss: 45.6486\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2297 - val_loss: 44.4589\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8537 - val_loss: 45.2216\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5216 - val_loss: 44.6509\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1544 - val_loss: 44.7569\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7625 - val_loss: 45.6312\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5274 - val_loss: 44.7819\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7231 - val_loss: 44.5740\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7349 - val_loss: 45.1441\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3313 - val_loss: 45.3537\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0308 - val_loss: 45.0263\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6695 - val_loss: 44.5497\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2857 - val_loss: 44.7820\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1749 - val_loss: 44.8751\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3631 - val_loss: 44.4409\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9955 - val_loss: 44.9142\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2005 - val_loss: 44.9853\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0825 - val_loss: 44.8398\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.7956 - val_loss: 44.8059\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5296 - val_loss: 45.4105\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0357 - val_loss: 45.5530\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.9921 - val_loss: 44.8648\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5859 - val_loss: 44.9811\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9525 - val_loss: 44.7768\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.3766 - val_loss: 44.4726\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1756 - val_loss: 44.9261\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0841 - val_loss: 44.6902\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6812 - val_loss: 45.6654\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.6745 - val_loss: 44.9462\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.4403 - val_loss: 45.2948\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3335 - val_loss: 44.5624\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9957 - val_loss: 44.5973\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1801 - val_loss: 45.6379\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 50.4321 - val_loss: 44.5845\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0994 - val_loss: 44.4084\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1716 - val_loss: 45.5268\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5058 - val_loss: 44.6597\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0658 - val_loss: 45.1598\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5112 - val_loss: 44.9006\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6577 - val_loss: 44.7951\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.5882 - val_loss: 44.9164\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1808 - val_loss: 44.3838\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5323 - val_loss: 52.8684\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.7031 - val_loss: 45.4457\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5950 - val_loss: 44.7252\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4528 - val_loss: 44.9144\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7463 - val_loss: 45.0131\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3920 - val_loss: 45.1387\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.2547 - val_loss: 45.3587\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7977 - val_loss: 45.8595\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6461 - val_loss: 44.9206\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8437 - val_loss: 46.4127\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0101 - val_loss: 44.6361\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9857 - val_loss: 44.7205\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.7282 - val_loss: 44.8525\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 51.0008 - val_loss: 44.9134\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.0407 - val_loss: 45.8907\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.1502 - val_loss: 46.8559\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.8834 - val_loss: 45.8910\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6697 - val_loss: 45.0595\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6526 - val_loss: 44.9475\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.7271 - val_loss: 44.5257\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0531 - val_loss: 44.5322\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6974 - val_loss: 44.6758\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1576 - val_loss: 44.6839\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0674 - val_loss: 44.8478\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8033 - val_loss: 44.8931\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3874 - val_loss: 45.2554\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9823 - val_loss: 44.6781\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.0224 - val_loss: 45.2278\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 49.4389 - val_loss: 44.5371\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.2494 - val_loss: 44.6113\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6663 - val_loss: 44.6320\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.7010 - val_loss: 46.1430\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.2196 - val_loss: 44.5134\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.3126 - val_loss: 44.6001\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.9687 - val_loss: 44.9830\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1018 - val_loss: 45.3558\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.9249 - val_loss: 49.0755\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6637 - val_loss: 45.9719\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.9699 - val_loss: 45.5313\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5031 - val_loss: 52.5491\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 53.4577 - val_loss: 57.7459\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.4621 - val_loss: 47.3195\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 49.1765 - val_loss: 45.0640\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6585 - val_loss: 45.7214\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9338 - val_loss: 44.4879\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 47.7746 - val_loss: 46.3918\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.1781 - val_loss: 44.5838\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.2841 - val_loss: 46.6500\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 51.2849 - val_loss: 44.7356\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.4435 - val_loss: 49.8428\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.6025 - val_loss: 44.6820\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6057 - val_loss: 45.1059\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3028 - val_loss: 45.0478\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8488 - val_loss: 44.8445\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4332 - val_loss: 48.4882\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.5805 - val_loss: 44.6898\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9524 - val_loss: 46.9041\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0949 - val_loss: 45.8377\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 47.8485 - val_loss: 44.4806\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.7037 - val_loss: 45.2944\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.9782 - val_loss: 44.3698\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.4550 - val_loss: 45.3779\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7043 - val_loss: 45.4574\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.6163 - val_loss: 48.3317\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 49.6084 - val_loss: 45.5765\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7803 - val_loss: 44.9072\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8134 - val_loss: 47.0251\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.7623 - val_loss: 48.5331\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.3095 - val_loss: 52.8397\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 50.3686 - val_loss: 46.4390\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 51.8019 - val_loss: 45.0891\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.2515 - val_loss: 44.6225\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.7126 - val_loss: 45.9625\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7821 - val_loss: 45.6952\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7215 - val_loss: 48.1628\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.4957 - val_loss: 45.3854\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.1520 - val_loss: 48.1007\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.2460 - val_loss: 45.5082\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0595 - val_loss: 46.0059\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0223 - val_loss: 45.2526\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6598 - val_loss: 45.0101\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8626 - val_loss: 44.7057\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7192 - val_loss: 44.6052\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.7768 - val_loss: 44.7376\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8658 - val_loss: 44.7153\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 47.5178 - val_loss: 44.5813\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6007 - val_loss: 44.4502\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3234 - val_loss: 45.3114\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.4733 - val_loss: 45.1563\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0762 - val_loss: 44.7905\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.2668 - val_loss: 49.4995\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3017 - val_loss: 46.1767\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.0013 - val_loss: 46.9483\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7151 - val_loss: 44.7290\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.2943 - val_loss: 45.3671\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7957 - val_loss: 44.5016\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9189 - val_loss: 44.7170\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.5355 - val_loss: 48.4040\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.2874 - val_loss: 45.7025\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.3284 - val_loss: 45.0715\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8295 - val_loss: 44.5708\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6712 - val_loss: 44.6122\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4780 - val_loss: 44.7561\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7887 - val_loss: 45.3235\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.5805 - val_loss: 44.5589\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 47.4199 - val_loss: 46.1892\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6345 - val_loss: 45.7204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5009 - val_loss: 45.2435\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.8598 - val_loss: 44.7328\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.9996 - val_loss: 45.7379\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4423 - val_loss: 45.0470\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9590 - val_loss: 44.7344\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.5674 - val_loss: 45.9533\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5150 - val_loss: 45.4602\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5595 - val_loss: 45.0133\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6173 - val_loss: 44.7077\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5891 - val_loss: 44.4853\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1001 - val_loss: 46.0734\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4911 - val_loss: 44.8341\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.9841 - val_loss: 45.1384\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2840 - val_loss: 47.0006\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7165 - val_loss: 46.2030\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9740 - val_loss: 45.5888\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.8223 - val_loss: 45.3677\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9701 - val_loss: 45.5568\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.6092 - val_loss: 45.7571\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.6119 - val_loss: 44.6069\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6232 - val_loss: 44.6621\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9126 - val_loss: 44.6119\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.7399 - val_loss: 44.7786\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.6175 - val_loss: 44.5726\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.8818 - val_loss: 44.5978\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.9046 - val_loss: 45.3978\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.2021 - val_loss: 45.8718\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7956 - val_loss: 45.2367\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.2403 - val_loss: 45.1880\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9144 - val_loss: 44.2771\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.6161 - val_loss: 44.4988\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.7932 - val_loss: 44.9753\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.9840 - val_loss: 44.6179\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.9816 - val_loss: 49.0391\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7806 - val_loss: 44.5531\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.9607 - val_loss: 44.5208\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8431 - val_loss: 44.4560\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.9567 - val_loss: 44.7225\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 48.5314 - val_loss: 45.1972\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.8620 - val_loss: 47.7676\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1486 - val_loss: 44.8323\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.8836 - val_loss: 44.7262\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.1324 - val_loss: 49.4935\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.8796 - val_loss: 44.5768\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.4936 - val_loss: 44.7338\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.0578 - val_loss: 44.7913\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.9699 - val_loss: 44.5205\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5344 - val_loss: 44.5737\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4743 - val_loss: 45.1503\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 48.5628 - val_loss: 45.7458\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4567 - val_loss: 45.1291\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 48.0570 - val_loss: 44.9526\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.4584 - val_loss: 45.6513\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0351 - val_loss: 44.5559\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 47.6469 - val_loss: 45.0365\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1485 - val_loss: 44.4992\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.1959 - val_loss: 45.7743\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5125 - val_loss: 44.5752\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.2994 - val_loss: 47.4605\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.5897 - val_loss: 49.1395\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.2847 - val_loss: 44.6095\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.5472 - val_loss: 44.2760\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.9107 - val_loss: 45.2567\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.7038 - val_loss: 44.4898\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7088 - val_loss: 47.0109\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4055 - val_loss: 45.6868\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.3068 - val_loss: 44.3755\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 51.5949 - val_loss: 46.0042\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 51.0498 - val_loss: 44.7025\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 48.4126 - val_loss: 44.6072\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2687 - val_loss: 45.7753\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7520 - val_loss: 44.8036\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.9056 - val_loss: 46.6622\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.0486 - val_loss: 45.2303\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5855 - val_loss: 47.6734\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.9736 - val_loss: 45.1422\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.0126 - val_loss: 44.1804\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7742 - val_loss: 44.3011\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 47.9092 - val_loss: 45.3682\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0012 - val_loss: 44.5558\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5012 - val_loss: 44.4021\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7138 - val_loss: 45.4419\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8882 - val_loss: 44.5415\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.6186 - val_loss: 45.6298\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5299 - val_loss: 44.7816\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0448 - val_loss: 44.6704\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8985 - val_loss: 44.6509\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.9001 - val_loss: 44.4722\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.7944 - val_loss: 46.2670\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.3074 - val_loss: 44.6924\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4620 - val_loss: 44.5208\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5929 - val_loss: 45.5286\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7441 - val_loss: 45.1620\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5948 - val_loss: 45.2715\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.1649 - val_loss: 44.7526\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.9016 - val_loss: 44.2798\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0730 - val_loss: 44.7441\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6198 - val_loss: 44.5815\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0441 - val_loss: 44.4419\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3100 - val_loss: 44.6324\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.3090 - val_loss: 44.3193\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4043 - val_loss: 46.2391\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.2334 - val_loss: 44.8722\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4283 - val_loss: 44.4001\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6241 - val_loss: 44.9380\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1843 - val_loss: 44.5275\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.5104 - val_loss: 45.4903\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.5876 - val_loss: 44.5329\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9736 - val_loss: 45.5310\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5429 - val_loss: 45.8556\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.8222 - val_loss: 44.7707\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.9863 - val_loss: 44.6265\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.9106 - val_loss: 47.1920\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.8320 - val_loss: 45.0584\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.1951 - val_loss: 48.7231\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.3280 - val_loss: 45.8576\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9919 - val_loss: 44.5948\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4870 - val_loss: 44.6092\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 47.9438 - val_loss: 44.9904\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4266 - val_loss: 44.4675\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.5828 - val_loss: 44.5378\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.4827 - val_loss: 44.6877\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6243 - val_loss: 45.5348\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.5949 - val_loss: 45.7376\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1411 - val_loss: 45.7933\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 50.1627 - val_loss: 45.8131\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8674 - val_loss: 49.1725\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.4865 - val_loss: 44.7641\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 50.5372 - val_loss: 44.6741\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0892 - val_loss: 48.4162\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9853 - val_loss: 51.7833\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.3442 - val_loss: 47.9187\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.4582 - val_loss: 53.4467\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.4178 - val_loss: 46.6745\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7590 - val_loss: 45.1194\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.9159 - val_loss: 48.1697\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.5909 - val_loss: 46.2213\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0541 - val_loss: 44.7658\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 47.9821 - val_loss: 44.4881\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.5721 - val_loss: 49.3761\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.7243 - val_loss: 45.3001\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.8176 - val_loss: 44.7154\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8599 - val_loss: 45.8168\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4091 - val_loss: 44.3979\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1723 - val_loss: 45.9707\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.7292 - val_loss: 45.2653\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8373 - val_loss: 46.5844\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4824 - val_loss: 45.1128\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8370 - val_loss: 44.5197\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7853 - val_loss: 45.5654\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6534 - val_loss: 44.8971\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8243 - val_loss: 45.1269\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8254 - val_loss: 44.2338\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3015 - val_loss: 44.9544\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.3121 - val_loss: 49.2232\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.5851 - val_loss: 44.3553\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7452 - val_loss: 44.3613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.8355 - val_loss: 44.3376\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.5346 - val_loss: 46.3757\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4070 - val_loss: 45.4820\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5500 - val_loss: 54.4365\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 52.0196 - val_loss: 46.4293\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6741 - val_loss: 44.6864\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6049 - val_loss: 44.6565\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0549 - val_loss: 44.8170\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4184 - val_loss: 45.0373\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.6176 - val_loss: 44.4619\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 50.4650 - val_loss: 45.1736\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.0705 - val_loss: 46.2327\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0769 - val_loss: 45.2079\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3661 - val_loss: 44.8056\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1246 - val_loss: 44.5803\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5534 - val_loss: 45.3136\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7436 - val_loss: 44.3599\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9860 - val_loss: 44.9323\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1109 - val_loss: 44.5200\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7716 - val_loss: 44.8003\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5504 - val_loss: 44.9575\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8587 - val_loss: 44.6400\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8800 - val_loss: 44.5731\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8231 - val_loss: 44.2857\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7950 - val_loss: 44.6237\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.9634 - val_loss: 44.4521\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3960 - val_loss: 46.4784\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9130 - val_loss: 46.1171\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6390 - val_loss: 44.9668\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.3632 - val_loss: 45.6328\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4844 - val_loss: 44.4102\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.1461 - val_loss: 44.7364\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7335 - val_loss: 44.7389\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.6981 - val_loss: 45.1422\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5405 - val_loss: 44.5025\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.9946 - val_loss: 47.2116\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.7002 - val_loss: 50.4077\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.8473 - val_loss: 47.3153\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.9307 - val_loss: 44.7258\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3949 - val_loss: 44.7606\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9255 - val_loss: 44.6150\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2352 - val_loss: 44.4602\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1027 - val_loss: 46.1378\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0191 - val_loss: 48.1628\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.9235 - val_loss: 44.8271\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9219 - val_loss: 44.8664\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2973 - val_loss: 46.7152\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8404 - val_loss: 45.1909\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1376 - val_loss: 45.5659\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9007 - val_loss: 44.4702\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.1743 - val_loss: 44.3062\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0585 - val_loss: 44.7695\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5849 - val_loss: 45.9361\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.3383 - val_loss: 44.7900\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8731 - val_loss: 49.0540\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.3860 - val_loss: 44.4807\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0267 - val_loss: 46.7936\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4683 - val_loss: 45.1045\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.8291 - val_loss: 45.3391\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8002 - val_loss: 46.4513\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2752 - val_loss: 44.9148\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9951 - val_loss: 46.1665\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6964 - val_loss: 45.1729\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.1485 - val_loss: 46.0360\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.3657 - val_loss: 44.6708\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0157 - val_loss: 44.4699\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6014 - val_loss: 45.3496\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0732 - val_loss: 44.2904\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3615 - val_loss: 48.8682\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.2787 - val_loss: 50.6984\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.3070 - val_loss: 44.8948\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5948 - val_loss: 45.7166\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0895 - val_loss: 44.4772\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2244 - val_loss: 44.3102\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6555 - val_loss: 45.0499\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8174 - val_loss: 44.9228\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6412 - val_loss: 44.8536\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.1986 - val_loss: 45.9808\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6652 - val_loss: 45.1412\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.2048 - val_loss: 44.7023\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 48.9846 - val_loss: 45.7639\n",
      "10/10 [==============================] - 0s 0s/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 47.8457 - val_loss: 46.2407\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9703 - val_loss: 48.5951\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2741 - val_loss: 44.6372\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5220 - val_loss: 44.5776\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.7473 - val_loss: 48.1716\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.9200 - val_loss: 44.8914\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7180 - val_loss: 45.2050\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.7235 - val_loss: 44.9771\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0897 - val_loss: 44.5584\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.3160 - val_loss: 45.0997\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6526 - val_loss: 45.8474\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.5589 - val_loss: 50.5935\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.8655 - val_loss: 48.8812\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.9677 - val_loss: 45.6664\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7422 - val_loss: 44.6841\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8314 - val_loss: 44.9039\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5214 - val_loss: 46.0825\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4655 - val_loss: 44.5939\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4449 - val_loss: 47.6472\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1309 - val_loss: 44.8568\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8641 - val_loss: 44.7189\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 47.7774 - val_loss: 45.8544\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.8406 - val_loss: 45.0061\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2857 - val_loss: 45.5325\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6384 - val_loss: 44.5475\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.5182 - val_loss: 45.5586\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8432 - val_loss: 48.2095\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.9430 - val_loss: 44.6356\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4727 - val_loss: 44.8463\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2030 - val_loss: 44.3917\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6427 - val_loss: 44.6906\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5903 - val_loss: 45.9851\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 50.2902 - val_loss: 47.3998\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.3278 - val_loss: 46.1511\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8914 - val_loss: 45.4675\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0197 - val_loss: 45.1197\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0575 - val_loss: 45.3925\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9532 - val_loss: 44.7928\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 48.0676 - val_loss: 44.9446\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.1539 - val_loss: 44.8568\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1534 - val_loss: 45.0514\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 48.3534 - val_loss: 44.5575\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.8796 - val_loss: 44.5378\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4582 - val_loss: 46.7521\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7381 - val_loss: 44.6824\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3514 - val_loss: 44.6034\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.9868 - val_loss: 44.5070\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8586 - val_loss: 44.9825\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0356 - val_loss: 45.7794\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.5930 - val_loss: 46.9321\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.1349 - val_loss: 44.9134\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.7395 - val_loss: 44.9661\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 47.8229 - val_loss: 44.5584\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.9972 - val_loss: 45.0831\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.1806 - val_loss: 47.0277\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.0624 - val_loss: 53.4806\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.1927 - val_loss: 46.4880\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.0532 - val_loss: 46.3196\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.2484 - val_loss: 45.2619\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8379 - val_loss: 44.3549\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5766 - val_loss: 45.5964\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8648 - val_loss: 45.0773\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6404 - val_loss: 48.4399\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.4867 - val_loss: 49.8066\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4508 - val_loss: 44.4544\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.5606 - val_loss: 44.8321\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6658 - val_loss: 44.8061\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4977 - val_loss: 44.8484\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8869 - val_loss: 45.1959\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.3915 - val_loss: 44.6275\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4073 - val_loss: 45.5976\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.0670 - val_loss: 44.7663\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2214 - val_loss: 46.9193\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.6017 - val_loss: 44.7489\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3268 - val_loss: 44.6489\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7231 - val_loss: 44.9223\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.4410 - val_loss: 45.0037\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.7405 - val_loss: 46.8625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.9719 - val_loss: 45.8750\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.7182 - val_loss: 44.6380\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.4228 - val_loss: 45.9101\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5870 - val_loss: 44.7239\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2187 - val_loss: 45.7958\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.9033 - val_loss: 46.2194\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7808 - val_loss: 44.6535\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.9271 - val_loss: 44.5520\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0934 - val_loss: 44.8595\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0790 - val_loss: 46.6032\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 46.9631 - val_loss: 47.3538\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5381 - val_loss: 44.6860\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9810 - val_loss: 49.5224\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0493 - val_loss: 45.8257\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1736 - val_loss: 45.4239\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4070 - val_loss: 53.5194\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.9825 - val_loss: 47.7239\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 49.3180 - val_loss: 45.2720\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.2420 - val_loss: 44.4963\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.2613 - val_loss: 44.6723\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.8604 - val_loss: 45.0664\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.2492 - val_loss: 45.8346\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.7432 - val_loss: 44.9117\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0115 - val_loss: 45.1663\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4284 - val_loss: 45.8199\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.3246 - val_loss: 48.3998\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2770 - val_loss: 47.3064\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9653 - val_loss: 46.7237\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.3612 - val_loss: 45.3629\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7139 - val_loss: 49.3690\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.2884 - val_loss: 44.5687\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 50.5885 - val_loss: 44.8115\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.8995 - val_loss: 52.0505\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.9817 - val_loss: 46.6790\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3066 - val_loss: 46.9971\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6668 - val_loss: 45.7885\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7093 - val_loss: 44.7521\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4656 - val_loss: 44.7505\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6379 - val_loss: 44.7779\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.3861 - val_loss: 44.3443\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7684 - val_loss: 45.4578\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0358 - val_loss: 48.9522\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 52.1999 - val_loss: 48.5270\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.7942 - val_loss: 45.2614\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6428 - val_loss: 44.6105\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0000 - val_loss: 45.6607\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.2912 - val_loss: 45.5672\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7929 - val_loss: 44.8229\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5690 - val_loss: 46.5329\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.1026 - val_loss: 47.0185\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.5245 - val_loss: 45.0183\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.2469 - val_loss: 44.9383\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.8984 - val_loss: 45.1730\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 51.3414 - val_loss: 47.3830\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 51.3026 - val_loss: 45.3515\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.3784 - val_loss: 44.9541\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9683 - val_loss: 44.5432\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4467 - val_loss: 44.7969\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5533 - val_loss: 44.9793\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1161 - val_loss: 44.6235\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7683 - val_loss: 44.7035\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8988 - val_loss: 45.5409\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4972 - val_loss: 45.6661\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0724 - val_loss: 45.1562\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7882 - val_loss: 45.4510\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5466 - val_loss: 45.0019\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1885 - val_loss: 46.8493\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0432 - val_loss: 44.6856\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5040 - val_loss: 45.3983\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8618 - val_loss: 44.6590\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.1005 - val_loss: 44.9871\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.6538 - val_loss: 44.5996\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4816 - val_loss: 44.9584\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7575 - val_loss: 46.9702\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6318 - val_loss: 45.3558\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6339 - val_loss: 45.1412\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.8238 - val_loss: 44.8486\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.5369 - val_loss: 45.9817\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 50.1306 - val_loss: 45.9891\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.3056 - val_loss: 45.2515\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.2840 - val_loss: 45.4057\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.1823 - val_loss: 46.3529\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3861 - val_loss: 48.0074\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9319 - val_loss: 45.0543\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.5374 - val_loss: 44.8044\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9843 - val_loss: 47.1017\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8822 - val_loss: 44.4688\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.2333 - val_loss: 44.2831\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8044 - val_loss: 44.8237\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4898 - val_loss: 45.5782\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.8721 - val_loss: 45.0087\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6303 - val_loss: 44.8293\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9486 - val_loss: 44.7019\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2670 - val_loss: 48.0841\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.4648 - val_loss: 50.6306\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.0488 - val_loss: 45.9214\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3777 - val_loss: 45.4771\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1322 - val_loss: 45.1205\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0692 - val_loss: 44.8661\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4067 - val_loss: 45.2832\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.7259 - val_loss: 47.1463\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.2770 - val_loss: 44.5609\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9984 - val_loss: 44.5909\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4174 - val_loss: 44.4725\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3289 - val_loss: 44.7921\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7226 - val_loss: 44.4709\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.3963 - val_loss: 48.3490\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.9609 - val_loss: 44.8470\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0353 - val_loss: 45.1885\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6322 - val_loss: 44.4128\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.0973 - val_loss: 58.0843\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 50.5561 - val_loss: 48.3092\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 50.5907 - val_loss: 45.9645\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8230 - val_loss: 44.5071\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.1618 - val_loss: 44.6925\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1901 - val_loss: 44.6446\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.6405 - val_loss: 47.1978\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.3659 - val_loss: 44.4790\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.6283 - val_loss: 44.7393\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.1383 - val_loss: 44.4347\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2277 - val_loss: 45.1305\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.4107 - val_loss: 44.4992\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9388 - val_loss: 44.5818\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5126 - val_loss: 47.0006\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2146 - val_loss: 45.1257\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6251 - val_loss: 46.0807\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6590 - val_loss: 44.6328\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.2912 - val_loss: 47.2361\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8178 - val_loss: 44.2359\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3757 - val_loss: 45.0823\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5857 - val_loss: 46.4843\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7974 - val_loss: 45.2309\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4475 - val_loss: 45.6192\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.5323 - val_loss: 49.4667\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1262 - val_loss: 44.7446\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4557 - val_loss: 44.9341\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1311 - val_loss: 46.5259\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.2391 - val_loss: 44.8394\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6198 - val_loss: 44.4335\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6451 - val_loss: 46.9315\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.5012 - val_loss: 46.2451\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.9840 - val_loss: 45.2991\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1394 - val_loss: 44.4609\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2389 - val_loss: 45.6574\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.8648 - val_loss: 45.1322\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.5757 - val_loss: 44.8525\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.5427 - val_loss: 44.6676\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.8316 - val_loss: 46.9237\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.4729 - val_loss: 44.7800\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5859 - val_loss: 45.0584\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.1323 - val_loss: 44.4286\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8125 - val_loss: 45.8104\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2416 - val_loss: 44.8427\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.1869 - val_loss: 46.2668\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9643 - val_loss: 44.6106\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4994 - val_loss: 44.4072\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.3192 - val_loss: 46.8793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6283 - val_loss: 45.8368\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.6125 - val_loss: 45.7425\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.9814 - val_loss: 45.0012\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8146 - val_loss: 44.8136\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8909 - val_loss: 44.5277\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.4266 - val_loss: 46.6504\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.9176 - val_loss: 44.7832\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.9145 - val_loss: 44.6964\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7894 - val_loss: 44.5366\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4910 - val_loss: 45.1255\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.6768 - val_loss: 44.5422\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8271 - val_loss: 45.9442\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.5564 - val_loss: 45.7624\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 46.6951 - val_loss: 54.7146\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 53.8455 - val_loss: 44.5610\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.2490 - val_loss: 47.3243\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 50.8079 - val_loss: 45.1057\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6723 - val_loss: 45.6512\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8138 - val_loss: 44.4522\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7912 - val_loss: 45.3512\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6073 - val_loss: 44.5196\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7257 - val_loss: 44.6209\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6129 - val_loss: 45.4586\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.5761 - val_loss: 44.4560\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.5732 - val_loss: 45.7078\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.2954 - val_loss: 44.8490\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.6096 - val_loss: 44.4165\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5506 - val_loss: 45.8542\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.0348 - val_loss: 45.0193\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.2204 - val_loss: 45.4775\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.2104 - val_loss: 45.3684\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0473 - val_loss: 45.6855\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2351 - val_loss: 45.6095\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8319 - val_loss: 45.3905\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8030 - val_loss: 44.5116\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.0957 - val_loss: 47.0943\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8791 - val_loss: 44.7256\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0289 - val_loss: 44.8592\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0996 - val_loss: 44.5567\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2098 - val_loss: 45.6344\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.2071 - val_loss: 44.8633\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.4162 - val_loss: 46.4075\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.1223 - val_loss: 44.9667\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.9244 - val_loss: 44.8782\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4336 - val_loss: 45.3940\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1946 - val_loss: 44.6795\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6077 - val_loss: 44.5561\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6007 - val_loss: 44.7382\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.1660 - val_loss: 45.8699\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6178 - val_loss: 44.8310\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3799 - val_loss: 44.4928\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0159 - val_loss: 44.7778\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.8308 - val_loss: 46.3910\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 52.0795 - val_loss: 44.4989\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.3666 - val_loss: 44.7594\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8801 - val_loss: 44.4699\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.7911 - val_loss: 44.6451\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4699 - val_loss: 44.4480\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4988 - val_loss: 45.2486\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5415 - val_loss: 44.7092\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2534 - val_loss: 44.6453\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.7982 - val_loss: 44.4215\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4737 - val_loss: 44.3867\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1674 - val_loss: 47.2374\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.6110 - val_loss: 44.9091\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.4679 - val_loss: 46.3502\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.3224 - val_loss: 49.5375\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.5469 - val_loss: 44.9862\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.8140 - val_loss: 44.3237\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9564 - val_loss: 44.6230\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4990 - val_loss: 44.4858\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.4142 - val_loss: 44.5915\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.7032 - val_loss: 45.0338\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.1390 - val_loss: 46.8804\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6589 - val_loss: 44.7352\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2796 - val_loss: 47.7583\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.6360 - val_loss: 46.4334\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.5421 - val_loss: 47.5255\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9987 - val_loss: 45.3905\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.8002 - val_loss: 44.5448\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0098 - val_loss: 44.3671\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5852 - val_loss: 48.9167\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.3417 - val_loss: 44.9846\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1217 - val_loss: 45.4878\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9802 - val_loss: 48.3579\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0239 - val_loss: 44.4802\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.3764 - val_loss: 46.5273\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4488 - val_loss: 44.9321\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7623 - val_loss: 45.1967\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7766 - val_loss: 44.6083\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.2882 - val_loss: 44.7167\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.1377 - val_loss: 50.0047\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.2621 - val_loss: 45.0310\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8537 - val_loss: 45.8247\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7064 - val_loss: 45.8105\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.4668 - val_loss: 47.4866\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5042 - val_loss: 44.7798\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2153 - val_loss: 45.1082\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.9767 - val_loss: 44.4761\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5200 - val_loss: 44.8980\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6610 - val_loss: 44.4995\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.0518 - val_loss: 45.3190\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.1204 - val_loss: 44.4524\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2728 - val_loss: 46.1031\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3408 - val_loss: 51.1848\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1035 - val_loss: 46.6638\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.5439 - val_loss: 48.4263\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3790 - val_loss: 44.3439\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6657 - val_loss: 44.5631\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2709 - val_loss: 44.4851\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.1095 - val_loss: 45.5552\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7728 - val_loss: 44.4976\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5397 - val_loss: 44.6477\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5215 - val_loss: 45.1396\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.0080 - val_loss: 44.6425\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7682 - val_loss: 44.4265\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9500 - val_loss: 46.3797\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.3722 - val_loss: 46.1770\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9598 - val_loss: 44.5839\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3212 - val_loss: 50.1806\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1347 - val_loss: 44.4832\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8616 - val_loss: 44.3900\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.2700 - val_loss: 45.6295\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.4559 - val_loss: 46.0914\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.8351 - val_loss: 44.4087\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3582 - val_loss: 55.1247\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 52.1603 - val_loss: 47.3017\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.2920 - val_loss: 49.2166\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.7306 - val_loss: 46.0825\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4914 - val_loss: 44.9011\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8447 - val_loss: 44.6399\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.0126 - val_loss: 47.9939\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.5168 - val_loss: 50.8140\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.3651 - val_loss: 47.3874\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.7650 - val_loss: 44.4893\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7776 - val_loss: 47.8067\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.1929 - val_loss: 47.3373\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.9780 - val_loss: 45.4197\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4192 - val_loss: 44.6806\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.5444 - val_loss: 44.8011\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.7218 - val_loss: 44.6392\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4855 - val_loss: 44.6135\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2641 - val_loss: 44.2021\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8402 - val_loss: 45.3058\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 46.9447 - val_loss: 45.3662\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6321 - val_loss: 45.8144\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.5910 - val_loss: 44.3639\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.4728 - val_loss: 45.4500\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1291 - val_loss: 44.4493\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8499 - val_loss: 44.3390\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6109 - val_loss: 44.2672\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9585 - val_loss: 44.7536\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.2901 - val_loss: 46.3687\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.0626 - val_loss: 46.9251\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.0476 - val_loss: 48.0376\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.4920 - val_loss: 45.6709\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.3055 - val_loss: 45.4334\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.3820 - val_loss: 44.8458\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 4ms/step - loss: 50.7288 - val_loss: 48.7906\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.6014 - val_loss: 48.3255\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.3948 - val_loss: 50.9628\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.2827 - val_loss: 46.2950\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.2264 - val_loss: 44.3790\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9125 - val_loss: 44.5783\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1581 - val_loss: 46.1755\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1128 - val_loss: 44.8675\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3468 - val_loss: 44.8586\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7685 - val_loss: 44.7836\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8898 - val_loss: 45.5270\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.3122 - val_loss: 45.2822\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4207 - val_loss: 47.9748\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6476 - val_loss: 44.1772\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7538 - val_loss: 44.5095\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 50.1314 - val_loss: 44.5728\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.8090 - val_loss: 44.3421\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5442 - val_loss: 45.4659\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7981 - val_loss: 44.6054\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.0922 - val_loss: 48.1759\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.5508 - val_loss: 44.3895\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8356 - val_loss: 46.0706\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5299 - val_loss: 44.6828\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4908 - val_loss: 45.2797\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8943 - val_loss: 44.6172\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.4661 - val_loss: 44.5537\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1751 - val_loss: 45.1871\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.3703 - val_loss: 44.7478\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9993 - val_loss: 44.6176\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6495 - val_loss: 45.4780\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1049 - val_loss: 45.2998\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 51.3967 - val_loss: 50.2997\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.8577 - val_loss: 45.5792\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8949 - val_loss: 44.3428\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3051 - val_loss: 44.8731\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.8711 - val_loss: 44.6750\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.0626 - val_loss: 44.3276\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.8265 - val_loss: 52.9219\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.7404 - val_loss: 44.9935\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.4426 - val_loss: 44.7466\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.2020 - val_loss: 46.1702\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.8120 - val_loss: 49.7030\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.7954 - val_loss: 47.6038\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5398 - val_loss: 44.5056\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4762 - val_loss: 45.6332\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4812 - val_loss: 45.9101\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.4326 - val_loss: 46.1761\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9966 - val_loss: 44.9763\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4352 - val_loss: 45.1791\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.7077 - val_loss: 44.4811\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.1572 - val_loss: 44.2615\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0686 - val_loss: 45.7942\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.9577 - val_loss: 45.6154\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1708 - val_loss: 46.4642\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2981 - val_loss: 45.4647\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9532 - val_loss: 44.2356\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7446 - val_loss: 44.4007\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0004 - val_loss: 44.9462\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.9969 - val_loss: 44.5846\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9372 - val_loss: 51.3219\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5981 - val_loss: 44.3282\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1143 - val_loss: 44.2741\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7875 - val_loss: 44.4299\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.0064 - val_loss: 45.6464\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 48.0214 - val_loss: 45.6383\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.8233 - val_loss: 47.9032\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 47.7669 - val_loss: 46.4657\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.7136 - val_loss: 44.4371\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7242 - val_loss: 44.4993\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.5009 - val_loss: 44.8063\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1336 - val_loss: 44.7191\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.1898 - val_loss: 45.7019\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4135 - val_loss: 46.1010\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7439 - val_loss: 48.6777\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 52.4725 - val_loss: 47.8767\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9510 - val_loss: 47.6924\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.3665 - val_loss: 50.4866\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 49.2196 - val_loss: 44.5966\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7305 - val_loss: 44.2993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3335 - val_loss: 44.6019\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8841 - val_loss: 44.7147\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9613 - val_loss: 44.6691\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4812 - val_loss: 44.7235\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0412 - val_loss: 44.3556\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 48.7611 - val_loss: 44.3516\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1774 - val_loss: 44.7656\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.7255 - val_loss: 45.4487\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5593 - val_loss: 45.1594\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3294 - val_loss: 46.0742\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8509 - val_loss: 44.4767\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7313 - val_loss: 45.7213\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1577 - val_loss: 48.4278\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.2798 - val_loss: 44.4726\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.4032 - val_loss: 44.6509\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.5916 - val_loss: 44.3397\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.2447 - val_loss: 44.4643\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2757 - val_loss: 44.5728\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2781 - val_loss: 44.7184\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.1271 - val_loss: 44.4888\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7116 - val_loss: 44.4547\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4030 - val_loss: 44.6725\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0671 - val_loss: 44.4971\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4164 - val_loss: 44.6124\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.5923 - val_loss: 46.0048\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7872 - val_loss: 47.0374\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.1850 - val_loss: 44.7206\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0736 - val_loss: 45.6348\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 47.5048 - val_loss: 44.7762\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2429 - val_loss: 44.8021\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8298 - val_loss: 44.6337\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.7792 - val_loss: 44.9613\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5316 - val_loss: 44.2995\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5520 - val_loss: 44.2875\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3441 - val_loss: 44.9882\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.1512 - val_loss: 45.7989\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1199 - val_loss: 44.9557\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3286 - val_loss: 46.8674\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.4649 - val_loss: 46.3036\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5146 - val_loss: 45.3423\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.6563 - val_loss: 45.0646\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0438 - val_loss: 50.3008\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.0885 - val_loss: 45.3889\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.2614 - val_loss: 44.4747\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3846 - val_loss: 49.2171\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.2252 - val_loss: 44.6600\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4725 - val_loss: 48.9661\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.4397 - val_loss: 44.6072\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.6825 - val_loss: 44.5796\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.1215 - val_loss: 44.6565\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7481 - val_loss: 44.9850\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8461 - val_loss: 50.8673\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.7598 - val_loss: 49.7393\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 50.0827 - val_loss: 45.0868\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.3342 - val_loss: 44.9928\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7164 - val_loss: 44.2554\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0580 - val_loss: 47.0409\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.7046 - val_loss: 44.6489\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7807 - val_loss: 45.9052\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2647 - val_loss: 44.9568\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5327 - val_loss: 44.2299\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6182 - val_loss: 45.2794\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7518 - val_loss: 44.2735\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0763 - val_loss: 44.2715\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6269 - val_loss: 47.0044\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8488 - val_loss: 48.7994\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6984 - val_loss: 48.4841\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9664 - val_loss: 45.7196\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 50.4426 - val_loss: 44.6353\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.5392 - val_loss: 44.7843\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.3049 - val_loss: 45.1414\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8606 - val_loss: 44.7801\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.5081 - val_loss: 44.3095\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9330 - val_loss: 48.2496\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.3799 - val_loss: 46.5294\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.8043 - val_loss: 45.4033\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 46.6983 - val_loss: 46.7321\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.4657 - val_loss: 45.2119\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 4ms/step - loss: 49.4455 - val_loss: 44.5735\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.2418 - val_loss: 44.7109\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.3703 - val_loss: 50.3199\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 54.2687 - val_loss: 48.1837\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6780 - val_loss: 44.3644\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.6856 - val_loss: 44.7511\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4526 - val_loss: 44.3022\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.3996 - val_loss: 46.1543\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6241 - val_loss: 46.0964\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6147 - val_loss: 46.5034\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3418 - val_loss: 44.4365\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.3320 - val_loss: 44.9466\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.6287 - val_loss: 44.7867\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1368 - val_loss: 49.4687\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3110 - val_loss: 46.1437\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.9784 - val_loss: 44.1221\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.6745 - val_loss: 44.2942\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3057 - val_loss: 44.6530\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2016 - val_loss: 45.5887\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.6217 - val_loss: 46.6320\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8252 - val_loss: 46.4082\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2665 - val_loss: 47.1272\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7994 - val_loss: 44.5525\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6384 - val_loss: 44.5161\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.7952 - val_loss: 47.7798\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.0181 - val_loss: 46.6259\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.3506 - val_loss: 44.9339\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.8368 - val_loss: 44.4160\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5833 - val_loss: 44.9445\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4875 - val_loss: 44.5239\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6168 - val_loss: 47.4930\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8551 - val_loss: 46.7553\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2692 - val_loss: 44.5543\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.9557 - val_loss: 49.2473\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.2434 - val_loss: 46.6927\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.5851 - val_loss: 46.6992\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.6762 - val_loss: 52.0554\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.9738 - val_loss: 44.5328\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.0866 - val_loss: 44.6391\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6468 - val_loss: 44.6912\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.4118 - val_loss: 46.0079\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.8578 - val_loss: 44.4683\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1057 - val_loss: 44.5696\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7128 - val_loss: 44.6964\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7676 - val_loss: 44.6522\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7873 - val_loss: 44.7778\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8351 - val_loss: 44.5073\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5592 - val_loss: 44.3977\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0728 - val_loss: 45.3705\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9217 - val_loss: 44.6603\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 47.2091 - val_loss: 45.2089\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3363 - val_loss: 46.1681\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.7547 - val_loss: 48.2808\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.5771 - val_loss: 44.8997\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.5427 - val_loss: 44.5141\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5879 - val_loss: 47.5059\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.7328 - val_loss: 44.7718\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0570 - val_loss: 44.8074\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.0298 - val_loss: 49.7415\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.0764 - val_loss: 51.9246\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4961 - val_loss: 44.6171\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2749 - val_loss: 44.6857\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.8661 - val_loss: 44.2514\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6367 - val_loss: 44.8867\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4977 - val_loss: 44.6691\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.1762 - val_loss: 44.3687\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.2158 - val_loss: 45.2555\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.7945 - val_loss: 46.6951\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7091 - val_loss: 45.2155\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.5703 - val_loss: 44.3628\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6961 - val_loss: 45.3758\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9555 - val_loss: 47.3868\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.7873 - val_loss: 48.5605\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7062 - val_loss: 45.1541\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2402 - val_loss: 45.5410\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5792 - val_loss: 45.1432\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4637 - val_loss: 44.3466\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8869 - val_loss: 44.2751\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5704 - val_loss: 44.6696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.3438 - val_loss: 44.8004\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.3092 - val_loss: 45.0994\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1613 - val_loss: 45.4814\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2073 - val_loss: 44.6517\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4530 - val_loss: 45.5586\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5181 - val_loss: 45.2209\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8294 - val_loss: 44.6970\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6490 - val_loss: 44.8289\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9734 - val_loss: 44.8865\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1504 - val_loss: 44.9021\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6775 - val_loss: 44.2410\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.0766 - val_loss: 49.7985\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.7726 - val_loss: 55.8586\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.9479 - val_loss: 49.5212\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.5285 - val_loss: 50.0074\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.9951 - val_loss: 48.2469\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4802 - val_loss: 44.4741\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5511 - val_loss: 44.8372\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.1473 - val_loss: 44.4649\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2857 - val_loss: 44.7733\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.6844 - val_loss: 44.8477\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5459 - val_loss: 44.8582\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0375 - val_loss: 45.0985\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.7391 - val_loss: 47.0586\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2230 - val_loss: 45.9731\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3118 - val_loss: 46.2787\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 50.9407 - val_loss: 45.3928\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0959 - val_loss: 45.5739\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5820 - val_loss: 45.8861\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9805 - val_loss: 44.4077\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.4069 - val_loss: 44.2820\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.4730 - val_loss: 44.6066\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9643 - val_loss: 46.0448\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9749 - val_loss: 44.3948\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.2967 - val_loss: 44.8279\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7763 - val_loss: 45.6815\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.0030 - val_loss: 45.0065\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6613 - val_loss: 46.1616\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7258 - val_loss: 44.3437\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.4691 - val_loss: 46.4126\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8556 - val_loss: 44.5857\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.9308 - val_loss: 44.7408\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8842 - val_loss: 45.3536\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.7385 - val_loss: 44.9518\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.2039 - val_loss: 46.9067\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 51.4935 - val_loss: 44.6792\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.4476 - val_loss: 44.6276\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6339 - val_loss: 44.4187\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0916 - val_loss: 45.5619\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.9747 - val_loss: 45.2854\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.0983 - val_loss: 44.2772\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1377 - val_loss: 44.3876\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4614 - val_loss: 44.6608\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0142 - val_loss: 44.0380\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4400 - val_loss: 44.4396\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5182 - val_loss: 45.4427\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8563 - val_loss: 45.0815\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5009 - val_loss: 47.9250\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9807 - val_loss: 45.4331\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3736 - val_loss: 46.6093\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8099 - val_loss: 44.5372\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0896 - val_loss: 44.7699\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8180 - val_loss: 44.6216\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3735 - val_loss: 44.3269\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4458 - val_loss: 44.9035\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9433 - val_loss: 45.3362\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.7576 - val_loss: 44.3566\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.4179 - val_loss: 50.5977\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.4622 - val_loss: 47.5752\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1734 - val_loss: 44.8464\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3540 - val_loss: 44.1706\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 48.8750 - val_loss: 44.5714\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5349 - val_loss: 44.6157\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4905 - val_loss: 45.0796\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4471 - val_loss: 44.8202\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.0286 - val_loss: 47.3729\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.6496 - val_loss: 47.5972\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.6334 - val_loss: 44.2395\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 6ms/step - loss: 47.8698 - val_loss: 44.3599\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3185 - val_loss: 44.5124\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7609 - val_loss: 44.0335\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5000 - val_loss: 44.8256\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1589 - val_loss: 46.9552\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6633 - val_loss: 45.5852\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4890 - val_loss: 44.9378\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8849 - val_loss: 45.6469\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.8900 - val_loss: 46.3533\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.7569 - val_loss: 47.3970\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.9943 - val_loss: 46.7281\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.2566 - val_loss: 44.1511\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.5093 - val_loss: 46.1650\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3433 - val_loss: 47.4414\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2322 - val_loss: 47.7142\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.3194 - val_loss: 46.8305\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.3399 - val_loss: 47.1796\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.3745 - val_loss: 44.6437\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5185 - val_loss: 45.6621\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.0541 - val_loss: 52.9175\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.8603 - val_loss: 48.1043\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3847 - val_loss: 46.3589\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6897 - val_loss: 46.7646\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6522 - val_loss: 44.5165\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.2632 - val_loss: 44.7147\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.8418 - val_loss: 44.3960\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5283 - val_loss: 44.4549\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.6867 - val_loss: 44.8822\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8018 - val_loss: 44.9639\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0658 - val_loss: 46.7079\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4939 - val_loss: 45.8876\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9072 - val_loss: 44.5781\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3837 - val_loss: 44.7750\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7058 - val_loss: 44.7397\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.6896 - val_loss: 44.5245\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5375 - val_loss: 44.1230\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.2532 - val_loss: 45.8796\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7049 - val_loss: 45.5155\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5129 - val_loss: 53.7688\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 51.7701 - val_loss: 57.1847\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 53.1043 - val_loss: 44.4369\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.1078 - val_loss: 44.9230\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.8372 - val_loss: 45.5600\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1203 - val_loss: 45.4552\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3988 - val_loss: 44.8708\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9501 - val_loss: 45.0573\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0657 - val_loss: 44.8901\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0212 - val_loss: 46.8509\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.7889 - val_loss: 50.6454\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.3979 - val_loss: 45.1805\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8607 - val_loss: 44.4155\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5302 - val_loss: 45.2054\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6628 - val_loss: 44.2954\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4566 - val_loss: 44.4048\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7614 - val_loss: 44.8939\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3752 - val_loss: 46.0336\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5601 - val_loss: 45.1616\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8359 - val_loss: 44.3534\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.1785 - val_loss: 48.9089\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1063 - val_loss: 44.8633\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.4644 - val_loss: 45.1890\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.4262 - val_loss: 44.5857\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9632 - val_loss: 44.5132\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8030 - val_loss: 44.2571\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.6287 - val_loss: 45.8986\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.8758 - val_loss: 45.0528\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.0087 - val_loss: 44.3343\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5668 - val_loss: 44.5307\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5543 - val_loss: 44.5235\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.7998 - val_loss: 47.4609\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0229 - val_loss: 47.2015\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8195 - val_loss: 44.5284\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1569 - val_loss: 47.7664\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9075 - val_loss: 44.9567\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6145 - val_loss: 46.2667\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1032 - val_loss: 44.8240\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4440 - val_loss: 46.4563\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.3621 - val_loss: 45.6206\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.4038 - val_loss: 46.1428\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.5874 - val_loss: 44.8758\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0116 - val_loss: 44.4245\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6124 - val_loss: 45.5800\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.0984 - val_loss: 44.3830\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6345 - val_loss: 44.6441\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9452 - val_loss: 44.7252\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5095 - val_loss: 45.2953\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7060 - val_loss: 44.3651\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4512 - val_loss: 44.3938\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0317 - val_loss: 44.7031\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3488 - val_loss: 46.7035\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5376 - val_loss: 47.5783\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.8802 - val_loss: 47.9171\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.7329 - val_loss: 44.6289\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 47.7634 - val_loss: 45.5799\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0587 - val_loss: 44.6886\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6255 - val_loss: 45.1318\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.6989 - val_loss: 46.3851\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.9043 - val_loss: 45.0312\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2089 - val_loss: 44.4219\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.2640 - val_loss: 49.0948\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9947 - val_loss: 44.3614\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.8296 - val_loss: 45.0881\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.8599 - val_loss: 46.4360\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.3536 - val_loss: 44.4739\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4987 - val_loss: 45.0533\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.5152 - val_loss: 44.5190\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4361 - val_loss: 44.1369\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.1401 - val_loss: 44.9104\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.3688 - val_loss: 44.6157\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.1703 - val_loss: 48.6890\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.8614 - val_loss: 49.9877\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.3640 - val_loss: 47.0457\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.0536 - val_loss: 44.1649\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5930 - val_loss: 44.2524\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5376 - val_loss: 44.4622\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0089 - val_loss: 47.6952\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 47.9771 - val_loss: 45.1255\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.8526 - val_loss: 48.2740\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 48.2685 - val_loss: 44.7989\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6990 - val_loss: 44.7708\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6674 - val_loss: 44.9046\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.8773 - val_loss: 44.8210\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0179 - val_loss: 44.3535\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6518 - val_loss: 44.1949\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7048 - val_loss: 45.7837\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4680 - val_loss: 45.2952\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3595 - val_loss: 44.7767\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6219 - val_loss: 44.9485\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5472 - val_loss: 44.4371\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5591 - val_loss: 44.5612\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0253 - val_loss: 50.3332\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2576 - val_loss: 44.6567\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8015 - val_loss: 45.2027\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7683 - val_loss: 47.9576\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.5161 - val_loss: 47.9141\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.8914 - val_loss: 45.1792\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.3108 - val_loss: 44.6347\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9090 - val_loss: 44.9382\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6306 - val_loss: 44.3920\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5579 - val_loss: 45.1077\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6643 - val_loss: 44.5094\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.3185 - val_loss: 44.5099\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4434 - val_loss: 44.8163\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.3057 - val_loss: 44.2663\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.1932 - val_loss: 44.2960\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3933 - val_loss: 44.5394\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0368 - val_loss: 44.4082\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5263 - val_loss: 44.4147\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0074 - val_loss: 45.6493\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3128 - val_loss: 50.9210\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.4979 - val_loss: 47.0842\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.4433 - val_loss: 45.1409\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.6058 - val_loss: 44.8893\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6719 - val_loss: 46.9670\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.1226 - val_loss: 44.3427\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.6689 - val_loss: 44.7213\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 50.2088 - val_loss: 44.2768\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.0260 - val_loss: 44.4484\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4741 - val_loss: 45.6560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.1907 - val_loss: 45.2576\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6065 - val_loss: 44.5331\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.6099 - val_loss: 45.2922\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.4863 - val_loss: 47.7376\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5137 - val_loss: 45.2942\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8776 - val_loss: 44.8459\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.4989 - val_loss: 44.6619\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.4356 - val_loss: 44.9706\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.1146 - val_loss: 44.7879\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.4525 - val_loss: 44.5066\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.3929 - val_loss: 44.1935\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4026 - val_loss: 45.2632\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.3211 - val_loss: 46.6332\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5947 - val_loss: 45.2080\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6864 - val_loss: 44.3420\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1198 - val_loss: 44.8683\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1499 - val_loss: 47.3116\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.2711 - val_loss: 47.3230\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.0313 - val_loss: 44.3338\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.2094 - val_loss: 46.1548\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7393 - val_loss: 44.2355\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6906 - val_loss: 45.7747\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.1738 - val_loss: 49.4347\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.8671 - val_loss: 47.2468\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2445 - val_loss: 44.1340\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4213 - val_loss: 44.4361\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6140 - val_loss: 44.2484\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.2113 - val_loss: 44.7966\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7882 - val_loss: 45.4671\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6180 - val_loss: 45.3617\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.3865 - val_loss: 45.6191\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7307 - val_loss: 44.6743\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4201 - val_loss: 44.4668\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9583 - val_loss: 44.6032\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.6160 - val_loss: 45.2503\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6861 - val_loss: 44.4998\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2828 - val_loss: 44.7030\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5762 - val_loss: 44.3654\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.9797 - val_loss: 44.5221\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.9087 - val_loss: 44.9561\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8997 - val_loss: 45.0800\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6118 - val_loss: 44.4356\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1530 - val_loss: 44.4793\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.7434 - val_loss: 45.0437\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9245 - val_loss: 47.8002\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6771 - val_loss: 44.4242\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.7396 - val_loss: 44.4323\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9645 - val_loss: 45.6199\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8676 - val_loss: 44.6387\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6665 - val_loss: 44.6358\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 50.0845 - val_loss: 47.0274\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.6227 - val_loss: 47.7239\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.0107 - val_loss: 44.6147\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.9139 - val_loss: 45.2663\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 48.9612 - val_loss: 45.3056\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.7529 - val_loss: 44.2241\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2414 - val_loss: 44.2517\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.1864 - val_loss: 45.1670\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.4677 - val_loss: 45.8106\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5332 - val_loss: 47.4482\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1315 - val_loss: 45.1097\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.2082 - val_loss: 44.6313\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9943 - val_loss: 47.9425\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.2441 - val_loss: 44.3120\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.8167 - val_loss: 44.8672\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.5208 - val_loss: 44.6059\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.1988 - val_loss: 44.6593\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1505 - val_loss: 46.8329\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.7587 - val_loss: 44.5166\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 47.2822 - val_loss: 44.6333\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.5251 - val_loss: 46.1327\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.9403 - val_loss: 46.3527\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 46.9751 - val_loss: 45.9412\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.7208 - val_loss: 46.2360\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.0465 - val_loss: 45.0099\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9400 - val_loss: 44.4884\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3156 - val_loss: 44.5996\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5997 - val_loss: 44.2555\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8326 - val_loss: 48.2839\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.5880 - val_loss: 45.2507\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8098 - val_loss: 44.8814\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3415 - val_loss: 44.4991\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.7991 - val_loss: 44.9703\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7845 - val_loss: 45.9530\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5774 - val_loss: 48.0226\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.5802 - val_loss: 48.5479\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9941 - val_loss: 44.7036\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8566 - val_loss: 44.4285\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0074 - val_loss: 46.1220\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.0895 - val_loss: 49.6803\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1465 - val_loss: 46.8731\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5276 - val_loss: 44.8189\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.9492 - val_loss: 45.5888\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1270 - val_loss: 46.0263\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.9313 - val_loss: 44.7006\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.4069 - val_loss: 50.9476\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.1423 - val_loss: 45.8482\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.9778 - val_loss: 45.5920\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.6383 - val_loss: 44.7264\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.2210 - val_loss: 45.6547\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8001 - val_loss: 44.3621\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.4494 - val_loss: 46.2767\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9556 - val_loss: 45.0629\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3214 - val_loss: 44.5807\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.6097 - val_loss: 44.5304\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6496 - val_loss: 45.2325\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.2207 - val_loss: 45.9539\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 49.3551 - val_loss: 46.3868\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.0882 - val_loss: 46.8696\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.4435 - val_loss: 45.1737\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8437 - val_loss: 44.5610\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.4789 - val_loss: 47.9726\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9152 - val_loss: 45.5231\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9908 - val_loss: 44.8992\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.1360 - val_loss: 44.1993\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8335 - val_loss: 45.4560\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.6907 - val_loss: 44.9142\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7276 - val_loss: 47.9931\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5058 - val_loss: 46.0978\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 47.3844 - val_loss: 45.1207\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9281 - val_loss: 44.5244\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.2896 - val_loss: 44.7136\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.6443 - val_loss: 44.2724\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4811 - val_loss: 44.8390\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.2357 - val_loss: 45.5861\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.6348 - val_loss: 45.6002\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.0550 - val_loss: 46.8052\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.3612 - val_loss: 45.0616\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 47.6191 - val_loss: 44.4636\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.9270 - val_loss: 45.9603\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7090 - val_loss: 44.3273\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4082 - val_loss: 44.3541\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.6299 - val_loss: 44.4293\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8938 - val_loss: 44.8196\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 47.9314 - val_loss: 44.4739\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5117 - val_loss: 44.3853\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1594 - val_loss: 44.4943\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.5632 - val_loss: 44.5562\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0110 - val_loss: 43.8550\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.1740 - val_loss: 46.3099\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.8288 - val_loss: 46.8925\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.4214 - val_loss: 47.4748\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.9462 - val_loss: 46.0874\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8306 - val_loss: 44.0776\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7537 - val_loss: 44.3111\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.7832 - val_loss: 45.6714\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8211 - val_loss: 45.1119\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 50.3318 - val_loss: 44.2886\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1024 - val_loss: 44.8270\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 47.7589 - val_loss: 45.6140\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7877 - val_loss: 44.2069\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.7698 - val_loss: 47.9342\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1696 - val_loss: 47.8862\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 51.8870 - val_loss: 48.2970\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.9916 - val_loss: 48.4226\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.3002 - val_loss: 45.8692\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1391 - val_loss: 46.1805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9286 - val_loss: 44.4412\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.8046 - val_loss: 44.1867\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4551 - val_loss: 44.9132\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.5019 - val_loss: 45.5974\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.8379 - val_loss: 48.1733\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.2889 - val_loss: 44.7063\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1112 - val_loss: 47.2046\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 48.5215 - val_loss: 49.4290\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6884 - val_loss: 43.9247\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8248 - val_loss: 44.2381\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.1972 - val_loss: 44.5057\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3024 - val_loss: 45.9398\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.7484 - val_loss: 44.5664\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.1574 - val_loss: 44.7379\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.6449 - val_loss: 46.5544\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.3625 - val_loss: 50.9520\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 52.7157 - val_loss: 47.6871\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.3338 - val_loss: 44.7164\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6777 - val_loss: 44.7657\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7740 - val_loss: 44.9233\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.4612 - val_loss: 46.1964\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1229 - val_loss: 44.4315\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3682 - val_loss: 44.5534\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4505 - val_loss: 44.2935\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7112 - val_loss: 46.1469\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1838 - val_loss: 46.4767\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 46.2486 - val_loss: 48.9826\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 52.6196 - val_loss: 50.1475\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.9503 - val_loss: 45.2603\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9568 - val_loss: 45.5270\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.1403 - val_loss: 44.2778\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5558 - val_loss: 44.7531\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6692 - val_loss: 44.4744\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3298 - val_loss: 44.5068\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.0279 - val_loss: 44.5829\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.7281 - val_loss: 47.8199\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6373 - val_loss: 53.9778\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.7688 - val_loss: 45.0046\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9637 - val_loss: 44.6444\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6889 - val_loss: 44.4671\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4543 - val_loss: 44.9400\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.3493 - val_loss: 47.4275\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.1168 - val_loss: 45.0206\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.9031 - val_loss: 44.5921\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5712 - val_loss: 44.8505\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4498 - val_loss: 44.4369\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7321 - val_loss: 44.5654\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.3283 - val_loss: 44.1875\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8720 - val_loss: 47.3040\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3211 - val_loss: 45.3603\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9521 - val_loss: 45.9502\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5515 - val_loss: 44.2381\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4301 - val_loss: 44.7147\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.2396 - val_loss: 45.0237\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5938 - val_loss: 44.2073\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.3922 - val_loss: 44.3800\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.8218 - val_loss: 45.4749\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.0569 - val_loss: 49.0989\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.5486 - val_loss: 44.2546\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.3649 - val_loss: 44.4018\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7566 - val_loss: 45.9406\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.4839 - val_loss: 45.1301\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0678 - val_loss: 44.5808\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7386 - val_loss: 46.9837\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5152 - val_loss: 44.1772\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3521 - val_loss: 46.2090\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4518 - val_loss: 47.0866\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7349 - val_loss: 44.7632\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5785 - val_loss: 44.8499\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5356 - val_loss: 44.4007\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.3287 - val_loss: 44.7348\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.6360 - val_loss: 44.1089\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4468 - val_loss: 44.8867\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.3721 - val_loss: 46.6446\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7193 - val_loss: 50.2203\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.3020 - val_loss: 45.4788\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.2804 - val_loss: 54.5585\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 48.5464 - val_loss: 44.8151\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8943 - val_loss: 44.6212\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9480 - val_loss: 44.3662\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8593 - val_loss: 44.2850\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6739 - val_loss: 44.2711\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.0709 - val_loss: 45.6421\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2389 - val_loss: 48.7529\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9434 - val_loss: 45.2823\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.4488 - val_loss: 48.8273\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8210 - val_loss: 44.6675\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4464 - val_loss: 44.6078\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.1928 - val_loss: 44.4721\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6152 - val_loss: 44.7700\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.2436 - val_loss: 44.6565\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 50.4301 - val_loss: 50.4437\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.8167 - val_loss: 45.5163\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.3481 - val_loss: 48.4445\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8585 - val_loss: 45.3966\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.1839 - val_loss: 49.7379\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.7570 - val_loss: 45.2140\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9888 - val_loss: 48.5429\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.7947 - val_loss: 44.4421\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8245 - val_loss: 45.2832\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.1293 - val_loss: 48.2403\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6782 - val_loss: 45.2971\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.5990 - val_loss: 44.1845\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3925 - val_loss: 44.4459\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7887 - val_loss: 44.7389\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9063 - val_loss: 44.4939\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6315 - val_loss: 44.3435\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4956 - val_loss: 44.3584\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.1807 - val_loss: 45.1408\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6987 - val_loss: 44.1319\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5651 - val_loss: 44.7882\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 47.9687 - val_loss: 44.7406\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3754 - val_loss: 44.3240\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7882 - val_loss: 44.7009\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5467 - val_loss: 44.3369\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3040 - val_loss: 47.9212\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.0347 - val_loss: 44.5380\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.2737 - val_loss: 44.8099\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9662 - val_loss: 45.8811\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7419 - val_loss: 44.6358\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.4732 - val_loss: 46.9733\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.8629 - val_loss: 44.8185\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8872 - val_loss: 45.3210\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5144 - val_loss: 44.1890\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.7979 - val_loss: 44.8682\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2996 - val_loss: 43.9988\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.3951 - val_loss: 46.0722\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8358 - val_loss: 44.8830\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.6924 - val_loss: 44.0797\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7252 - val_loss: 44.2771\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7508 - val_loss: 45.2879\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0796 - val_loss: 46.2973\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8709 - val_loss: 46.0322\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.0687 - val_loss: 44.1446\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9740 - val_loss: 44.6792\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.4374 - val_loss: 45.1205\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4887 - val_loss: 44.2504\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0082 - val_loss: 45.2052\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 47.8416 - val_loss: 45.3756\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 50.0776 - val_loss: 44.2410\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.1871 - val_loss: 45.2163\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 48.7761 - val_loss: 44.6124\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.6628 - val_loss: 44.9212\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5538 - val_loss: 46.7536\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.5918 - val_loss: 49.0423\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4030 - val_loss: 44.2865\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9272 - val_loss: 44.6656\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.2590 - val_loss: 44.6925\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6754 - val_loss: 44.9830\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.3990 - val_loss: 45.2807\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2829 - val_loss: 44.2481\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5796 - val_loss: 44.5682\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.1819 - val_loss: 45.3634\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0117 - val_loss: 44.0962\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3798 - val_loss: 47.3329\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.9974 - val_loss: 44.7505\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1368 - val_loss: 44.6843\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.8817 - val_loss: 44.6166\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 47.8836 - val_loss: 44.6518\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4189 - val_loss: 45.1682\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8531 - val_loss: 44.1374\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.4184 - val_loss: 44.3958\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6348 - val_loss: 45.3396\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3431 - val_loss: 50.6898\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.2143 - val_loss: 44.2905\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3668 - val_loss: 44.3228\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 47.5771 - val_loss: 46.1884\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6754 - val_loss: 45.3970\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.4217 - val_loss: 49.9007\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1605 - val_loss: 44.5487\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8071 - val_loss: 44.6055\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9348 - val_loss: 44.2626\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 52.0560 - val_loss: 44.1941\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4371 - val_loss: 44.2786\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.3347 - val_loss: 46.0000\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1882 - val_loss: 47.2278\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.3777 - val_loss: 47.3203\n",
      "10/10 [==============================] - 0s 0s/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 47.3487 - val_loss: 44.6579\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6707 - val_loss: 44.4267\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1076 - val_loss: 45.7862\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4883 - val_loss: 46.4324\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9343 - val_loss: 48.4058\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8360 - val_loss: 46.3252\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1371 - val_loss: 44.6281\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.9232 - val_loss: 44.5938\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0354 - val_loss: 48.3891\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.0875 - val_loss: 44.3593\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5725 - val_loss: 44.8348\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5286 - val_loss: 45.1173\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.3611 - val_loss: 44.9016\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.0852 - val_loss: 45.0123\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.9870 - val_loss: 44.3579\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6287 - val_loss: 44.9460\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.1555 - val_loss: 45.3308\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.2374 - val_loss: 44.5790\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1386 - val_loss: 45.1486\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9648 - val_loss: 45.0145\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.1481 - val_loss: 48.6291\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8041 - val_loss: 44.5957\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.3597 - val_loss: 44.5181\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.3074 - val_loss: 44.2078\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0318 - val_loss: 44.7460\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.3617 - val_loss: 44.4806\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0173 - val_loss: 45.6850\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7915 - val_loss: 45.3871\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.5719 - val_loss: 44.6868\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5813 - val_loss: 44.4816\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5918 - val_loss: 44.6470\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.1504 - val_loss: 44.9880\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.1847 - val_loss: 46.1550\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1327 - val_loss: 45.4621\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 47.9594 - val_loss: 46.1473\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0795 - val_loss: 46.9995\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 46.7576 - val_loss: 47.7127\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.9128 - val_loss: 48.0833\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.6355 - val_loss: 45.2070\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5069 - val_loss: 44.3596\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.6014 - val_loss: 46.2850\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1312 - val_loss: 44.5168\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.8937 - val_loss: 44.4528\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5899 - val_loss: 44.4897\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4827 - val_loss: 45.1262\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4876 - val_loss: 44.4030\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.7406 - val_loss: 47.0689\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7919 - val_loss: 44.4817\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5233 - val_loss: 44.3500\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7946 - val_loss: 45.4364\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.1898 - val_loss: 47.4576\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.0891 - val_loss: 44.3652\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.2277 - val_loss: 44.3835\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.2601 - val_loss: 45.8302\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4146 - val_loss: 44.5113\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.1985 - val_loss: 44.6771\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5954 - val_loss: 45.4161\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7168 - val_loss: 44.2007\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0126 - val_loss: 44.0635\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5582 - val_loss: 45.7887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.8460 - val_loss: 44.9469\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.7555 - val_loss: 44.4938\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4303 - val_loss: 47.9514\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.2765 - val_loss: 45.1403\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5967 - val_loss: 44.4225\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3385 - val_loss: 45.3983\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.3725 - val_loss: 45.1438\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.7767 - val_loss: 48.4245\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.5617 - val_loss: 45.1300\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.1863 - val_loss: 45.7472\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5068 - val_loss: 46.9280\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6092 - val_loss: 46.3609\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 50.8551 - val_loss: 45.0214\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2673 - val_loss: 45.0736\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0669 - val_loss: 46.8427\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.0972 - val_loss: 48.4440\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1238 - val_loss: 47.6887\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0417 - val_loss: 45.4867\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 51.7382 - val_loss: 46.4473\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 50.7313 - val_loss: 47.5776\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.2995 - val_loss: 45.8712\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9511 - val_loss: 44.4918\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.6005 - val_loss: 45.0580\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.7558 - val_loss: 44.4872\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0952 - val_loss: 44.5354\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.0581 - val_loss: 44.8148\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1890 - val_loss: 46.0254\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3878 - val_loss: 45.1575\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2561 - val_loss: 44.7001\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3215 - val_loss: 44.3583\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7177 - val_loss: 44.3837\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9847 - val_loss: 44.6619\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6765 - val_loss: 44.5022\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7833 - val_loss: 44.9539\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.1753 - val_loss: 44.5562\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.8902 - val_loss: 44.5204\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1987 - val_loss: 44.6840\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.1685 - val_loss: 46.3141\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.5097 - val_loss: 44.4578\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4289 - val_loss: 44.8448\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 47.3868 - val_loss: 44.2083\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6374 - val_loss: 45.0212\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6649 - val_loss: 46.2724\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.9521 - val_loss: 44.4153\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0436 - val_loss: 44.1153\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.7924 - val_loss: 44.8571\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0938 - val_loss: 44.7565\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.3045 - val_loss: 45.1774\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3839 - val_loss: 44.7388\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.1873 - val_loss: 45.3001\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.2272 - val_loss: 44.6985\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5017 - val_loss: 44.4331\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3455 - val_loss: 44.7444\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 46.8736 - val_loss: 46.6607\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5603 - val_loss: 44.2744\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.2390 - val_loss: 45.2097\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.2647 - val_loss: 44.1909\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8334 - val_loss: 44.5961\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4256 - val_loss: 44.7595\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8690 - val_loss: 44.6623\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.2950 - val_loss: 44.7536\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.6392 - val_loss: 44.3679\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.2705 - val_loss: 44.1809\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.7558 - val_loss: 45.7117\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0625 - val_loss: 44.6277\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.8669 - val_loss: 44.8443\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.3341 - val_loss: 44.2151\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.2157 - val_loss: 48.6046\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9321 - val_loss: 46.2613\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5892 - val_loss: 45.0213\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6662 - val_loss: 44.4876\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6684 - val_loss: 44.6873\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.1132 - val_loss: 44.5676\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2022 - val_loss: 49.7711\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8054 - val_loss: 44.1829\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7702 - val_loss: 48.2764\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8825 - val_loss: 45.5587\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.6685 - val_loss: 44.4009\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0092 - val_loss: 46.1461\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.1808 - val_loss: 48.6263\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.7070 - val_loss: 44.2126\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.2250 - val_loss: 44.6951\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.0632 - val_loss: 45.9113\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.9243 - val_loss: 44.1170\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.4946 - val_loss: 46.5512\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1813 - val_loss: 44.7821\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1775 - val_loss: 46.1268\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0822 - val_loss: 44.0327\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.7209 - val_loss: 44.7776\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.0644 - val_loss: 44.6447\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1823 - val_loss: 44.3418\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.6543 - val_loss: 44.7124\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 50.2937 - val_loss: 46.8528\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.0979 - val_loss: 44.1641\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8119 - val_loss: 47.5423\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.5575 - val_loss: 45.1364\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.3610 - val_loss: 44.7623\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1965 - val_loss: 47.0410\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.6544 - val_loss: 44.7474\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5693 - val_loss: 44.5477\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5529 - val_loss: 44.2712\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.9074 - val_loss: 44.5985\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7031 - val_loss: 44.2471\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0721 - val_loss: 44.3217\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6105 - val_loss: 45.3265\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.1020 - val_loss: 49.4571\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 47.6827 - val_loss: 44.4430\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7679 - val_loss: 47.2132\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.7777 - val_loss: 44.6111\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.6917 - val_loss: 44.5223\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1861 - val_loss: 45.1973\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9238 - val_loss: 44.3037\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1690 - val_loss: 50.2612\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 48.7312 - val_loss: 45.1927\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6335 - val_loss: 44.6473\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4984 - val_loss: 45.6961\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7195 - val_loss: 45.7917\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.5051 - val_loss: 44.1736\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5854 - val_loss: 45.5197\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.5038 - val_loss: 47.4015\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.5197 - val_loss: 44.5794\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.0468 - val_loss: 44.6064\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6990 - val_loss: 44.3152\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 47.6342 - val_loss: 44.5141\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.2565 - val_loss: 47.4402\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0005 - val_loss: 44.7933\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2987 - val_loss: 46.7734\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.3015 - val_loss: 44.1769\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6121 - val_loss: 45.7130\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7811 - val_loss: 45.5333\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4653 - val_loss: 44.5001\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4576 - val_loss: 44.3435\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7724 - val_loss: 44.3588\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.2770 - val_loss: 44.7104\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.3481 - val_loss: 44.4740\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1789 - val_loss: 44.7193\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.4011 - val_loss: 44.2524\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2352 - val_loss: 49.0064\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2630 - val_loss: 44.6510\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6048 - val_loss: 45.8253\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.2636 - val_loss: 45.7182\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3861 - val_loss: 45.2997\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.4961 - val_loss: 45.0450\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.2119 - val_loss: 44.3250\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.3971 - val_loss: 44.6178\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5722 - val_loss: 44.8733\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5929 - val_loss: 46.0010\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8315 - val_loss: 44.2752\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1969 - val_loss: 44.1407\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4054 - val_loss: 46.2781\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9669 - val_loss: 44.3397\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3722 - val_loss: 44.4385\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2242 - val_loss: 44.3327\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1719 - val_loss: 46.2082\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8010 - val_loss: 45.0954\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5028 - val_loss: 44.8270\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1186 - val_loss: 44.5106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5201 - val_loss: 44.0207\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6725 - val_loss: 46.6324\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.3857 - val_loss: 44.3930\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.0771 - val_loss: 45.0557\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.6122 - val_loss: 46.2625\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.8185 - val_loss: 44.9914\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.6147 - val_loss: 46.1820\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.5755 - val_loss: 46.3971\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.4721 - val_loss: 44.2278\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.2315 - val_loss: 45.2020\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7522 - val_loss: 44.4472\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8759 - val_loss: 44.8073\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3643 - val_loss: 44.2886\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6789 - val_loss: 45.2092\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6675 - val_loss: 44.3331\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4133 - val_loss: 44.0790\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0416 - val_loss: 46.3133\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.0168 - val_loss: 44.2683\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.9944 - val_loss: 44.9401\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.3451 - val_loss: 46.0342\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4666 - val_loss: 44.3170\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.3805 - val_loss: 44.0789\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.2869 - val_loss: 49.6029\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.2054 - val_loss: 47.1494\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 50.3682 - val_loss: 48.7994\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.0881 - val_loss: 44.6534\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4816 - val_loss: 44.8258\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8609 - val_loss: 45.2590\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.4877 - val_loss: 44.5123\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0430 - val_loss: 44.5341\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.2875 - val_loss: 48.8993\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4715 - val_loss: 44.9094\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8456 - val_loss: 44.3589\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9480 - val_loss: 44.3822\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3193 - val_loss: 44.5317\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3375 - val_loss: 44.6120\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.1184 - val_loss: 43.9840\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 47.1407 - val_loss: 44.9468\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6864 - val_loss: 46.3435\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.7944 - val_loss: 44.6579\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.4751 - val_loss: 44.5682\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.7771 - val_loss: 44.2178\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.7125 - val_loss: 44.7046\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8578 - val_loss: 43.9961\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7417 - val_loss: 44.3374\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4214 - val_loss: 44.6458\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.3724 - val_loss: 46.3004\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.1559 - val_loss: 46.1345\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6568 - val_loss: 44.6380\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7573 - val_loss: 43.9783\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9975 - val_loss: 44.3078\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.3349 - val_loss: 47.1664\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.6167 - val_loss: 46.6047\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0088 - val_loss: 46.5136\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.4651 - val_loss: 45.5013\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.7648 - val_loss: 44.3306\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9086 - val_loss: 45.8586\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6522 - val_loss: 48.9936\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8576 - val_loss: 44.5074\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4280 - val_loss: 45.1887\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.1428 - val_loss: 47.9540\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2122 - val_loss: 48.2070\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6287 - val_loss: 44.2787\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3240 - val_loss: 44.2932\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.7911 - val_loss: 44.0416\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.3885 - val_loss: 44.2736\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.5196 - val_loss: 44.6260\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.3875 - val_loss: 44.5481\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3847 - val_loss: 45.6540\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0299 - val_loss: 45.0621\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8282 - val_loss: 45.7454\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2253 - val_loss: 45.6547\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.5405 - val_loss: 53.5884\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.7100 - val_loss: 45.0492\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3439 - val_loss: 44.2815\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4699 - val_loss: 47.0813\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7403 - val_loss: 45.2231\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7335 - val_loss: 44.8639\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3245 - val_loss: 44.4756\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6337 - val_loss: 44.3558\n",
      "Epoch 98/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 47.6902 - val_loss: 44.5768\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3426 - val_loss: 48.2644\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.7378 - val_loss: 46.4357\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.5479 - val_loss: 45.9977\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.5915 - val_loss: 45.4305\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.0669 - val_loss: 45.6414\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0494 - val_loss: 47.9859\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.2537 - val_loss: 45.2903\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.4164 - val_loss: 47.2850\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9753 - val_loss: 44.1684\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7120 - val_loss: 44.1321\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5431 - val_loss: 48.9031\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5443 - val_loss: 44.4523\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7722 - val_loss: 45.7596\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.2341 - val_loss: 44.7285\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9758 - val_loss: 44.6815\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.4820 - val_loss: 46.2637\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3174 - val_loss: 47.7301\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1851 - val_loss: 44.3272\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.3566 - val_loss: 44.4213\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.2862 - val_loss: 44.9305\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5713 - val_loss: 44.5022\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4408 - val_loss: 46.7935\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7038 - val_loss: 44.7611\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4029 - val_loss: 43.9670\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8954 - val_loss: 44.0483\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7084 - val_loss: 46.9426\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8154 - val_loss: 48.9632\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8904 - val_loss: 57.1741\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 52.0501 - val_loss: 48.8819\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9901 - val_loss: 45.0681\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.3278 - val_loss: 44.5361\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3025 - val_loss: 45.5772\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4306 - val_loss: 44.8937\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5035 - val_loss: 45.4755\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.2932 - val_loss: 45.0853\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7283 - val_loss: 46.2002\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5682 - val_loss: 50.1191\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.2277 - val_loss: 49.7356\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1001 - val_loss: 44.5080\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6162 - val_loss: 44.4856\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6529 - val_loss: 45.3967\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9553 - val_loss: 44.9983\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4608 - val_loss: 44.4718\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7794 - val_loss: 44.7516\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.5235 - val_loss: 47.5380\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.7067 - val_loss: 47.2135\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 52.5734 - val_loss: 45.7505\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.2971 - val_loss: 51.0564\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5545 - val_loss: 44.5601\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8318 - val_loss: 45.1978\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9592 - val_loss: 44.6928\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8296 - val_loss: 44.8341\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.5841 - val_loss: 46.4476\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3420 - val_loss: 44.4603\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6242 - val_loss: 44.4005\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.5016 - val_loss: 44.2992\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.2831 - val_loss: 45.2557\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4867 - val_loss: 44.6292\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4037 - val_loss: 44.6723\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.2770 - val_loss: 44.2704\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6051 - val_loss: 44.3236\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4192 - val_loss: 45.0299\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9716 - val_loss: 44.0017\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.0933 - val_loss: 45.4337\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.2958 - val_loss: 44.5349\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5881 - val_loss: 45.1190\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4078 - val_loss: 44.5470\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.3323 - val_loss: 44.2578\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4964 - val_loss: 50.1064\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.2809 - val_loss: 50.2330\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 51.9421 - val_loss: 51.5389\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.1383 - val_loss: 51.7753\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.5401 - val_loss: 48.0488\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5975 - val_loss: 45.7758\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8394 - val_loss: 45.6894\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0902 - val_loss: 44.9996\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0525 - val_loss: 44.2441\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.2514 - val_loss: 45.1668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1291 - val_loss: 49.5571\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.6741 - val_loss: 47.3480\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8852 - val_loss: 46.0512\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.0601 - val_loss: 44.5200\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3634 - val_loss: 44.2235\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.2617 - val_loss: 45.3218\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8249 - val_loss: 44.1875\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.2783 - val_loss: 44.8677\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1077 - val_loss: 45.5449\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0456 - val_loss: 44.8932\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6702 - val_loss: 47.2489\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1132 - val_loss: 46.0849\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5262 - val_loss: 44.4098\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.5000 - val_loss: 44.5645\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8901 - val_loss: 44.1900\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9269 - val_loss: 44.4386\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4837 - val_loss: 45.2528\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6358 - val_loss: 45.0400\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.3836 - val_loss: 44.4811\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6520 - val_loss: 44.5569\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0152 - val_loss: 44.2391\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5102 - val_loss: 44.6987\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.7864 - val_loss: 44.5822\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.2430 - val_loss: 44.3063\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8448 - val_loss: 44.2377\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.2557 - val_loss: 44.1029\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5408 - val_loss: 44.7364\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.2144 - val_loss: 44.6926\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7090 - val_loss: 44.7108\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5803 - val_loss: 44.7874\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0945 - val_loss: 44.8400\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.7912 - val_loss: 44.6464\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7956 - val_loss: 44.7957\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1702 - val_loss: 47.2791\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6299 - val_loss: 52.8958\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.5950 - val_loss: 47.9661\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.0858 - val_loss: 46.1546\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6745 - val_loss: 44.4491\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7958 - val_loss: 44.0117\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0070 - val_loss: 45.0035\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7731 - val_loss: 45.5075\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9303 - val_loss: 48.1559\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.2060 - val_loss: 53.7674\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 52.0723 - val_loss: 47.4033\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4997 - val_loss: 46.9459\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.6414 - val_loss: 57.2276\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 52.4998 - val_loss: 46.6418\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.9288 - val_loss: 45.0922\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.9392 - val_loss: 44.8741\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4752 - val_loss: 46.5968\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8728 - val_loss: 44.7232\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.6633 - val_loss: 46.3587\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.3909 - val_loss: 45.2390\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4394 - val_loss: 46.6771\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.4708 - val_loss: 44.2000\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4318 - val_loss: 45.2313\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0704 - val_loss: 46.9964\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 50.0183 - val_loss: 45.4696\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0486 - val_loss: 44.1555\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.0002 - val_loss: 44.6190\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4032 - val_loss: 46.0104\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0914 - val_loss: 44.8049\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0161 - val_loss: 46.2454\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.1102 - val_loss: 44.8815\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.2656 - val_loss: 44.6259\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7918 - val_loss: 44.6163\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5616 - val_loss: 46.6257\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9360 - val_loss: 44.3648\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5533 - val_loss: 44.8813\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8397 - val_loss: 44.7773\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5177 - val_loss: 44.5787\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 50.0437 - val_loss: 44.6627\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2755 - val_loss: 44.1716\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.1619 - val_loss: 46.8403\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.8034 - val_loss: 44.3082\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9843 - val_loss: 44.7860\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.2286 - val_loss: 44.7159\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1790 - val_loss: 44.5408\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 47.6989 - val_loss: 44.2329\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6895 - val_loss: 47.1439\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0096 - val_loss: 44.3693\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2274 - val_loss: 44.9642\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8409 - val_loss: 44.7278\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.2078 - val_loss: 44.3426\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7082 - val_loss: 44.0865\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8152 - val_loss: 44.8504\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8582 - val_loss: 44.5424\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0117 - val_loss: 44.7062\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5059 - val_loss: 51.0691\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.9758 - val_loss: 44.8290\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.0906 - val_loss: 44.0771\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7172 - val_loss: 44.2207\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9714 - val_loss: 45.3578\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0131 - val_loss: 45.3219\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2244 - val_loss: 44.6926\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.7240 - val_loss: 44.5121\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.6733 - val_loss: 44.0611\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.3400 - val_loss: 44.3793\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4561 - val_loss: 44.1861\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3170 - val_loss: 44.3535\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.3193 - val_loss: 44.5811\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.1613 - val_loss: 44.3454\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0779 - val_loss: 44.3767\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6019 - val_loss: 46.4812\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3840 - val_loss: 46.1944\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2304 - val_loss: 44.5969\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1729 - val_loss: 45.9686\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4331 - val_loss: 44.0607\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4364 - val_loss: 45.1419\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5640 - val_loss: 44.4752\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3496 - val_loss: 45.2807\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.7764 - val_loss: 46.3229\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.1012 - val_loss: 47.4210\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.9837 - val_loss: 52.0496\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.5824 - val_loss: 44.8914\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6578 - val_loss: 44.0238\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2302 - val_loss: 45.8532\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0914 - val_loss: 45.1264\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1932 - val_loss: 44.4684\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9519 - val_loss: 44.5597\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1650 - val_loss: 44.1730\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4232 - val_loss: 44.6908\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.5815 - val_loss: 45.2648\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8487 - val_loss: 44.7443\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.7962 - val_loss: 44.7849\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0638 - val_loss: 44.9128\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3830 - val_loss: 44.5851\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7137 - val_loss: 45.3813\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9426 - val_loss: 44.3192\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1949 - val_loss: 46.2228\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3162 - val_loss: 44.2383\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.1496 - val_loss: 44.3698\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7328 - val_loss: 45.0145\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3360 - val_loss: 45.3843\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9207 - val_loss: 44.7369\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4180 - val_loss: 44.4347\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.1327 - val_loss: 45.2624\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0123 - val_loss: 44.2055\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5370 - val_loss: 44.1912\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4616 - val_loss: 46.1085\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0725 - val_loss: 51.0760\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8744 - val_loss: 46.3563\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8715 - val_loss: 45.4267\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8033 - val_loss: 44.1422\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4789 - val_loss: 44.6076\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.2161 - val_loss: 44.1428\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4311 - val_loss: 51.2974\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5457 - val_loss: 44.6866\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0890 - val_loss: 44.5740\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7134 - val_loss: 44.3962\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0647 - val_loss: 44.9956\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0402 - val_loss: 44.5158\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4484 - val_loss: 45.3095\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6456 - val_loss: 44.6456\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.9053 - val_loss: 45.8068\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8333 - val_loss: 44.6243\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8324 - val_loss: 44.2305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9620 - val_loss: 46.2445\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3198 - val_loss: 44.8267\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6375 - val_loss: 44.1712\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5767 - val_loss: 44.5693\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7578 - val_loss: 44.1014\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4526 - val_loss: 44.0989\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6456 - val_loss: 46.0565\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 50.4456 - val_loss: 48.6573\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.2453 - val_loss: 44.3816\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.2683 - val_loss: 45.2263\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7173 - val_loss: 44.4343\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.0330 - val_loss: 44.7339\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.7204 - val_loss: 44.4119\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2526 - val_loss: 44.6929\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.7833 - val_loss: 51.6530\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7730 - val_loss: 45.4513\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6603 - val_loss: 48.0188\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.2481 - val_loss: 45.5552\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.1425 - val_loss: 44.9294\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8582 - val_loss: 44.3221\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.8224 - val_loss: 44.2711\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6944 - val_loss: 44.9195\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9990 - val_loss: 44.4474\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.6596 - val_loss: 44.5342\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.8516 - val_loss: 44.3709\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9854 - val_loss: 44.4541\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0349 - val_loss: 49.2118\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.6324 - val_loss: 45.9450\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5898 - val_loss: 46.1673\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1817 - val_loss: 44.6349\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6743 - val_loss: 46.4016\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0028 - val_loss: 47.0354\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.6314 - val_loss: 48.4044\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.1214 - val_loss: 44.8998\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 47.4639 - val_loss: 44.8359\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8230 - val_loss: 44.4020\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.2920 - val_loss: 44.1501\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2412 - val_loss: 44.6431\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7667 - val_loss: 44.3546\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6221 - val_loss: 47.6222\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.4903 - val_loss: 50.8546\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.4889 - val_loss: 52.6792\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.7570 - val_loss: 46.8806\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8931 - val_loss: 44.0676\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3992 - val_loss: 47.1507\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5384 - val_loss: 44.2428\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.3762 - val_loss: 44.3752\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.2114 - val_loss: 44.5811\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.8425 - val_loss: 46.7685\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.9055 - val_loss: 44.6346\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.5679 - val_loss: 44.5904\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9328 - val_loss: 45.7219\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 48.5106 - val_loss: 44.5863\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.2358 - val_loss: 44.4490\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7649 - val_loss: 44.6743\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5733 - val_loss: 44.4201\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7049 - val_loss: 44.3544\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3526 - val_loss: 45.1968\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9540 - val_loss: 44.1329\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6670 - val_loss: 44.2913\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 52.5556 - val_loss: 44.7423\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.3360 - val_loss: 44.3043\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6206 - val_loss: 48.8343\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9289 - val_loss: 44.2298\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8119 - val_loss: 44.2954\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.5188 - val_loss: 44.3371\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.2407 - val_loss: 44.7327\n",
      "10/10 [==============================] - 0s 0s/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.1158 - val_loss: 45.1682\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.4996 - val_loss: 44.3353\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.2612 - val_loss: 44.4839\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9683 - val_loss: 44.8101\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9406 - val_loss: 44.8777\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.6114 - val_loss: 45.0743\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6855 - val_loss: 47.7285\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3924 - val_loss: 44.5145\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7414 - val_loss: 44.5219\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.3924 - val_loss: 44.4076\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6164 - val_loss: 46.3437\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3385 - val_loss: 44.1232\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.9747 - val_loss: 44.9369\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2764 - val_loss: 44.7692\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7280 - val_loss: 44.7732\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8898 - val_loss: 45.6761\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1065 - val_loss: 45.1708\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.5264 - val_loss: 45.4407\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.2934 - val_loss: 44.8615\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7892 - val_loss: 44.9690\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2656 - val_loss: 44.9699\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8007 - val_loss: 53.4346\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.9667 - val_loss: 45.3120\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.6330 - val_loss: 46.9066\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8090 - val_loss: 45.1511\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.2368 - val_loss: 44.1144\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6814 - val_loss: 44.1954\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5372 - val_loss: 45.3666\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8053 - val_loss: 45.1383\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 47.9577 - val_loss: 44.2569\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9364 - val_loss: 45.9078\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6949 - val_loss: 45.1041\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5997 - val_loss: 49.6419\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.6696 - val_loss: 48.4544\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4323 - val_loss: 44.2839\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3197 - val_loss: 44.7827\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8102 - val_loss: 45.3329\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4939 - val_loss: 44.4091\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3809 - val_loss: 46.1127\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.7775 - val_loss: 44.4741\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0345 - val_loss: 44.3331\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9366 - val_loss: 45.8626\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.1136 - val_loss: 44.8727\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5098 - val_loss: 47.5431\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6499 - val_loss: 44.2538\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.2753 - val_loss: 45.1026\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.1323 - val_loss: 44.3823\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1593 - val_loss: 44.6222\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.5018 - val_loss: 45.0287\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7397 - val_loss: 45.8729\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.9288 - val_loss: 46.3629\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.8014 - val_loss: 44.1952\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7413 - val_loss: 49.5253\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.8077 - val_loss: 46.0234\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7978 - val_loss: 44.2136\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.9240 - val_loss: 44.5961\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.6646 - val_loss: 44.4811\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8841 - val_loss: 44.4710\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.0977 - val_loss: 44.4437\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6582 - val_loss: 44.4297\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.6750 - val_loss: 45.0284\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.9575 - val_loss: 47.8669\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 50.0664 - val_loss: 47.8732\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.8592 - val_loss: 47.0741\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 48.2128 - val_loss: 47.0521\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.1916 - val_loss: 44.5208\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.6666 - val_loss: 44.9512\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.9865 - val_loss: 44.4096\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0295 - val_loss: 44.3306\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.9241 - val_loss: 44.1198\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.1455 - val_loss: 46.4570\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5538 - val_loss: 44.9434\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6834 - val_loss: 44.3099\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5494 - val_loss: 44.4413\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.3428 - val_loss: 44.7548\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8970 - val_loss: 43.9673\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1780 - val_loss: 44.4717\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.3399 - val_loss: 44.5037\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6796 - val_loss: 45.0184\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7194 - val_loss: 46.3797\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4590 - val_loss: 44.2189\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5531 - val_loss: 44.1726\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.9247 - val_loss: 44.6654\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0346 - val_loss: 45.3353\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.2194 - val_loss: 47.7007\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.0961 - val_loss: 46.8852\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6778 - val_loss: 49.3660\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.8187 - val_loss: 47.9971\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.7908 - val_loss: 46.3307\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 52.0112 - val_loss: 51.4537\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.2318 - val_loss: 49.4503\n",
      "Epoch 92/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 49.9285 - val_loss: 45.0196\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.1393 - val_loss: 45.1825\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7740 - val_loss: 45.3520\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.3250 - val_loss: 45.4709\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4125 - val_loss: 44.3439\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.4664 - val_loss: 44.4414\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.9840 - val_loss: 44.4379\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.2525 - val_loss: 44.7806\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.3454 - val_loss: 44.5109\n",
      "10/10 [==============================] - 0s 321us/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 47.5822 - val_loss: 44.8345\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.9390 - val_loss: 46.5827\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6635 - val_loss: 44.5777\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5267 - val_loss: 44.0530\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6839 - val_loss: 44.9966\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.3989 - val_loss: 44.9646\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2557 - val_loss: 45.4828\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 51.3350 - val_loss: 44.6202\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.0144 - val_loss: 44.3877\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7955 - val_loss: 44.8857\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.2392 - val_loss: 44.6263\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.6588 - val_loss: 46.3612\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.8176 - val_loss: 44.8383\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.3448 - val_loss: 44.0567\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.1342 - val_loss: 44.2381\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.9355 - val_loss: 48.0971\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6851 - val_loss: 45.4068\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8438 - val_loss: 45.2362\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5631 - val_loss: 44.7425\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8952 - val_loss: 44.9118\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 48.1753 - val_loss: 46.2924\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3558 - val_loss: 46.1498\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7947 - val_loss: 44.2871\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.2349 - val_loss: 44.1770\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.2401 - val_loss: 44.1809\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6250 - val_loss: 44.5233\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0600 - val_loss: 46.4334\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.8771 - val_loss: 45.5217\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.5420 - val_loss: 45.0056\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.3632 - val_loss: 44.3212\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.0523 - val_loss: 45.8044\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4461 - val_loss: 44.1544\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.2416 - val_loss: 44.2468\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.2289 - val_loss: 44.5867\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.2322 - val_loss: 44.2220\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 47.5816 - val_loss: 44.1327\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3036 - val_loss: 44.3860\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.2120 - val_loss: 47.8019\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 50.4818 - val_loss: 44.5660\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0503 - val_loss: 48.0755\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9651 - val_loss: 44.3779\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3294 - val_loss: 47.1681\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.7660 - val_loss: 44.3400\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9549 - val_loss: 44.1379\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.0717 - val_loss: 47.2477\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.6247 - val_loss: 45.3139\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8624 - val_loss: 46.6092\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.4893 - val_loss: 44.3954\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4713 - val_loss: 44.0243\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 47.3100 - val_loss: 47.1320\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6971 - val_loss: 44.2370\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.1434 - val_loss: 44.4345\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.2144 - val_loss: 46.2886\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6094 - val_loss: 44.5951\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4733 - val_loss: 44.4365\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.9752 - val_loss: 45.3830\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4540 - val_loss: 44.6795\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9818 - val_loss: 44.6618\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5749 - val_loss: 45.6705\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.2545 - val_loss: 44.4668\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3854 - val_loss: 44.1465\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4691 - val_loss: 44.7994\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9364 - val_loss: 44.6630\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.1912 - val_loss: 44.5255\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7627 - val_loss: 44.8747\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9539 - val_loss: 44.4488\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.2651 - val_loss: 44.6346\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6602 - val_loss: 44.1857\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.6360 - val_loss: 47.4042\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6682 - val_loss: 44.8348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2971 - val_loss: 46.3061\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.3506 - val_loss: 46.0335\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3498 - val_loss: 45.0695\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4930 - val_loss: 44.4185\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.6856 - val_loss: 44.5522\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.1420 - val_loss: 44.6917\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3091 - val_loss: 44.2180\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0717 - val_loss: 45.0549\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1238 - val_loss: 46.4077\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.1317 - val_loss: 44.3957\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8415 - val_loss: 44.1068\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5889 - val_loss: 45.6082\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0567 - val_loss: 45.0281\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 46.8945 - val_loss: 46.5939\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.0834 - val_loss: 44.3682\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.1896 - val_loss: 44.3918\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.5332 - val_loss: 45.4658\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.1724 - val_loss: 44.4177\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9413 - val_loss: 45.2126\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4964 - val_loss: 45.9141\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.3384 - val_loss: 45.2274\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.2771 - val_loss: 45.2271\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2956 - val_loss: 44.2792\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.3260 - val_loss: 44.2614\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4329 - val_loss: 44.5566\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.4039 - val_loss: 44.5902\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.5326 - val_loss: 44.2741\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.2652 - val_loss: 44.7014\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7504 - val_loss: 45.4480\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.9989 - val_loss: 45.5650\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.8460 - val_loss: 44.3026\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.0869 - val_loss: 46.3781\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.5321 - val_loss: 44.2622\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1812 - val_loss: 44.2850\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3943 - val_loss: 44.3391\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1554 - val_loss: 44.2097\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2907 - val_loss: 45.6300\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6901 - val_loss: 46.4833\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.9611 - val_loss: 44.2877\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8256 - val_loss: 45.9275\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4216 - val_loss: 50.5858\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.4356 - val_loss: 44.4186\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.6285 - val_loss: 45.6077\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1701 - val_loss: 44.4905\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4060 - val_loss: 44.7570\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4279 - val_loss: 44.4570\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5116 - val_loss: 44.4059\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6559 - val_loss: 44.6872\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6496 - val_loss: 44.6690\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.3553 - val_loss: 45.9763\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.6883 - val_loss: 44.2335\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5367 - val_loss: 44.1702\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6783 - val_loss: 45.2356\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.2716 - val_loss: 45.5705\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.4778 - val_loss: 44.8423\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.2976 - val_loss: 45.2294\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8649 - val_loss: 46.9897\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1051 - val_loss: 44.6758\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0303 - val_loss: 44.4602\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5725 - val_loss: 44.6844\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.1997 - val_loss: 44.7091\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.9085 - val_loss: 44.8289\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6376 - val_loss: 44.1548\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.9363 - val_loss: 44.2305\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.3947 - val_loss: 44.8794\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.3303 - val_loss: 44.5956\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.3839 - val_loss: 45.0181\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0990 - val_loss: 44.2059\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.4115 - val_loss: 44.0926\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.3214 - val_loss: 47.7078\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.8908 - val_loss: 47.4816\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.7724 - val_loss: 44.9074\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5149 - val_loss: 45.8446\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.0844 - val_loss: 44.2548\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2118 - val_loss: 46.9988\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.1873 - val_loss: 44.3570\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.9872 - val_loss: 44.3856\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.5991 - val_loss: 45.4004\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 47.0269 - val_loss: 45.0299\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9999 - val_loss: 45.5199\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2176 - val_loss: 44.3713\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7395 - val_loss: 46.9954\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.0470 - val_loss: 49.9774\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.5916 - val_loss: 45.6417\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4763 - val_loss: 44.6565\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1665 - val_loss: 44.1284\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.2518 - val_loss: 44.7632\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0816 - val_loss: 44.5781\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.2880 - val_loss: 46.3983\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6390 - val_loss: 45.3840\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3594 - val_loss: 44.4126\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7679 - val_loss: 46.0288\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.1713 - val_loss: 44.2969\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8105 - val_loss: 45.8532\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.3827 - val_loss: 49.7397\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.7494 - val_loss: 49.5195\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.1981 - val_loss: 44.7423\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.7872 - val_loss: 44.4629\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7091 - val_loss: 44.3292\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7272 - val_loss: 44.9106\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.8627 - val_loss: 46.5491\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0257 - val_loss: 44.4035\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4096 - val_loss: 44.6909\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7184 - val_loss: 44.1883\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4681 - val_loss: 45.0601\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9650 - val_loss: 44.8879\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0085 - val_loss: 44.8126\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3115 - val_loss: 46.2341\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3909 - val_loss: 44.8673\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4937 - val_loss: 45.7621\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4532 - val_loss: 44.2490\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7775 - val_loss: 44.5952\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7576 - val_loss: 46.4787\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7935 - val_loss: 48.1311\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8514 - val_loss: 46.8285\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.0423 - val_loss: 48.5083\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9321 - val_loss: 46.1240\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1398 - val_loss: 45.0910\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7258 - val_loss: 44.8378\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.4099 - val_loss: 56.6367\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.5032 - val_loss: 46.1399\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0067 - val_loss: 45.0426\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.6064 - val_loss: 44.8383\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4964 - val_loss: 44.3636\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.9689 - val_loss: 44.9697\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4079 - val_loss: 44.2887\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6615 - val_loss: 44.2413\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7750 - val_loss: 44.3297\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5135 - val_loss: 45.8039\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7551 - val_loss: 47.6512\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.2700 - val_loss: 44.0915\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.3428 - val_loss: 45.0262\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3397 - val_loss: 44.4770\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2125 - val_loss: 44.3719\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.1012 - val_loss: 44.5731\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5568 - val_loss: 44.3901\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4441 - val_loss: 44.3037\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.2842 - val_loss: 44.5139\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4388 - val_loss: 44.3492\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5444 - val_loss: 44.7956\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8177 - val_loss: 47.4445\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2684 - val_loss: 46.9736\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.2612 - val_loss: 50.8954\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3803 - val_loss: 45.1666\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2667 - val_loss: 44.2859\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1740 - val_loss: 46.6159\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.2341 - val_loss: 44.8564\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7860 - val_loss: 50.8646\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2005 - val_loss: 44.2577\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.0668 - val_loss: 44.3473\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4782 - val_loss: 49.1970\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.5161 - val_loss: 53.8640\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 50.5249 - val_loss: 51.1965\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.7709 - val_loss: 44.0810\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7600 - val_loss: 44.4923\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.2889 - val_loss: 44.3949\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5369 - val_loss: 44.0854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3158 - val_loss: 44.3396\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.3464 - val_loss: 45.1486\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.7434 - val_loss: 45.9152\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.3262 - val_loss: 45.1496\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5532 - val_loss: 45.0411\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.3304 - val_loss: 44.3553\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.2364 - val_loss: 45.8323\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.6535 - val_loss: 46.1484\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0220 - val_loss: 46.3244\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.1387 - val_loss: 58.6498\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.1246 - val_loss: 44.6728\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.2382 - val_loss: 47.4591\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.0017 - val_loss: 44.9402\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.1724 - val_loss: 44.4572\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.4296 - val_loss: 44.5831\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4170 - val_loss: 44.4916\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2634 - val_loss: 44.3896\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4754 - val_loss: 44.4690\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4215 - val_loss: 46.9292\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.2124 - val_loss: 45.0009\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 52.7031 - val_loss: 44.5223\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.4483 - val_loss: 45.6939\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 46.9772 - val_loss: 46.6988\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8741 - val_loss: 44.4589\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.2645 - val_loss: 45.8089\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.0774 - val_loss: 45.3476\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1287 - val_loss: 44.1601\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.7163 - val_loss: 44.5659\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.5713 - val_loss: 44.5099\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.0955 - val_loss: 45.6889\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.3670 - val_loss: 44.2605\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6840 - val_loss: 44.5286\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5552 - val_loss: 44.7657\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.1587 - val_loss: 46.5255\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6688 - val_loss: 44.8856\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6951 - val_loss: 46.1224\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8504 - val_loss: 44.4735\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.4913 - val_loss: 44.4210\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6699 - val_loss: 45.8680\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.3050 - val_loss: 47.8070\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.3536 - val_loss: 47.8304\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.8198 - val_loss: 49.8843\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.9925 - val_loss: 44.8548\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7470 - val_loss: 44.7899\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3671 - val_loss: 44.9114\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.8898 - val_loss: 44.4696\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8699 - val_loss: 46.2040\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.9298 - val_loss: 44.5642\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4790 - val_loss: 44.5668\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7063 - val_loss: 44.3654\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3119 - val_loss: 44.7911\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.3307 - val_loss: 44.3668\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7579 - val_loss: 48.3410\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.8953 - val_loss: 45.5968\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.1467 - val_loss: 44.9017\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.0397 - val_loss: 45.5916\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.2856 - val_loss: 45.9006\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.6118 - val_loss: 44.3121\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.2796 - val_loss: 44.6623\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.9814 - val_loss: 44.8242\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.9632 - val_loss: 44.4083\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6677 - val_loss: 44.8509\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.4650 - val_loss: 44.2537\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4258 - val_loss: 44.9773\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6598 - val_loss: 44.8043\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6162 - val_loss: 44.1866\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5899 - val_loss: 44.4656\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.4952 - val_loss: 44.7370\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0694 - val_loss: 44.5577\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7204 - val_loss: 44.8678\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9091 - val_loss: 45.4866\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1540 - val_loss: 46.6505\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.1008 - val_loss: 44.7130\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 50.4608 - val_loss: 49.5718\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.9497 - val_loss: 46.2731\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.8808 - val_loss: 45.9471\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.5901 - val_loss: 44.9908\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6283 - val_loss: 46.9907\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0617 - val_loss: 44.4204\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.3243 - val_loss: 44.2398\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2280 - val_loss: 44.3720\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6061 - val_loss: 44.3110\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.8708 - val_loss: 45.1757\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.5782 - val_loss: 47.6110\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9775 - val_loss: 45.6852\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6125 - val_loss: 46.0832\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0823 - val_loss: 44.9361\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4549 - val_loss: 44.1216\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8685 - val_loss: 44.4418\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4981 - val_loss: 45.2930\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6127 - val_loss: 44.2217\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.8391 - val_loss: 44.5787\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.1285 - val_loss: 45.5401\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2460 - val_loss: 44.1088\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0693 - val_loss: 44.6451\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.9607 - val_loss: 44.3052\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6754 - val_loss: 44.0572\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4938 - val_loss: 44.3964\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6398 - val_loss: 44.7663\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.5065 - val_loss: 45.6401\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.7184 - val_loss: 46.0367\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4284 - val_loss: 44.4549\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.1327 - val_loss: 45.4423\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8581 - val_loss: 44.7203\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.3298 - val_loss: 45.8342\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.0176 - val_loss: 46.6355\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.1305 - val_loss: 45.0153\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5672 - val_loss: 45.4503\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8252 - val_loss: 46.7346\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 50.5949 - val_loss: 44.5519\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8551 - val_loss: 47.1646\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.2590 - val_loss: 47.0706\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9022 - val_loss: 44.1306\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8993 - val_loss: 46.3139\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3089 - val_loss: 46.1918\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7083 - val_loss: 44.4391\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5005 - val_loss: 45.9429\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5946 - val_loss: 45.0470\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7204 - val_loss: 44.1875\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3628 - val_loss: 44.4993\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4975 - val_loss: 44.4827\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7032 - val_loss: 46.7269\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8264 - val_loss: 45.2713\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2543 - val_loss: 44.2308\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5819 - val_loss: 44.3420\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2530 - val_loss: 45.3180\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.8432 - val_loss: 44.6913\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5377 - val_loss: 44.4291\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6680 - val_loss: 44.1346\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2544 - val_loss: 47.3033\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.2979 - val_loss: 44.4788\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.7263 - val_loss: 45.7242\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.8600 - val_loss: 44.6783\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.1329 - val_loss: 45.7985\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1434 - val_loss: 44.6556\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.5250 - val_loss: 44.7738\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.5334 - val_loss: 46.0574\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1452 - val_loss: 45.8163\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.5491 - val_loss: 47.8665\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.4007 - val_loss: 45.1112\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1541 - val_loss: 44.8528\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.5206 - val_loss: 44.4676\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2207 - val_loss: 46.4535\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.8125 - val_loss: 44.8123\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.4822 - val_loss: 44.7727\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.5655 - val_loss: 44.5444\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.4184 - val_loss: 47.6785\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.5993 - val_loss: 47.7159\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.0073 - val_loss: 47.1652\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 50.8063 - val_loss: 44.5926\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5704 - val_loss: 45.0673\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7534 - val_loss: 46.0243\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5401 - val_loss: 44.7458\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.5060 - val_loss: 46.5044\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1277 - val_loss: 48.9795\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.8105 - val_loss: 45.5746\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4561 - val_loss: 44.6428\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9368 - val_loss: 45.6111\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8376 - val_loss: 55.1867\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.9959 - val_loss: 46.3377\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0221 - val_loss: 44.4632\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.4019 - val_loss: 44.9421\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.9067 - val_loss: 44.8125\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0497 - val_loss: 44.4929\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.3884 - val_loss: 44.4473\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5164 - val_loss: 43.9921\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7600 - val_loss: 44.8999\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2810 - val_loss: 44.4336\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6916 - val_loss: 47.0480\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6763 - val_loss: 45.8048\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.1386 - val_loss: 46.2239\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.4881 - val_loss: 44.4499\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.8455 - val_loss: 44.7476\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.0792 - val_loss: 44.6347\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1580 - val_loss: 44.9677\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8637 - val_loss: 45.2004\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2550 - val_loss: 45.4303\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 46.9015 - val_loss: 51.2186\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8144 - val_loss: 45.0284\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7808 - val_loss: 44.3732\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3833 - val_loss: 45.8495\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0714 - val_loss: 44.9673\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2825 - val_loss: 44.3159\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.7567 - val_loss: 44.4730\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3194 - val_loss: 50.4705\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.1787 - val_loss: 47.4325\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6588 - val_loss: 46.9079\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.6595 - val_loss: 44.8616\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.1812 - val_loss: 44.4119\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.2817 - val_loss: 44.8970\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.1870 - val_loss: 44.3909\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3623 - val_loss: 44.3247\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.1303 - val_loss: 45.6209\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.1325 - val_loss: 48.1444\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0614 - val_loss: 45.0875\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0601 - val_loss: 44.1370\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.0632 - val_loss: 45.3341\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3558 - val_loss: 44.4023\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.5043 - val_loss: 44.3032\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.9280 - val_loss: 45.0868\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.4086 - val_loss: 44.7366\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.0966 - val_loss: 46.3181\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2525 - val_loss: 49.2830\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9062 - val_loss: 44.7516\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7240 - val_loss: 44.0658\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3508 - val_loss: 49.8050\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.2547 - val_loss: 45.2814\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 46.7013 - val_loss: 46.0198\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.2148 - val_loss: 44.3429\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6415 - val_loss: 45.8007\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.2914 - val_loss: 44.3121\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5052 - val_loss: 44.5123\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.2475 - val_loss: 46.3504\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4553 - val_loss: 44.2446\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.5549 - val_loss: 45.0473\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.3026 - val_loss: 45.2930\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6268 - val_loss: 45.1196\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8489 - val_loss: 44.7931\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.4156 - val_loss: 46.2540\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7636 - val_loss: 44.5065\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.2339 - val_loss: 45.9528\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4196 - val_loss: 44.0877\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7474 - val_loss: 44.1101\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.3620 - val_loss: 46.4732\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7653 - val_loss: 44.4540\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.3715 - val_loss: 45.2323\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.3698 - val_loss: 44.4434\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.3168 - val_loss: 46.4188\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9868 - val_loss: 44.6175\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9424 - val_loss: 45.6245\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5102 - val_loss: 45.0175\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.5726 - val_loss: 46.2252\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.3369 - val_loss: 44.7281\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2213 - val_loss: 45.0968\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.3377 - val_loss: 45.5719\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.9029 - val_loss: 44.5974\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.5082 - val_loss: 45.0855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1264 - val_loss: 44.8299\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.2175 - val_loss: 44.7035\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4267 - val_loss: 44.2801\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4250 - val_loss: 44.2089\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5540 - val_loss: 44.5250\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.0241 - val_loss: 45.1843\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.6561 - val_loss: 46.3215\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1260 - val_loss: 45.6514\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.0855 - val_loss: 46.1832\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.0428 - val_loss: 45.7413\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2288 - val_loss: 44.2555\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6908 - val_loss: 44.5015\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.1298 - val_loss: 44.0723\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.0788 - val_loss: 45.1352\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0250 - val_loss: 44.2908\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3640 - val_loss: 44.5863\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.1986 - val_loss: 45.8156\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8741 - val_loss: 44.4445\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8360 - val_loss: 45.9681\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6954 - val_loss: 44.3251\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5015 - val_loss: 45.4941\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.7474 - val_loss: 47.9380\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6381 - val_loss: 45.0300\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.1367 - val_loss: 49.3244\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.7479 - val_loss: 46.6765\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 50.3756 - val_loss: 46.3463\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1016 - val_loss: 44.8393\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.5299 - val_loss: 44.7156\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.3697 - val_loss: 45.9013\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.8521 - val_loss: 47.0494\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.9804 - val_loss: 52.7189\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.3891 - val_loss: 46.9832\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.5299 - val_loss: 44.3007\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8682 - val_loss: 44.0626\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.6243 - val_loss: 45.6719\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1495 - val_loss: 46.6392\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 47.9780 - val_loss: 44.4099\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7796 - val_loss: 44.4614\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7347 - val_loss: 45.7064\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.1015 - val_loss: 45.9357\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.3494 - val_loss: 44.4427\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8725 - val_loss: 44.2971\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.2520 - val_loss: 44.6129\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.1716 - val_loss: 45.3302\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5849 - val_loss: 44.7866\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1334 - val_loss: 45.7428\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6702 - val_loss: 46.0059\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.0407 - val_loss: 44.1608\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.0208 - val_loss: 44.7497\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 49.8784 - val_loss: 44.8027\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.0901 - val_loss: 44.4108\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 47.4681 - val_loss: 44.5627\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6651 - val_loss: 44.3001\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9801 - val_loss: 44.5521\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5460 - val_loss: 44.8106\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.4332 - val_loss: 44.4338\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.9858 - val_loss: 44.3635\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3574 - val_loss: 44.9688\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6616 - val_loss: 44.0937\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2131 - val_loss: 44.4021\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6796 - val_loss: 44.5316\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1940 - val_loss: 45.5125\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.9955 - val_loss: 44.8097\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0663 - val_loss: 47.6737\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6218 - val_loss: 44.5106\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.7227 - val_loss: 44.3803\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5627 - val_loss: 45.3250\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.2998 - val_loss: 44.2581\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.9644 - val_loss: 45.3766\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.4773 - val_loss: 46.6336\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 50.5111 - val_loss: 46.1332\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.8812 - val_loss: 45.3275\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5230 - val_loss: 45.4189\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6447 - val_loss: 48.6823\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.7563 - val_loss: 45.4173\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8428 - val_loss: 46.2132\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6143 - val_loss: 44.8517\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8061 - val_loss: 46.1728\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 6ms/step - loss: 47.7043 - val_loss: 44.4501\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3773 - val_loss: 44.3465\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.2987 - val_loss: 44.6655\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4262 - val_loss: 44.5034\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7529 - val_loss: 44.6442\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.3894 - val_loss: 46.7706\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.8848 - val_loss: 45.1757\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.1810 - val_loss: 44.3253\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.2589 - val_loss: 44.6479\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.2846 - val_loss: 44.6164\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7532 - val_loss: 49.0866\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.4312 - val_loss: 48.6804\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.7861 - val_loss: 45.1494\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.5044 - val_loss: 45.7617\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3303 - val_loss: 45.3321\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0915 - val_loss: 45.1215\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9202 - val_loss: 48.2805\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4064 - val_loss: 44.2614\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.6214 - val_loss: 44.5619\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7202 - val_loss: 44.1935\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9878 - val_loss: 45.7850\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1655 - val_loss: 44.3298\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0800 - val_loss: 47.4433\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6145 - val_loss: 44.8149\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5004 - val_loss: 45.8036\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 47.4932 - val_loss: 45.5330\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9184 - val_loss: 44.2040\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1213 - val_loss: 48.0072\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1205 - val_loss: 44.2401\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4249 - val_loss: 44.4412\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.6517 - val_loss: 46.3201\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5685 - val_loss: 44.6145\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.2765 - val_loss: 44.9561\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4991 - val_loss: 44.4505\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4521 - val_loss: 44.7065\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.6191 - val_loss: 45.9979\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.7243 - val_loss: 44.4098\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.8895 - val_loss: 44.7802\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9436 - val_loss: 44.6537\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.8700 - val_loss: 44.8970\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1792 - val_loss: 45.4627\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.1751 - val_loss: 44.8321\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6872 - val_loss: 44.5840\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7395 - val_loss: 44.6416\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.9903 - val_loss: 44.5032\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.0113 - val_loss: 45.3908\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.3131 - val_loss: 47.0258\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9738 - val_loss: 44.3204\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7175 - val_loss: 46.2716\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.6703 - val_loss: 44.1899\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.2833 - val_loss: 44.2216\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.6074 - val_loss: 45.8948\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0443 - val_loss: 44.2102\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6481 - val_loss: 44.3663\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2538 - val_loss: 44.5706\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5636 - val_loss: 47.5401\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.7587 - val_loss: 45.1269\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.1885 - val_loss: 46.0331\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 49.6683 - val_loss: 45.1554\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4992 - val_loss: 45.8130\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8060 - val_loss: 45.1803\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5887 - val_loss: 44.5304\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6236 - val_loss: 44.4937\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1280 - val_loss: 45.6695\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9441 - val_loss: 46.7869\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7224 - val_loss: 44.7046\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.9459 - val_loss: 45.6774\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.3753 - val_loss: 44.6781\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5966 - val_loss: 44.3424\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4674 - val_loss: 45.1612\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.1372 - val_loss: 48.5601\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4695 - val_loss: 49.4658\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5052 - val_loss: 44.2344\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3641 - val_loss: 44.6082\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.2548 - val_loss: 44.6389\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.5196 - val_loss: 46.1532\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.9196 - val_loss: 43.9516\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.3966 - val_loss: 44.1081\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.9383 - val_loss: 44.3112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9037 - val_loss: 45.1700\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9311 - val_loss: 44.8624\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3329 - val_loss: 45.3582\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9493 - val_loss: 45.0058\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.2858 - val_loss: 44.4818\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.7531 - val_loss: 44.3028\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.0871 - val_loss: 44.9305\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.4833 - val_loss: 44.2205\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.4429 - val_loss: 45.2138\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.2806 - val_loss: 44.4195\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6256 - val_loss: 44.4074\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.1222 - val_loss: 45.8721\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7973 - val_loss: 44.5767\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4326 - val_loss: 44.4146\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1341 - val_loss: 44.6957\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5427 - val_loss: 44.4700\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.9719 - val_loss: 44.2160\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1722 - val_loss: 44.5401\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.5047 - val_loss: 45.9543\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.9902 - val_loss: 44.9942\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 50.2824 - val_loss: 44.7054\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9021 - val_loss: 47.9871\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.5903 - val_loss: 46.1800\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4893 - val_loss: 45.1440\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.3638 - val_loss: 44.2508\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.3130 - val_loss: 44.4279\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 50.7037 - val_loss: 44.7788\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.6899 - val_loss: 45.9289\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.6304 - val_loss: 45.0085\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5830 - val_loss: 44.2739\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6530 - val_loss: 44.4169\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.2268 - val_loss: 44.4123\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3317 - val_loss: 45.1809\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4449 - val_loss: 44.9575\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6461 - val_loss: 44.4200\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8370 - val_loss: 46.3062\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.4496 - val_loss: 44.6472\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3110 - val_loss: 45.0665\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.6614 - val_loss: 46.1092\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.7098 - val_loss: 48.7769\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0285 - val_loss: 44.8864\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.8150 - val_loss: 44.2474\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3991 - val_loss: 44.4304\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6794 - val_loss: 44.8038\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 47.6449 - val_loss: 46.7014\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.1792 - val_loss: 47.4819\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.0437 - val_loss: 45.7888\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.3878 - val_loss: 44.6630\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.6442 - val_loss: 45.3135\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4246 - val_loss: 44.3011\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.3536 - val_loss: 44.8574\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.4385 - val_loss: 45.5646\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7045 - val_loss: 46.3838\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9878 - val_loss: 44.2421\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5761 - val_loss: 44.6078\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.1350 - val_loss: 44.4151\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4270 - val_loss: 44.4334\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2264 - val_loss: 45.1708\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.6657 - val_loss: 47.3713\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.7285 - val_loss: 46.3200\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0941 - val_loss: 44.9466\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5593 - val_loss: 44.2921\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2738 - val_loss: 44.6723\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3694 - val_loss: 44.5139\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.3612 - val_loss: 45.3498\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.4888 - val_loss: 44.2299\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.1476 - val_loss: 45.2838\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4155 - val_loss: 44.8125\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0737 - val_loss: 44.7147\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0020 - val_loss: 46.2603\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6238 - val_loss: 44.2023\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7922 - val_loss: 45.7006\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2646 - val_loss: 45.6344\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9632 - val_loss: 44.3246\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.2518 - val_loss: 44.6609\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.1942 - val_loss: 44.5594\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5281 - val_loss: 45.6589\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0462 - val_loss: 47.4176\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6436 - val_loss: 46.7653\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.9483 - val_loss: 44.4896\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5156 - val_loss: 45.6380\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0347 - val_loss: 48.2546\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.0995 - val_loss: 44.2947\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.2443 - val_loss: 50.9476\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.9086 - val_loss: 47.0618\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0542 - val_loss: 44.4330\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7981 - val_loss: 44.9034\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8039 - val_loss: 44.3854\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.0737 - val_loss: 44.4828\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7652 - val_loss: 45.5401\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4218 - val_loss: 46.7545\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.0723 - val_loss: 45.3481\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5736 - val_loss: 44.1574\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4326 - val_loss: 46.2364\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4765 - val_loss: 44.7052\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.2383 - val_loss: 44.6398\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7385 - val_loss: 45.1058\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1643 - val_loss: 44.3093\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.1151 - val_loss: 49.6761\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4176 - val_loss: 44.1870\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7206 - val_loss: 44.3854\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7340 - val_loss: 44.5494\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5818 - val_loss: 44.9574\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3328 - val_loss: 45.2012\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7560 - val_loss: 44.2970\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.6234 - val_loss: 44.4124\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7131 - val_loss: 44.6777\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.7960 - val_loss: 44.6837\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 46.9921 - val_loss: 47.5808\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0224 - val_loss: 44.4981\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8868 - val_loss: 44.7601\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.1933 - val_loss: 46.5444\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7337 - val_loss: 46.0843\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.8955 - val_loss: 44.8103\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5749 - val_loss: 45.8345\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3285 - val_loss: 44.7107\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 46.8987 - val_loss: 47.4375\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.2524 - val_loss: 45.7775\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.0636 - val_loss: 44.4358\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.1676 - val_loss: 46.2305\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4502 - val_loss: 45.2966\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7174 - val_loss: 44.2559\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4895 - val_loss: 44.7063\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2958 - val_loss: 44.3121\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3656 - val_loss: 45.3532\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6745 - val_loss: 44.5897\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.0917 - val_loss: 46.4140\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6003 - val_loss: 46.6115\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0122 - val_loss: 44.4135\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0095 - val_loss: 44.2752\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.7857 - val_loss: 47.9749\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3869 - val_loss: 44.1662\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5985 - val_loss: 45.0236\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6690 - val_loss: 44.3587\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6818 - val_loss: 49.0951\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5325 - val_loss: 54.0106\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.1737 - val_loss: 45.8164\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0303 - val_loss: 46.2156\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.1850 - val_loss: 45.2044\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7354 - val_loss: 44.8310\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9124 - val_loss: 45.3256\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7945 - val_loss: 44.9809\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.6691 - val_loss: 44.3944\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1138 - val_loss: 47.3259\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8267 - val_loss: 47.7303\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2858 - val_loss: 46.7292\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3103 - val_loss: 46.2422\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1780 - val_loss: 44.3783\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6207 - val_loss: 44.5143\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 47.1125 - val_loss: 45.2115\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.2869 - val_loss: 46.4066\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.0991 - val_loss: 44.4001\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4416 - val_loss: 45.5539\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4547 - val_loss: 44.1990\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5339 - val_loss: 45.1434\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3744 - val_loss: 44.7122\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2094 - val_loss: 45.5056\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5278 - val_loss: 44.2849\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.2042 - val_loss: 44.2798\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 47.0872 - val_loss: 50.4232\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.4574 - val_loss: 44.7083\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4566 - val_loss: 44.3106\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4564 - val_loss: 44.8864\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1598 - val_loss: 44.6684\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.8116 - val_loss: 47.9801\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2730 - val_loss: 45.7640\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4779 - val_loss: 46.3093\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 52.2221 - val_loss: 44.3069\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.0708 - val_loss: 44.4521\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7208 - val_loss: 46.3149\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4444 - val_loss: 45.2934\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.3177 - val_loss: 46.0407\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.3321 - val_loss: 44.7180\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.1542 - val_loss: 44.3112\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9110 - val_loss: 44.5159\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.5502 - val_loss: 44.2878\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 50.4551 - val_loss: 45.3237\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.8614 - val_loss: 44.6881\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.6913 - val_loss: 44.7236\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 47.8344 - val_loss: 44.5390\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0869 - val_loss: 45.7123\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5697 - val_loss: 47.1483\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3822 - val_loss: 44.8049\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9485 - val_loss: 45.0462\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4850 - val_loss: 45.5907\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2416 - val_loss: 44.2599\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5844 - val_loss: 45.9665\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7284 - val_loss: 44.3510\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7480 - val_loss: 45.6509\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8034 - val_loss: 45.4238\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9649 - val_loss: 48.1672\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8317 - val_loss: 45.2197\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.2400 - val_loss: 44.4352\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4480 - val_loss: 44.2222\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4478 - val_loss: 45.7362\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8667 - val_loss: 51.2228\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 52.0628 - val_loss: 48.5618\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0297 - val_loss: 45.5690\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.9337 - val_loss: 45.9783\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.9609 - val_loss: 51.0879\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.9986 - val_loss: 44.3418\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6290 - val_loss: 45.9952\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.9018 - val_loss: 45.5239\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.5429 - val_loss: 46.9340\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.3243 - val_loss: 44.6043\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0527 - val_loss: 44.4353\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9306 - val_loss: 44.7307\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5310 - val_loss: 44.5522\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.3015 - val_loss: 45.0102\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.3512 - val_loss: 48.1866\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.7647 - val_loss: 46.1421\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3552 - val_loss: 44.2433\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1021 - val_loss: 44.2633\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5038 - val_loss: 48.1270\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.4266 - val_loss: 44.6083\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.0156 - val_loss: 44.7612\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.7943 - val_loss: 45.3921\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7557 - val_loss: 44.5216\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6246 - val_loss: 47.2919\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3290 - val_loss: 44.9873\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.3406 - val_loss: 44.6759\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7745 - val_loss: 44.2953\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7932 - val_loss: 44.6360\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7736 - val_loss: 44.6180\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.5441 - val_loss: 47.6691\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 52.7902 - val_loss: 67.5909\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 54.3109 - val_loss: 48.9416\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.5182 - val_loss: 44.6179\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1606 - val_loss: 44.3557\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6769 - val_loss: 44.9676\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2753 - val_loss: 44.8370\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5925 - val_loss: 45.2285\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4683 - val_loss: 44.7765\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3481 - val_loss: 44.7115\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.2909 - val_loss: 45.4698\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3705 - val_loss: 44.6125\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5317 - val_loss: 44.2046\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8070 - val_loss: 44.5686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.2194 - val_loss: 44.5002\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3195 - val_loss: 44.7379\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6144 - val_loss: 44.1031\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.1438 - val_loss: 47.1860\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6489 - val_loss: 46.0425\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.9736 - val_loss: 53.8616\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.9975 - val_loss: 47.9195\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5847 - val_loss: 46.0092\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 51.0262 - val_loss: 52.6496\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 50.1657 - val_loss: 47.9908\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.1885 - val_loss: 45.1188\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6123 - val_loss: 44.4553\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8963 - val_loss: 44.6505\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.1402 - val_loss: 44.5004\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5338 - val_loss: 44.3974\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.3848 - val_loss: 44.6351\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4173 - val_loss: 45.2813\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.3500 - val_loss: 44.2314\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8882 - val_loss: 44.5936\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.2980 - val_loss: 44.3010\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.1991 - val_loss: 44.7883\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6124 - val_loss: 44.8421\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.0366 - val_loss: 44.3402\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4619 - val_loss: 44.9672\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4885 - val_loss: 45.4897\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9051 - val_loss: 44.3704\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.2636 - val_loss: 44.4337\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.9011 - val_loss: 44.5335\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7566 - val_loss: 45.7075\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.9881 - val_loss: 45.0792\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4712 - val_loss: 46.4741\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7089 - val_loss: 45.3086\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5138 - val_loss: 44.4585\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.3452 - val_loss: 44.8808\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 47.0811 - val_loss: 46.4723\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2472 - val_loss: 44.4331\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.9144 - val_loss: 45.4404\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.1894 - val_loss: 44.7930\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6084 - val_loss: 44.7310\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3720 - val_loss: 44.5012\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4167 - val_loss: 45.4188\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.1780 - val_loss: 44.7763\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.8634 - val_loss: 44.4419\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.3569 - val_loss: 45.1734\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8979 - val_loss: 44.5634\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.8399 - val_loss: 48.1162\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.4435 - val_loss: 46.2319\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3462 - val_loss: 45.3138\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.3329 - val_loss: 44.7080\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7281 - val_loss: 45.8264\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.4587 - val_loss: 47.6370\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 46.9137 - val_loss: 44.9470\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0242 - val_loss: 44.4327\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.2967 - val_loss: 46.8727\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.6823 - val_loss: 44.9967\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.3907 - val_loss: 44.9244\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.3173 - val_loss: 44.5916\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.2045 - val_loss: 46.8318\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0770 - val_loss: 45.9444\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.4556 - val_loss: 45.1021\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6085 - val_loss: 44.4941\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7896 - val_loss: 44.9052\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8873 - val_loss: 44.6966\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.7526 - val_loss: 44.5552\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.1722 - val_loss: 44.5835\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4854 - val_loss: 46.2616\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 52.5287 - val_loss: 48.4874\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3968 - val_loss: 45.2480\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.1088 - val_loss: 44.5029\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4152 - val_loss: 44.5689\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.5114 - val_loss: 44.4184\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1987 - val_loss: 44.4178\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1659 - val_loss: 44.9526\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9613 - val_loss: 44.3081\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.0301 - val_loss: 45.6008\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4959 - val_loss: 44.4834\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.6208 - val_loss: 44.2997\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5232 - val_loss: 44.3670\n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 4ms/step - loss: 50.3079 - val_loss: 46.9425\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4774 - val_loss: 44.3102\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6268 - val_loss: 44.3280\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.2039 - val_loss: 45.2254\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0670 - val_loss: 44.4573\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5849 - val_loss: 44.5766\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3357 - val_loss: 44.5018\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4815 - val_loss: 44.5621\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4010 - val_loss: 44.4625\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6942 - val_loss: 44.3589\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3231 - val_loss: 44.8986\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8362 - val_loss: 44.8775\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0929 - val_loss: 46.3348\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7991 - val_loss: 45.5876\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.0569 - val_loss: 46.1584\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9690 - val_loss: 44.2481\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.1571 - val_loss: 44.7292\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7088 - val_loss: 45.4183\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.1116 - val_loss: 44.6151\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.4934 - val_loss: 46.4884\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8414 - val_loss: 45.9453\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.5530 - val_loss: 44.8476\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4246 - val_loss: 46.9173\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8784 - val_loss: 45.4947\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4686 - val_loss: 44.2667\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8827 - val_loss: 44.4176\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7013 - val_loss: 44.5360\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1482 - val_loss: 44.4311\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9796 - val_loss: 45.5216\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.2337 - val_loss: 44.5817\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5323 - val_loss: 44.2175\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4526 - val_loss: 45.6970\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4062 - val_loss: 44.0937\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.2452 - val_loss: 44.6247\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0258 - val_loss: 44.3726\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.6148 - val_loss: 45.8368\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.3668 - val_loss: 44.8113\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9119 - val_loss: 44.8579\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8609 - val_loss: 44.7006\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4998 - val_loss: 45.3398\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0742 - val_loss: 45.3866\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.6110 - val_loss: 45.8212\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5576 - val_loss: 44.6362\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.9182 - val_loss: 44.6386\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4552 - val_loss: 44.4604\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.2190 - val_loss: 44.1484\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.4061 - val_loss: 44.9126\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8037 - val_loss: 45.1602\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.2630 - val_loss: 44.6274\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.8930 - val_loss: 46.8605\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3312 - val_loss: 44.5687\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.2285 - val_loss: 44.3619\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5671 - val_loss: 44.4630\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6205 - val_loss: 44.6770\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2210 - val_loss: 45.0183\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6286 - val_loss: 45.9395\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.1951 - val_loss: 44.9328\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5343 - val_loss: 45.8817\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5362 - val_loss: 44.1483\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9812 - val_loss: 45.1077\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6546 - val_loss: 44.8947\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7688 - val_loss: 44.7653\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9478 - val_loss: 44.5261\n",
      "10/10 [==============================] - 0s 0s/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 47.8875 - val_loss: 44.9193\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9595 - val_loss: 45.4567\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4851 - val_loss: 48.1405\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.0273 - val_loss: 44.8303\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.0525 - val_loss: 44.5036\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6567 - val_loss: 45.0107\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.1588 - val_loss: 44.8520\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 46.9914 - val_loss: 47.3862\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.9039 - val_loss: 44.5986\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.4122 - val_loss: 44.7289\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.4829 - val_loss: 45.0558\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9924 - val_loss: 45.1002\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4866 - val_loss: 45.2873\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.0780 - val_loss: 44.9379\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.4375 - val_loss: 45.1494\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.1199 - val_loss: 46.6914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 50.1441 - val_loss: 45.7949\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.3209 - val_loss: 45.8005\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.3372 - val_loss: 44.6985\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.1653 - val_loss: 46.3677\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.4453 - val_loss: 48.4189\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2513 - val_loss: 44.1921\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.0899 - val_loss: 46.6162\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.1335 - val_loss: 49.2150\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0860 - val_loss: 45.2351\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.5759 - val_loss: 44.7371\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.3354 - val_loss: 44.4317\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.5206 - val_loss: 46.4103\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9538 - val_loss: 45.0630\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8257 - val_loss: 44.6209\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9008 - val_loss: 44.6167\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7034 - val_loss: 45.7965\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7392 - val_loss: 44.9908\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5746 - val_loss: 44.9042\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.0054 - val_loss: 45.8685\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6613 - val_loss: 44.3983\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8663 - val_loss: 45.8460\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.0108 - val_loss: 44.8728\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3675 - val_loss: 45.1157\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6158 - val_loss: 45.4884\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.3412 - val_loss: 44.3509\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.9581 - val_loss: 45.3170\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3727 - val_loss: 53.2922\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5690 - val_loss: 44.4956\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6008 - val_loss: 46.0531\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4011 - val_loss: 44.9059\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.0490 - val_loss: 45.4748\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.4937 - val_loss: 44.9113\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5958 - val_loss: 45.0149\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1691 - val_loss: 44.6852\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6152 - val_loss: 47.2138\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.9633 - val_loss: 45.1867\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.0675 - val_loss: 44.5110\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.2327 - val_loss: 44.4251\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4640 - val_loss: 44.6929\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4234 - val_loss: 44.9394\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.8781 - val_loss: 44.6982\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7938 - val_loss: 50.2751\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1508 - val_loss: 46.1045\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4325 - val_loss: 44.4123\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.7267 - val_loss: 44.6544\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4171 - val_loss: 49.9884\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1842 - val_loss: 45.7071\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.2545 - val_loss: 44.6700\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.3712 - val_loss: 44.5764\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.3261 - val_loss: 45.0890\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.1578 - val_loss: 44.7179\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1220 - val_loss: 45.7478\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4867 - val_loss: 46.5326\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3671 - val_loss: 45.9716\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.5972 - val_loss: 44.4976\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.3392 - val_loss: 44.6388\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8162 - val_loss: 45.3463\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.3444 - val_loss: 44.6475\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0292 - val_loss: 45.1104\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.8981 - val_loss: 44.9071\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.2341 - val_loss: 46.3870\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.7857 - val_loss: 44.3559\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.3675 - val_loss: 45.5276\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.1837 - val_loss: 45.0306\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.8347 - val_loss: 46.8782\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 48.8695 - val_loss: 45.0162\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9213 - val_loss: 44.7035\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.3145 - val_loss: 45.8243\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.0126 - val_loss: 44.4510\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6841 - val_loss: 45.1635\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7315 - val_loss: 46.4208\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.5642 - val_loss: 44.4094\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3236 - val_loss: 45.3011\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0108 - val_loss: 44.6930\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5977 - val_loss: 44.9580\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4997 - val_loss: 44.8591\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9055 - val_loss: 48.6047\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0477 - val_loss: 50.4957\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 51.1098 - val_loss: 55.4917\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.6521 - val_loss: 44.5398\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 49.9552 - val_loss: 45.3970\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 52.2726 - val_loss: 48.2118\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.3229 - val_loss: 44.6939\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.1588 - val_loss: 45.8229\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.7973 - val_loss: 47.1533\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0048 - val_loss: 44.4768\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9278 - val_loss: 44.5037\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.9583 - val_loss: 45.2779\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.5175 - val_loss: 49.9969\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1655 - val_loss: 44.8800\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.7062 - val_loss: 44.9231\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5762 - val_loss: 45.0566\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6105 - val_loss: 45.7363\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.6018 - val_loss: 44.9299\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4741 - val_loss: 44.5989\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6437 - val_loss: 45.7686\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6138 - val_loss: 44.8023\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.3731 - val_loss: 44.8598\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0063 - val_loss: 45.1936\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4734 - val_loss: 46.7559\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4555 - val_loss: 47.4877\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.8909 - val_loss: 46.2383\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8783 - val_loss: 45.1141\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8935 - val_loss: 47.2763\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7595 - val_loss: 45.1149\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6031 - val_loss: 45.0144\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9443 - val_loss: 45.2832\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.0582 - val_loss: 45.1060\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8170 - val_loss: 44.7541\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.0770 - val_loss: 47.2233\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0310 - val_loss: 44.7306\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.4910 - val_loss: 44.9707\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1914 - val_loss: 44.5067\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7448 - val_loss: 44.9114\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.4260 - val_loss: 46.4261\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.9706 - val_loss: 45.4121\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7958 - val_loss: 44.6798\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.5936 - val_loss: 44.5601\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 46.9826 - val_loss: 46.4329\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7740 - val_loss: 47.0252\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7887 - val_loss: 44.7949\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.2065 - val_loss: 44.7178\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.1161 - val_loss: 45.9395\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7553 - val_loss: 45.5304\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4352 - val_loss: 44.5911\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5465 - val_loss: 44.9332\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4622 - val_loss: 44.8563\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6185 - val_loss: 44.4982\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.3702 - val_loss: 44.9005\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.5535 - val_loss: 44.5382\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.7266 - val_loss: 44.8932\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5187 - val_loss: 49.4828\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.1015 - val_loss: 44.6563\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4614 - val_loss: 45.7091\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.2886 - val_loss: 47.9400\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9311 - val_loss: 44.3632\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.4531 - val_loss: 45.5879\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2518 - val_loss: 45.0775\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.2302 - val_loss: 45.0168\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.4812 - val_loss: 44.6641\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7454 - val_loss: 45.4458\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.2431 - val_loss: 44.5161\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8025 - val_loss: 46.9656\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4589 - val_loss: 47.3378\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3924 - val_loss: 45.0928\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.2488 - val_loss: 44.6288\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9060 - val_loss: 45.1810\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.7231 - val_loss: 44.3865\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4835 - val_loss: 44.4230\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.4924 - val_loss: 45.3913\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7536 - val_loss: 44.8152\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4311 - val_loss: 46.3612\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.8732 - val_loss: 48.4765\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0406 - val_loss: 44.4285\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8761 - val_loss: 44.8197\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7161 - val_loss: 44.4666\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.3487 - val_loss: 46.3399\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5200 - val_loss: 45.2832\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3485 - val_loss: 48.5377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9680 - val_loss: 44.6313\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5527 - val_loss: 45.3644\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.1162 - val_loss: 51.0852\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4817 - val_loss: 44.6119\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.2168 - val_loss: 45.0023\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.1686 - val_loss: 45.5112\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2190 - val_loss: 46.3367\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7491 - val_loss: 45.0560\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.2932 - val_loss: 45.6974\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.0822 - val_loss: 45.9480\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7689 - val_loss: 45.0576\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5957 - val_loss: 47.2645\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.2818 - val_loss: 44.5825\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.1200 - val_loss: 44.4485\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3900 - val_loss: 45.1740\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.3512 - val_loss: 45.5335\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.0398 - val_loss: 44.8094\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3950 - val_loss: 45.2073\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8358 - val_loss: 45.8596\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9558 - val_loss: 44.9347\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2731 - val_loss: 44.9333\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4324 - val_loss: 44.5413\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.9010 - val_loss: 45.2481\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.1163 - val_loss: 45.7090\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5906 - val_loss: 44.7193\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 47.0028 - val_loss: 45.1323\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4375 - val_loss: 44.9405\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4086 - val_loss: 44.7155\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.2876 - val_loss: 44.9872\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.1954 - val_loss: 44.9043\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5226 - val_loss: 51.0882\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.6416 - val_loss: 49.0645\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2368 - val_loss: 44.8745\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6418 - val_loss: 45.7967\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4331 - val_loss: 44.8828\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5850 - val_loss: 45.4165\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.3224 - val_loss: 45.3539\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4929 - val_loss: 45.4864\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8248 - val_loss: 45.7702\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4394 - val_loss: 44.7558\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8737 - val_loss: 44.8078\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.3422 - val_loss: 47.1231\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.0541 - val_loss: 48.0251\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0684 - val_loss: 46.0374\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8027 - val_loss: 45.8956\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3943 - val_loss: 46.2370\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0556 - val_loss: 45.5082\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3366 - val_loss: 44.5488\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4163 - val_loss: 44.7877\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.0617 - val_loss: 44.7403\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5881 - val_loss: 44.7380\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0488 - val_loss: 44.8393\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9424 - val_loss: 46.3376\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0849 - val_loss: 45.6902\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.9018 - val_loss: 44.6789\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4879 - val_loss: 44.7793\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.9656 - val_loss: 45.1545\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.2329 - val_loss: 49.0039\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.7821 - val_loss: 46.9106\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7999 - val_loss: 46.7408\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6618 - val_loss: 46.1239\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9441 - val_loss: 45.4464\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.0253 - val_loss: 46.7575\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8433 - val_loss: 44.8417\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 46.8426 - val_loss: 47.8072\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6986 - val_loss: 44.5931\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.3307 - val_loss: 45.1729\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9095 - val_loss: 44.9632\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.2711 - val_loss: 44.7259\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.0600 - val_loss: 45.1648\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8416 - val_loss: 44.9987\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.4347 - val_loss: 45.1231\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7040 - val_loss: 45.7087\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3579 - val_loss: 44.7631\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6908 - val_loss: 44.7710\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.1024 - val_loss: 45.0696\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7865 - val_loss: 44.9162\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3122 - val_loss: 46.2137\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7722 - val_loss: 45.6523\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.6226 - val_loss: 44.6917\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.7990 - val_loss: 47.1267\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8347 - val_loss: 45.1331\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6851 - val_loss: 44.9901\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7697 - val_loss: 44.7009\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.2263 - val_loss: 47.6965\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.1338 - val_loss: 49.1036\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4367 - val_loss: 45.0198\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8565 - val_loss: 44.8488\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0752 - val_loss: 44.7443\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5251 - val_loss: 44.7251\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6562 - val_loss: 45.0402\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0692 - val_loss: 45.8933\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1685 - val_loss: 50.0212\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.8996 - val_loss: 46.5721\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0295 - val_loss: 45.1236\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.3611 - val_loss: 44.4922\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3379 - val_loss: 45.9220\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7904 - val_loss: 47.0905\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.7718 - val_loss: 45.9463\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7077 - val_loss: 46.5421\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.6393 - val_loss: 44.5729\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1249 - val_loss: 45.9771\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 46.9175 - val_loss: 45.2452\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.3643 - val_loss: 44.7042\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6111 - val_loss: 47.7686\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5762 - val_loss: 46.2727\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.1651 - val_loss: 45.0323\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.1623 - val_loss: 45.4154\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.0223 - val_loss: 45.7841\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7834 - val_loss: 45.7329\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3251 - val_loss: 51.3885\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.6768 - val_loss: 45.6278\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7144 - val_loss: 45.3761\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.0985 - val_loss: 45.3543\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6857 - val_loss: 44.8066\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.0150 - val_loss: 45.0988\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 46.8782 - val_loss: 44.8693\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5901 - val_loss: 44.8271\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1368 - val_loss: 45.3623\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.1458 - val_loss: 45.1830\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5434 - val_loss: 46.2508\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8181 - val_loss: 44.5983\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.2840 - val_loss: 45.8689\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6445 - val_loss: 46.3617\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.0546 - val_loss: 45.6464\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.4808 - val_loss: 46.4929\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.2882 - val_loss: 45.2710\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.2204 - val_loss: 45.0750\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5513 - val_loss: 44.9816\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0825 - val_loss: 45.5073\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9794 - val_loss: 44.9304\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7336 - val_loss: 45.2743\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3386 - val_loss: 46.1906\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.6358 - val_loss: 45.4503\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2350 - val_loss: 45.1283\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.2544 - val_loss: 47.1806\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5807 - val_loss: 48.4994\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7663 - val_loss: 44.7194\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0479 - val_loss: 44.7962\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.3283 - val_loss: 45.5630\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.4347 - val_loss: 45.7899\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.8896 - val_loss: 47.3887\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4169 - val_loss: 44.7705\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3989 - val_loss: 44.8334\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5303 - val_loss: 45.8052\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4740 - val_loss: 45.7357\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8722 - val_loss: 44.6943\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4930 - val_loss: 44.7459\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.4027 - val_loss: 47.6217\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.8470 - val_loss: 44.7237\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7150 - val_loss: 44.8629\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8716 - val_loss: 48.1664\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0514 - val_loss: 45.3190\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7047 - val_loss: 45.1495\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.0628 - val_loss: 44.5935\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.0682 - val_loss: 44.6060\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.1210 - val_loss: 44.9765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8144 - val_loss: 46.5397\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 51.6582 - val_loss: 48.6907\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9130 - val_loss: 45.1174\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7928 - val_loss: 44.8845\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5632 - val_loss: 45.5903\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6772 - val_loss: 45.4585\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6897 - val_loss: 44.9493\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3720 - val_loss: 45.8047\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.2735 - val_loss: 45.3922\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5142 - val_loss: 47.3558\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.6802 - val_loss: 50.6270\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.2277 - val_loss: 46.1486\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.2226 - val_loss: 45.4077\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5279 - val_loss: 44.9528\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3500 - val_loss: 44.9513\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6233 - val_loss: 45.4750\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.6901 - val_loss: 45.0375\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.9476 - val_loss: 45.0163\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.3175 - val_loss: 45.2362\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.1639 - val_loss: 44.5324\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.1286 - val_loss: 48.5304\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4680 - val_loss: 44.9332\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.1679 - val_loss: 45.1844\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3306 - val_loss: 45.0853\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.0813 - val_loss: 44.8094\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6703 - val_loss: 46.3536\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.6023 - val_loss: 46.2266\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7859 - val_loss: 48.8660\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6150 - val_loss: 52.2467\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 50.4823 - val_loss: 50.5106\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.5990 - val_loss: 53.0446\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.0574 - val_loss: 46.7834\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5323 - val_loss: 49.4309\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.7285 - val_loss: 46.2109\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5014 - val_loss: 44.5386\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.1248 - val_loss: 44.6616\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.2386 - val_loss: 44.8664\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.1378 - val_loss: 45.2043\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5190 - val_loss: 45.2142\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.1556 - val_loss: 44.8571\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6480 - val_loss: 47.6521\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.4968 - val_loss: 44.8459\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 46.9224 - val_loss: 46.6452\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.5892 - val_loss: 45.0956\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6537 - val_loss: 45.0180\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8780 - val_loss: 46.2531\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5659 - val_loss: 46.7825\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5521 - val_loss: 45.3328\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.2440 - val_loss: 44.8804\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6503 - val_loss: 48.9389\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.0006 - val_loss: 46.1530\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.2551 - val_loss: 44.7745\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7247 - val_loss: 45.9051\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3975 - val_loss: 44.8765\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7615 - val_loss: 46.0349\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5855 - val_loss: 45.7496\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.5460 - val_loss: 44.9826\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6525 - val_loss: 44.6591\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.1482 - val_loss: 45.6644\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8454 - val_loss: 44.8398\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.2011 - val_loss: 50.0852\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.2701 - val_loss: 45.2663\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.3254 - val_loss: 45.5592\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.3091 - val_loss: 44.9889\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5634 - val_loss: 44.7236\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6102 - val_loss: 45.1753\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8137 - val_loss: 45.2519\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5282 - val_loss: 45.3836\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.7393 - val_loss: 44.8106\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.4955 - val_loss: 44.7944\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8096 - val_loss: 45.1194\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.0567 - val_loss: 45.0690\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7542 - val_loss: 45.5830\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6258 - val_loss: 55.8274\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.8504 - val_loss: 47.4406\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7485 - val_loss: 45.6897\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.1859 - val_loss: 44.8206\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.3807 - val_loss: 45.3433\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3460 - val_loss: 44.9601\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7929 - val_loss: 44.8104\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 46.9965 - val_loss: 44.9328\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.3712 - val_loss: 45.1542\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.5500 - val_loss: 44.7565\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.1818 - val_loss: 45.8089\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.2155 - val_loss: 45.2834\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5868 - val_loss: 45.7454\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 46.9841 - val_loss: 44.8859\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.8956 - val_loss: 44.8970\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1418 - val_loss: 45.6093\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6641 - val_loss: 45.3659\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 46.9884 - val_loss: 53.7244\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.9384 - val_loss: 49.4260\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6930 - val_loss: 45.8990\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5314 - val_loss: 45.4152\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.7608 - val_loss: 45.0051\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.9818 - val_loss: 46.5903\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 52.3165 - val_loss: 46.5163\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 52.0291 - val_loss: 45.2615\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4124 - val_loss: 45.5032\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0126 - val_loss: 45.2396\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.3873 - val_loss: 44.9598\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2341 - val_loss: 45.1254\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.0003 - val_loss: 46.2202\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2160 - val_loss: 47.9590\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0122 - val_loss: 49.6970\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3030 - val_loss: 44.9104\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6141 - val_loss: 45.2153\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1279 - val_loss: 45.2343\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5154 - val_loss: 45.2784\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.3559 - val_loss: 46.4412\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3221 - val_loss: 45.7028\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4387 - val_loss: 46.5417\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6082 - val_loss: 45.3536\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9586 - val_loss: 45.1349\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.2010 - val_loss: 47.2573\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.3397 - val_loss: 46.0584\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9443 - val_loss: 45.9972\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9435 - val_loss: 45.0061\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.4144 - val_loss: 45.5815\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.1265 - val_loss: 45.0641\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7043 - val_loss: 45.3758\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.4686 - val_loss: 44.8619\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.3961 - val_loss: 45.9642\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3623 - val_loss: 45.1879\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3673 - val_loss: 47.1172\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.7220 - val_loss: 46.2351\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.7338 - val_loss: 50.9310\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.1888 - val_loss: 45.1116\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0010 - val_loss: 45.0043\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8788 - val_loss: 44.8918\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.0183 - val_loss: 45.9094\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.6635 - val_loss: 45.0190\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9013 - val_loss: 45.2373\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.0843 - val_loss: 45.4507\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.9348 - val_loss: 45.1522\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5816 - val_loss: 45.8306\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.1011 - val_loss: 44.9333\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9074 - val_loss: 45.1758\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1207 - val_loss: 44.9221\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9546 - val_loss: 46.4459\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9405 - val_loss: 44.9215\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.3083 - val_loss: 44.9037\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.3195 - val_loss: 46.2731\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.6332 - val_loss: 48.0900\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4040 - val_loss: 45.9312\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7203 - val_loss: 48.0457\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8131 - val_loss: 45.2721\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.0421 - val_loss: 45.6670\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.6673 - val_loss: 45.2047\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7048 - val_loss: 45.0746\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.2860 - val_loss: 44.9395\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9867 - val_loss: 45.1184\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6732 - val_loss: 44.8203\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3687 - val_loss: 45.3014\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.1930 - val_loss: 45.2178\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.5684 - val_loss: 46.8367\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5943 - val_loss: 44.9925\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4441 - val_loss: 46.1097\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4335 - val_loss: 44.9232\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.3873 - val_loss: 45.1132\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9832 - val_loss: 45.2959\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9023 - val_loss: 52.5991\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5445 - val_loss: 44.8213\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.4288 - val_loss: 45.0663\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.3042 - val_loss: 45.0101\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9206 - val_loss: 45.5422\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 46.8961 - val_loss: 46.2759\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4025 - val_loss: 45.0227\n",
      "10/10 [==============================] - 0s 987us/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 47.0207 - val_loss: 45.4432\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7706 - val_loss: 45.8892\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.9143 - val_loss: 45.1214\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 46.7781 - val_loss: 48.8645\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.4197 - val_loss: 45.1225\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7513 - val_loss: 45.3990\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.1721 - val_loss: 45.2957\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.4249 - val_loss: 45.0740\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 46.9011 - val_loss: 46.6648\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6630 - val_loss: 45.7388\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3805 - val_loss: 46.6248\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8588 - val_loss: 45.9446\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5696 - val_loss: 45.1247\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6206 - val_loss: 45.5787\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.9928 - val_loss: 46.3885\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.7382 - val_loss: 46.1100\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1219 - val_loss: 46.0991\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7682 - val_loss: 47.0085\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4293 - val_loss: 45.1173\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.4376 - val_loss: 45.1736\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 47.2557 - val_loss: 45.1137\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0536 - val_loss: 45.2157\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.0002 - val_loss: 44.9528\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.1682 - val_loss: 45.0641\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5447 - val_loss: 45.0052\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5781 - val_loss: 46.5949\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.1492 - val_loss: 45.1566\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.4729 - val_loss: 47.0946\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7909 - val_loss: 45.1394\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8915 - val_loss: 45.1622\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.1369 - val_loss: 48.2102\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7671 - val_loss: 45.7172\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3818 - val_loss: 44.8935\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.3448 - val_loss: 46.1057\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4489 - val_loss: 45.5507\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.2121 - val_loss: 54.2928\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.4123 - val_loss: 45.9408\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.2720 - val_loss: 47.4716\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.1999 - val_loss: 45.3085\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.0065 - val_loss: 45.9048\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2469 - val_loss: 45.0387\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7457 - val_loss: 46.9410\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0865 - val_loss: 46.3618\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.8938 - val_loss: 47.3315\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.2395 - val_loss: 45.6096\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.5915 - val_loss: 45.3232\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.2372 - val_loss: 45.0980\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7556 - val_loss: 45.2609\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6771 - val_loss: 46.2683\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 46.7514 - val_loss: 45.4640\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0871 - val_loss: 45.8126\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.2107 - val_loss: 45.1834\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4817 - val_loss: 47.6702\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.5133 - val_loss: 45.3656\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4172 - val_loss: 45.5000\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.3320 - val_loss: 45.8895\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.8721 - val_loss: 46.6503\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6406 - val_loss: 48.2638\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6164 - val_loss: 45.1849\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.0702 - val_loss: 45.1857\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9637 - val_loss: 45.1851\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.6978 - val_loss: 45.4292\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.7171 - val_loss: 44.8949\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.0078 - val_loss: 45.7097\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.0236 - val_loss: 45.0027\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8179 - val_loss: 45.8540\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.3316 - val_loss: 44.7764\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9850 - val_loss: 45.8354\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.4926 - val_loss: 45.2667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.6308 - val_loss: 46.1260\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.2556 - val_loss: 45.0712\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.8837 - val_loss: 46.0086\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5728 - val_loss: 45.0075\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.3126 - val_loss: 45.9965\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 47.2802 - val_loss: 45.0850\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.2695 - val_loss: 44.9795\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.6460 - val_loss: 45.8266\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.5632 - val_loss: 45.6088\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.7094 - val_loss: 45.1928\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.5632 - val_loss: 48.0797\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8128 - val_loss: 44.9472\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4666 - val_loss: 45.1331\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.4602 - val_loss: 45.2761\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 49.0164 - val_loss: 45.6179\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 49.5402 - val_loss: 50.9126\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.5914 - val_loss: 46.6875\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.4108 - val_loss: 49.4351\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.0570 - val_loss: 45.0411\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.5284 - val_loss: 44.8707\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0142 - val_loss: 45.1038\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.1697 - val_loss: 45.0815\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.9789 - val_loss: 46.4576\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.6537 - val_loss: 44.9858\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 47.0481 - val_loss: 45.6917\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3199 - val_loss: 45.8254\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 48.0767 - val_loss: 45.6208\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.1856 - val_loss: 46.2947\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 48.8366 - val_loss: 45.5420\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.7967 - val_loss: 45.3218\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.2639 - val_loss: 46.1256\n",
      "10/10 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "mse3 = [] # Initializing the list for appending the MSE upon each iteration\n",
    "for i in range(50):\n",
    "    mse3.append(MSE(model, X_norm, Y, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reporting Mean and Standard Deviation of the Mean Squared Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the mean squared error\n",
    "x = ['{0}'.format(i+1) for i in range(50)]\n",
    "plt.bar(x,mse3)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Mean Squared Error - MSE')\n",
    "plt.title('Evolution of MSE of normalized data over the iterations - epochs:100')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of the MSE's: 51.4439490644891\n",
      "Standard deviation of the MSE's: 1.7234248224899242\n"
     ]
    }
   ],
   "source": [
    "# Mean of the MSE's\n",
    "mean_partC = np.array(mse3).mean()\n",
    "print(\"Mean of the MSE's:\",mean_partC)\n",
    "\n",
    "# Standard deviation of the MSE'S\n",
    "std_partC = np.array(mse3).std()\n",
    "print(\"Standard deviation of the MSE's:\",std_partC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison between the Mean of the Mean Squared Errors on increasing the number of epochs to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(['EPOCHS:50','EPOCHS:100'],[mean_partB,mean_partC])\n",
    "plt.xlabel('Number of epochs')\n",
    "plt.ylabel(\"Mean of the MSE's\")\n",
    "plt.title('Normalized data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5.8320181693097055"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Difference between both mean of the MSE's\n",
    "mean_partC-mean_partB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be observed that on increasing the number of epochs the mean of the MSE reduces. So, to reduce error and increase accuracy of our model, we can increse the number of epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D. Build a new model and report mean for the MSE's with normalized data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us build a new neural network model that performs regression. The charecteristics of the new model are bleow:\n",
    "<ul>\n",
    "    <li>Number of hidden layers: <b>3</b></li>\n",
    "    <li>Number of nodes in each of the hidden layer: <b>10</b></li>\n",
    "    <li>Activation function: <b>ReLU</b></li>\n",
    "    <li>Rest of the features are same as the <b>Base Line Model</b></li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the new neural network\n",
    "def base_line_model_new():\n",
    "    # Model Creation\n",
    "    reg_mod = Sequential()\n",
    "    reg_mod.add(Dense(10, activation='relu',input_shape=(n_cols,)))\n",
    "    reg_mod.add(Dense(10, activation='relu',input_shape=(n_cols,)))\n",
    "    reg_mod.add(Dense(10, activation='relu',input_shape=(n_cols,)))\n",
    "    reg_mod.add(Dense(1))\n",
    "    # Model compilation\n",
    "    reg_mod.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return reg_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_new = base_line_model_new()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 38.1140 - val_loss: 41.7905\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.3280 - val_loss: 40.7122\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 37.7269 - val_loss: 44.7886\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 36.9279 - val_loss: 42.1988\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.1784 - val_loss: 42.0318\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 36.0928 - val_loss: 43.0443\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 36.8112 - val_loss: 44.8216\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.1908 - val_loss: 41.4896\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.9147 - val_loss: 42.2331\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.2154 - val_loss: 50.7866\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 37.5335 - val_loss: 45.1785\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 35.6228 - val_loss: 43.7102\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.0439 - val_loss: 41.9357\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.3788 - val_loss: 42.0823\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.2045 - val_loss: 43.6344\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.5928 - val_loss: 43.5107\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 38.5571 - val_loss: 48.6341\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.6875 - val_loss: 44.8140\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.4622 - val_loss: 42.2190\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.4005 - val_loss: 42.3006\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 37.5788 - val_loss: 45.7382\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 39.7771 - val_loss: 43.1183\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 38.6961 - val_loss: 42.1223\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 38.3901 - val_loss: 42.0678\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 35.8783 - val_loss: 41.7179\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.2103 - val_loss: 43.8108\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 37.3994 - val_loss: 42.9320\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 41.9258 - val_loss: 46.0271\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 39.5925 - val_loss: 46.3723\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.7236 - val_loss: 41.7188\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 35.8113 - val_loss: 42.5539\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.9944 - val_loss: 42.1304\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.5834 - val_loss: 42.5067\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.6291 - val_loss: 41.2508\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 35.0417 - val_loss: 42.7081\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.1650 - val_loss: 42.7627\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 37.5673 - val_loss: 42.4941\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 36.1616 - val_loss: 45.6969\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 39.1866 - val_loss: 42.1617\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 35.1831 - val_loss: 41.9073\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 37.4786 - val_loss: 43.9415\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 36.0426 - val_loss: 43.5974\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 34.6810 - val_loss: 41.8774\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 36.4525 - val_loss: 42.2536\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 39.7653 - val_loss: 41.7555\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 37.4708 - val_loss: 42.6325\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 36.8359 - val_loss: 42.2149\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 35.8483 - val_loss: 41.7311\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 36.2935 - val_loss: 42.2097\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 37.2980 - val_loss: 43.8409\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 36.2430 - val_loss: 43.6643\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 39.7206 - val_loss: 42.8906\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 37.3121 - val_loss: 42.1683\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 37.7010 - val_loss: 41.9841\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 37.3809 - val_loss: 45.7688\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 38.9969 - val_loss: 42.5049\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 35.1119 - val_loss: 41.6709\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.5042 - val_loss: 44.7692\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.7107 - val_loss: 43.8523\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 36.1810 - val_loss: 42.9377\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 37.9389 - val_loss: 42.9036\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 35.2318 - val_loss: 40.9822\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.4607 - val_loss: 43.3735\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.6549 - val_loss: 41.1234\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 36.2649 - val_loss: 42.7471\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 35.1711 - val_loss: 41.7930\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 35.2400 - val_loss: 41.9270\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 36.6414 - val_loss: 42.4789\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 36.4643 - val_loss: 45.8504\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 37.4163 - val_loss: 43.7575\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 40.3451 - val_loss: 47.1020\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 36.8677 - val_loss: 44.1135\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.6257 - val_loss: 46.2701\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.4511 - val_loss: 41.9837\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 36.0477 - val_loss: 42.7042\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.8459 - val_loss: 41.8314\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.7526 - val_loss: 41.9704\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 35.2748 - val_loss: 42.0371\n",
      "Epoch 29/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 34.9916 - val_loss: 43.4063\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.8276 - val_loss: 42.2006\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 35.8889 - val_loss: 41.4892\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.3998 - val_loss: 45.6553\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 37.4071 - val_loss: 42.3049\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 36.6967 - val_loss: 41.3066\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 39.8748 - val_loss: 46.3136\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 39.3005 - val_loss: 42.3844\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.5351 - val_loss: 41.9825\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 35.6692 - val_loss: 41.7582\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 37.7569 - val_loss: 42.6484\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 37.3122 - val_loss: 45.6540\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.5073 - val_loss: 44.4972\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.0707 - val_loss: 41.9917\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.1120 - val_loss: 45.9852\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 37.4946 - val_loss: 47.7655\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.2185 - val_loss: 41.7935\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 35.5213 - val_loss: 43.3538\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 36.8751 - val_loss: 42.9799\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.7362 - val_loss: 41.4698\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.8653 - val_loss: 43.5734\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 37.6015 - val_loss: 42.6938\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 36.5146 - val_loss: 41.8967\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.8978 - val_loss: 42.3167\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.8140 - val_loss: 46.3169\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 39.3090 - val_loss: 41.6956\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.6236 - val_loss: 41.7442\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.5125 - val_loss: 43.7868\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.9883 - val_loss: 48.2618\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 35.8270 - val_loss: 42.8285\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 35.0440 - val_loss: 44.1603\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 37.0956 - val_loss: 42.6974\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.6865 - val_loss: 44.2998\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 37.0862 - val_loss: 48.9709\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 39.7255 - val_loss: 42.0766\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 35.9819 - val_loss: 42.8748\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.1206 - val_loss: 44.6666\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.7862 - val_loss: 42.0279\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.0733 - val_loss: 43.6029\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.4286 - val_loss: 41.5519\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.5050 - val_loss: 42.9475\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.6241 - val_loss: 42.5116\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 35.8860 - val_loss: 41.7809\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.6699 - val_loss: 42.4527\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 35.6856 - val_loss: 42.2831\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.2538 - val_loss: 43.4717\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.5357 - val_loss: 41.6974\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.0081 - val_loss: 42.1478\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.4422 - val_loss: 43.0544\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 37.2266 - val_loss: 41.5610\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 39.0402 - val_loss: 42.2800\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 38.0676 - val_loss: 42.7547\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 35.3728 - val_loss: 42.2133\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.3068 - val_loss: 43.2739\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 38.6065 - val_loss: 43.6879\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.1310 - val_loss: 42.2234\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 35.6341 - val_loss: 42.6830\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 36.0283 - val_loss: 41.7641\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 37.5077 - val_loss: 45.0798\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.9961 - val_loss: 43.3813\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 37.6777 - val_loss: 41.7338\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.9697 - val_loss: 48.3205\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 42.8531 - val_loss: 52.9006\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 39.8779 - val_loss: 48.4678\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 39.4301 - val_loss: 44.8072\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 39.4267 - val_loss: 42.8421\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 37.6240 - val_loss: 43.7433\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 37.5927 - val_loss: 44.3648\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 40.0446 - val_loss: 42.4618\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 37.1827 - val_loss: 42.8164\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.6790 - val_loss: 43.4648\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.8505 - val_loss: 43.7573\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 37.0023 - val_loss: 45.3184\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 36.0130 - val_loss: 41.6859\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 38.6650 - val_loss: 41.0715\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 40.8514 - val_loss: 52.5808\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 39.7258 - val_loss: 53.1886\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 36.7080 - val_loss: 41.8529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.2952 - val_loss: 42.4426\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.2922 - val_loss: 42.1092\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 35.2684 - val_loss: 43.2028\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 36.8141 - val_loss: 41.5116\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.2943 - val_loss: 43.0931\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 36.6215 - val_loss: 43.1441\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 36.6727 - val_loss: 41.9487\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.9379 - val_loss: 49.4768\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 37.2431 - val_loss: 41.7025\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.8669 - val_loss: 45.0575\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 35.5067 - val_loss: 45.8634\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 37.6319 - val_loss: 42.5019\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 36.1304 - val_loss: 44.3221\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.4584 - val_loss: 42.1009\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.0878 - val_loss: 42.9212\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.0944 - val_loss: 52.0722\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 36.9142 - val_loss: 44.9076\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 35.9027 - val_loss: 42.4275\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.2990 - val_loss: 42.4993\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.7056 - val_loss: 43.8649\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.9272 - val_loss: 44.4346\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.9831 - val_loss: 42.1886\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 37.6879 - val_loss: 45.2175\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.4262 - val_loss: 42.8337\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.6237 - val_loss: 42.2330\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.1668 - val_loss: 41.9374\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.6064 - val_loss: 44.8028\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 36.7516 - val_loss: 46.9809\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.6843 - val_loss: 41.7796\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.1770 - val_loss: 43.0947\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 39.4418 - val_loss: 61.4664\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 43.9917 - val_loss: 49.9681\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.2037 - val_loss: 43.2168\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 35.6577 - val_loss: 42.8760\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.1759 - val_loss: 42.2457\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.8771 - val_loss: 42.7883\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 36.1354 - val_loss: 43.0470\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.9042 - val_loss: 48.8136\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 43.4477 - val_loss: 42.7833\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 38.0782 - val_loss: 43.8640\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 36.3066 - val_loss: 43.8129\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.8139 - val_loss: 43.0319\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.7772 - val_loss: 41.9496\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.1891 - val_loss: 47.8051\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 38.8121 - val_loss: 44.0687\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.8318 - val_loss: 44.4540\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.5876 - val_loss: 42.7690\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.7304 - val_loss: 45.3002\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 35.9464 - val_loss: 41.7918\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.3691 - val_loss: 44.4817\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.8761 - val_loss: 45.4218\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.9384 - val_loss: 41.2778\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.1886 - val_loss: 44.6927\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 42.5336 - val_loss: 46.1744\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 38.2163 - val_loss: 47.8565\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 38.3989 - val_loss: 41.7365\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.1326 - val_loss: 42.1304\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 36.1362 - val_loss: 41.6711\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.9728 - val_loss: 41.4890\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.0973 - val_loss: 41.9703\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 37.0711 - val_loss: 43.1931\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 38.0581 - val_loss: 49.4391\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 41.3166 - val_loss: 44.7562\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.1389 - val_loss: 42.9087\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.1356 - val_loss: 43.0975\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 39.4256 - val_loss: 46.5575\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 38.2353 - val_loss: 43.6733\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.1546 - val_loss: 42.9915\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.6061 - val_loss: 41.6952\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.7265 - val_loss: 43.0037\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.2756 - val_loss: 43.6695\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.6403 - val_loss: 43.3048\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.0567 - val_loss: 43.8255\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 39.2055 - val_loss: 43.8648\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.2356 - val_loss: 42.5880\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.4198 - val_loss: 45.7034\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 38.4415 - val_loss: 54.3439\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 38.3339 - val_loss: 58.6523\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 36.5273 - val_loss: 42.5342\n",
      "Epoch 36/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 35.0525 - val_loss: 49.1334\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.8822 - val_loss: 43.3928\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.7754 - val_loss: 42.2993\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 36.5648 - val_loss: 48.6905\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 38.8172 - val_loss: 42.8527\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 35.7460 - val_loss: 42.8780\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.1571 - val_loss: 42.4822\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.9166 - val_loss: 44.4633\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 37.6641 - val_loss: 49.2143\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 37.0598 - val_loss: 42.1664\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.7201 - val_loss: 43.0020\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 36.1254 - val_loss: 42.0992\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 35.1690 - val_loss: 42.2320\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 35.9360 - val_loss: 42.2337\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 37.5299 - val_loss: 45.7896\n",
      "10/10 [==============================] - 0s 724us/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 41.5526 - val_loss: 48.0341\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 38.6521 - val_loss: 42.6737\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 35.5475 - val_loss: 42.7352\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.1526 - val_loss: 42.4319\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.9959 - val_loss: 43.4033\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.2897 - val_loss: 42.9019\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 37.3343 - val_loss: 51.6062\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.3489 - val_loss: 46.9358\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.3287 - val_loss: 47.7232\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 40.9675 - val_loss: 50.4167\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 39.9819 - val_loss: 45.3511\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.5018 - val_loss: 44.0396\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 35.6281 - val_loss: 42.0611\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.3227 - val_loss: 44.5015\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.8070 - val_loss: 44.0686\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 35.6338 - val_loss: 42.8462\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.2874 - val_loss: 52.3795\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 38.6608 - val_loss: 46.7729\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 36.6752 - val_loss: 42.9196\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.6032 - val_loss: 42.3715\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.4510 - val_loss: 43.0567\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.3359 - val_loss: 47.6974\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 37.0943 - val_loss: 50.1599\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 37.5320 - val_loss: 45.4072\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 35.0198 - val_loss: 45.1395\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 37.3368 - val_loss: 43.9767\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 35.4146 - val_loss: 42.3792\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.7025 - val_loss: 41.7812\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.7691 - val_loss: 42.8288\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.9599 - val_loss: 43.4892\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 34.8471 - val_loss: 44.1791\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.9254 - val_loss: 42.7765\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 35.0258 - val_loss: 46.3448\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.6443 - val_loss: 42.2782\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 36.1062 - val_loss: 61.1583\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.3302 - val_loss: 46.2202\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 38.5466 - val_loss: 52.1969\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.5795 - val_loss: 42.5978\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 35.1415 - val_loss: 43.9603\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 37.1079 - val_loss: 48.5540\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.8633 - val_loss: 49.0301\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 38.6219 - val_loss: 43.8103\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 36.1902 - val_loss: 43.2441\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.2764 - val_loss: 45.6535\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 36.4453 - val_loss: 45.7646\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.8843 - val_loss: 42.0931\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 36.8263 - val_loss: 42.0617\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 35.2573 - val_loss: 43.3109\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.1408 - val_loss: 43.8993\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.6637 - val_loss: 42.7982\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 35.6240 - val_loss: 43.2540\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.8298 - val_loss: 46.1060\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.3959 - val_loss: 44.3991\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 35.4034 - val_loss: 43.8487\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.8863 - val_loss: 43.5454\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.2433 - val_loss: 41.7933\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 35.3601 - val_loss: 45.6249\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 39.5418 - val_loss: 47.8826\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 35.7497 - val_loss: 43.2919\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.6934 - val_loss: 42.5762\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.2155 - val_loss: 47.5638\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.1064 - val_loss: 45.6601\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 39.4917 - val_loss: 50.0094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 38.3182 - val_loss: 43.9680\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 38.0819 - val_loss: 46.3991\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 38.4409 - val_loss: 42.9157\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 36.1643 - val_loss: 45.0945\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.7004 - val_loss: 42.5819\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 37.3940 - val_loss: 45.4574\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 36.4349 - val_loss: 46.5452\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.1409 - val_loss: 44.3857\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.1189 - val_loss: 45.1165\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 35.7619 - val_loss: 43.7899\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 35.2816 - val_loss: 42.8137\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 35.8749 - val_loss: 43.7508\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 35.1635 - val_loss: 44.6926\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 37.0254 - val_loss: 42.5416\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 36.8910 - val_loss: 42.0713\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 36.8987 - val_loss: 45.7117\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 35.6960 - val_loss: 49.3576\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 37.0561 - val_loss: 44.2328\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 35.9812 - val_loss: 42.6080\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 35.1590 - val_loss: 43.1089\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 37.1546 - val_loss: 49.0438\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.3400 - val_loss: 42.0774\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.3155 - val_loss: 43.2822\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.2143 - val_loss: 42.4554\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 38.4668 - val_loss: 44.1664\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.9798 - val_loss: 43.6417\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.6695 - val_loss: 45.0060\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 36.7177 - val_loss: 46.1520\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 42.1821 - val_loss: 43.1702\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 36.7654 - val_loss: 46.6330\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 36.0634 - val_loss: 44.4342\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 35.9755 - val_loss: 42.7593\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.8220 - val_loss: 43.7686\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 35.2907 - val_loss: 44.8418\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.3026 - val_loss: 42.0061\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 38.4025 - val_loss: 46.2736\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 35.8750 - val_loss: 41.6068\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 35.7553 - val_loss: 42.6088\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.3641 - val_loss: 44.7536\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 35.7829 - val_loss: 43.0060\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.2167 - val_loss: 51.1626\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 38.5839 - val_loss: 44.8018\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 37.7859 - val_loss: 43.4040\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.0398 - val_loss: 50.0381\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 36.9872 - val_loss: 45.2790\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 41.8781 - val_loss: 43.2844\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 36.7832 - val_loss: 41.8346\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 34.9620 - val_loss: 42.3807\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 37.4917 - val_loss: 46.3992\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 38.4463 - val_loss: 45.7832\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 36.7320 - val_loss: 43.4962\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 39.2836 - val_loss: 43.0295\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 37.5615 - val_loss: 46.2296\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 35.9828 - val_loss: 43.5064\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.1787 - val_loss: 43.8015\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 37.2728 - val_loss: 43.2108\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 35.2492 - val_loss: 42.8200\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 36.3676 - val_loss: 43.0751\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.5376 - val_loss: 42.3144\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.3885 - val_loss: 46.9384\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 35.4233 - val_loss: 42.5272\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 39.6205 - val_loss: 50.7068\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 38.1442 - val_loss: 41.9325\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 35.9288 - val_loss: 42.8146\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.2703 - val_loss: 46.8860\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 37.6179 - val_loss: 47.5874\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 36.1043 - val_loss: 44.6908\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.0989 - val_loss: 43.7578\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.7631 - val_loss: 44.5087\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 37.0198 - val_loss: 42.7684\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.3515 - val_loss: 43.7710\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.8450 - val_loss: 42.0973\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.3540 - val_loss: 42.4631\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 37.0914 - val_loss: 47.0973\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.0269 - val_loss: 42.1747\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 37.9185 - val_loss: 43.1118\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 41.2280 - val_loss: 42.7163\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 37.0029 - val_loss: 42.0598\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.8482 - val_loss: 43.7492\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 34.5914 - val_loss: 41.8627\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.8713 - val_loss: 43.0724\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.1290 - val_loss: 42.1506\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 36.0946 - val_loss: 42.8175\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 35.7184 - val_loss: 48.8120\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 36.5067 - val_loss: 49.5081\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.7393 - val_loss: 46.8649\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.1231 - val_loss: 43.4958\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 34.4916 - val_loss: 42.4669\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.1950 - val_loss: 41.7443\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 37.7768 - val_loss: 45.5938\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.8178 - val_loss: 43.8952\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 34.7912 - val_loss: 43.2883\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.3914 - val_loss: 43.0588\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.9326 - val_loss: 42.2054\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.0684 - val_loss: 43.3638\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 36.2464 - val_loss: 45.6749\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 37.4076 - val_loss: 43.4283\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 35.6036 - val_loss: 42.0499\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 39.4227 - val_loss: 44.4998\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 35.0653 - val_loss: 42.1361\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 37.3874 - val_loss: 43.8877\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.0920 - val_loss: 43.8410\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 34.9347 - val_loss: 45.9910\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 38.2784 - val_loss: 44.2057\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 35.5060 - val_loss: 46.4882\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.3755 - val_loss: 42.9635\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 37.1668 - val_loss: 44.2144\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 35.0465 - val_loss: 46.4844\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 36.4651 - val_loss: 46.4601\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 36.3833 - val_loss: 44.1683\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 35.4299 - val_loss: 43.5483\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.9811 - val_loss: 43.5728\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.7892 - val_loss: 46.3158\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.9292 - val_loss: 41.8680\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.5671 - val_loss: 41.5219\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.2592 - val_loss: 42.9670\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 37.4690 - val_loss: 46.1908\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 35.7309 - val_loss: 48.2332\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 36.8111 - val_loss: 41.9659\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 35.2405 - val_loss: 42.4480\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 35.7273 - val_loss: 44.0180\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 36.3163 - val_loss: 43.2023\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.6989 - val_loss: 42.1568\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.4734 - val_loss: 42.4991\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.1108 - val_loss: 42.7708\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.6740 - val_loss: 42.9813\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 33.8140 - val_loss: 45.5273\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.3501 - val_loss: 45.7528\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 38.2137 - val_loss: 53.0639\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.7945 - val_loss: 41.4016\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.8491 - val_loss: 45.7168\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.5593 - val_loss: 42.3570\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.9447 - val_loss: 53.8952\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 37.5664 - val_loss: 44.0511\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 37.5174 - val_loss: 44.6245\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.9894 - val_loss: 42.4466\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 36.7976 - val_loss: 43.5230\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 35.3797 - val_loss: 43.6502\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 37.7079 - val_loss: 48.5928\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 37.6880 - val_loss: 41.2025\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.2240 - val_loss: 42.9627\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.5390 - val_loss: 41.6655\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.5443 - val_loss: 42.9352\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.3948 - val_loss: 41.8369\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.7644 - val_loss: 45.3105\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 36.2593 - val_loss: 44.6417\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 36.7958 - val_loss: 44.0909\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 34.5000 - val_loss: 42.9398\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.0670 - val_loss: 44.8221\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 35.6242 - val_loss: 46.1330\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.7770 - val_loss: 43.3360\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 36.1508 - val_loss: 42.9502\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.6895 - val_loss: 42.5344\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 35.0982 - val_loss: 46.2148\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 35.2442 - val_loss: 45.4750\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 38.3124 - val_loss: 43.0845\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.5462 - val_loss: 44.1403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.6818 - val_loss: 43.5391\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 42.9327 - val_loss: 46.1507\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 38.1481 - val_loss: 46.8310\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 39.1245 - val_loss: 45.0532\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 37.0457 - val_loss: 43.3352\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 36.0416 - val_loss: 44.8433\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.1104 - val_loss: 44.0976\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 33.7565 - val_loss: 42.8252\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.6340 - val_loss: 43.6779\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.2732 - val_loss: 43.1290\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 35.2637 - val_loss: 43.2901\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 35.1970 - val_loss: 43.8123\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.5503 - val_loss: 46.0042\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.3863 - val_loss: 41.7413\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.5083 - val_loss: 43.6416\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.2647 - val_loss: 43.3485\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.6397 - val_loss: 42.2315\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 33.8743 - val_loss: 46.4073\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 39.3023 - val_loss: 43.2232\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 34.9031 - val_loss: 44.7941\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 35.2174 - val_loss: 44.0655\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.1459 - val_loss: 43.6698\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.4488 - val_loss: 45.2626\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 36.9830 - val_loss: 48.8141\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 36.3517 - val_loss: 42.4635\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 35.8792 - val_loss: 42.7702\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.5340 - val_loss: 42.4328\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 34.6261 - val_loss: 42.8133\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.5061 - val_loss: 47.7985\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 38.6560 - val_loss: 52.8984\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 39.1121 - val_loss: 42.9451\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.0996 - val_loss: 43.4743\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 35.6465 - val_loss: 43.9583\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.4819 - val_loss: 41.7383\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.7531 - val_loss: 46.3697\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 34.6622 - val_loss: 44.1791\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 37.1662 - val_loss: 45.2910\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 38.1256 - val_loss: 46.8216\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.9877 - val_loss: 41.7830\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 40.5106 - val_loss: 50.1196\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.0691 - val_loss: 43.3275\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.4957 - val_loss: 44.7674\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 37.2795 - val_loss: 44.9669\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 36.0854 - val_loss: 43.2145\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.1229 - val_loss: 43.3889\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.9145 - val_loss: 42.0813\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.6323 - val_loss: 45.2222\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 33.8818 - val_loss: 44.6389\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.9146 - val_loss: 45.9192\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.8530 - val_loss: 41.9428\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.1687 - val_loss: 46.4823\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 38.9365 - val_loss: 43.0179\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 35.5840 - val_loss: 42.2761\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.5159 - val_loss: 43.8613\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 35.9308 - val_loss: 41.3660\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 37.3913 - val_loss: 43.3534\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 34.7277 - val_loss: 43.8458\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.5295 - val_loss: 46.0437\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 43.5632 - val_loss: 48.5584\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.8286 - val_loss: 42.8408\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.9213 - val_loss: 44.1683\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.8882 - val_loss: 44.0004\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 38.0208 - val_loss: 51.9586\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 43.4996 - val_loss: 44.7492\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 40.9666 - val_loss: 43.5427\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.8511 - val_loss: 43.5442\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 38.7773 - val_loss: 42.3853\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 40.8323 - val_loss: 47.7342\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 36.2882 - val_loss: 42.0328\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.5248 - val_loss: 42.6960\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.4449 - val_loss: 44.1826\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.3845 - val_loss: 42.5759\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 35.9053 - val_loss: 43.2756\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 37.8985 - val_loss: 44.0848\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 36.5807 - val_loss: 47.9024\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 38.7798 - val_loss: 43.9517\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.4791 - val_loss: 43.7376\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 35.0392 - val_loss: 42.3607\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.6516 - val_loss: 44.4418\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 34.2470 - val_loss: 44.3536\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 37.1322 - val_loss: 45.5014\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 35.0649 - val_loss: 42.6172\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.2061 - val_loss: 41.6811\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 33.5443 - val_loss: 44.5290\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.1853 - val_loss: 42.7949\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 35.3333 - val_loss: 41.5388\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 34.5174 - val_loss: 45.0520\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.3729 - val_loss: 44.4146\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 35.3415 - val_loss: 44.6737\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 35.1918 - val_loss: 43.0924\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 37.7618 - val_loss: 42.6613\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.2752 - val_loss: 45.1346\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 34.5373 - val_loss: 44.1520\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 34.3361 - val_loss: 43.4266\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 35.7358 - val_loss: 44.2303\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.5451 - val_loss: 43.0952\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 37.6655 - val_loss: 42.8076\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.9384 - val_loss: 47.5390\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.5442 - val_loss: 42.8506\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.5174 - val_loss: 43.6811\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.3605 - val_loss: 42.6670\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 36.3201 - val_loss: 43.6676\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.1898 - val_loss: 44.6384\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 36.1492 - val_loss: 47.6884\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.4845 - val_loss: 53.0315\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.9565 - val_loss: 44.1313\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.6167 - val_loss: 44.9298\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.6083 - val_loss: 43.6143\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.8510 - val_loss: 43.2235\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.3564 - val_loss: 41.5856\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.7949 - val_loss: 42.8455\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 33.9714 - val_loss: 44.2792\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.7325 - val_loss: 42.9913\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.4532 - val_loss: 42.9728\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 34.1628 - val_loss: 43.8718\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 36.2677 - val_loss: 56.8570\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 37.0575 - val_loss: 47.7960\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.7238 - val_loss: 43.8937\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.0710 - val_loss: 42.8046\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 37.4383 - val_loss: 53.3738\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 38.2467 - val_loss: 45.3072\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 34.1833 - val_loss: 42.8312\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.8956 - val_loss: 43.7261\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 36.7642 - val_loss: 45.1868\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.2440 - val_loss: 43.7942\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.2943 - val_loss: 45.8576\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.6699 - val_loss: 45.0604\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 36.1830 - val_loss: 47.3010\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.8855 - val_loss: 50.1218\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.5499 - val_loss: 43.7288\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 34.9665 - val_loss: 41.5747\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.6575 - val_loss: 42.9070\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.4989 - val_loss: 49.4019\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 37.3831 - val_loss: 42.0711\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.6050 - val_loss: 45.8122\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 36.6892 - val_loss: 46.0323\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 39.4010 - val_loss: 49.3981\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 35.6254 - val_loss: 42.7387\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 34.4605 - val_loss: 43.8048\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.2622 - val_loss: 43.0200\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.3413 - val_loss: 42.3186\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.3020 - val_loss: 45.2517\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.8007 - val_loss: 45.1469\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.0245 - val_loss: 42.1534\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.2722 - val_loss: 45.2492\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 35.2143 - val_loss: 43.4246\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 37.0437 - val_loss: 43.6182\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.0950 - val_loss: 46.7566\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 37.3692 - val_loss: 47.7489\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 37.2439 - val_loss: 42.2412\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 35.1122 - val_loss: 42.3968\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.8234 - val_loss: 48.9750\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 34.5962 - val_loss: 43.6668\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 34.9152 - val_loss: 45.7629\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 36.9196 - val_loss: 55.5374\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 38.0213 - val_loss: 48.3765\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.0174 - val_loss: 43.9359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 34.6247 - val_loss: 41.6339\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 35.8161 - val_loss: 46.2974\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 37.4649 - val_loss: 50.6614\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 41.8392 - val_loss: 52.6076\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.4061 - val_loss: 42.1341\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.5147 - val_loss: 48.5328\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.4077 - val_loss: 49.4693\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 35.7116 - val_loss: 45.0272\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 41.0922 - val_loss: 46.9339\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.7680 - val_loss: 44.1200\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.7001 - val_loss: 43.0888\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.4298 - val_loss: 43.3080\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.7611 - val_loss: 43.1902\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 33.9832 - val_loss: 46.2286\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 35.5948 - val_loss: 43.5293\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 35.2061 - val_loss: 43.4013\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.6099 - val_loss: 45.9680\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.2280 - val_loss: 45.8668\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 37.4096 - val_loss: 46.3446\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 36.2689 - val_loss: 43.8263\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 36.5036 - val_loss: 41.6462\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 35.2545 - val_loss: 44.2626\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 38.0442 - val_loss: 43.8608\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 38.9567 - val_loss: 44.1361\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.8798 - val_loss: 42.6094\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 35.4725 - val_loss: 45.1864\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.4596 - val_loss: 45.0044\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.3152 - val_loss: 41.4497\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 35.8895 - val_loss: 43.4754\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.0529 - val_loss: 44.1634\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.0685 - val_loss: 40.6129\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.0351 - val_loss: 42.4770\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 33.8508 - val_loss: 42.2256\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.8509 - val_loss: 43.5355\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.4439 - val_loss: 42.9202\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.3387 - val_loss: 42.9560\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.1662 - val_loss: 44.5172\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 38.0441 - val_loss: 51.3706\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 37.2111 - val_loss: 43.4159\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.2908 - val_loss: 42.5058\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.0178 - val_loss: 41.3550\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.9736 - val_loss: 43.8806\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.3523 - val_loss: 44.8679\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.7802 - val_loss: 42.8364\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.6773 - val_loss: 45.2850\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.1759 - val_loss: 44.3029\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.6310 - val_loss: 42.5457\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.9455 - val_loss: 43.1996\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 35.6087 - val_loss: 42.6368\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 36.9068 - val_loss: 42.3273\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 36.8607 - val_loss: 43.9742\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 36.5267 - val_loss: 43.2233\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.1696 - val_loss: 43.2784\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.7372 - val_loss: 41.5710\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 33.5030 - val_loss: 42.0522\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 36.1690 - val_loss: 47.1112\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 33.7060 - val_loss: 43.5840\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.4362 - val_loss: 43.7992\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.2659 - val_loss: 49.2766\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.7341 - val_loss: 45.1302\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.6557 - val_loss: 46.3277\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 37.0665 - val_loss: 48.8948\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 36.2173 - val_loss: 41.8561\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.5586 - val_loss: 45.4942\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.5099 - val_loss: 43.6824\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.4347 - val_loss: 42.8856\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.1404 - val_loss: 43.4109\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 33.9379 - val_loss: 44.0394\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 34.0579 - val_loss: 43.6306\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 33.3062 - val_loss: 45.4719\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 36.2636 - val_loss: 44.8864\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 43.0560 - val_loss: 63.8640\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 46.8138 - val_loss: 43.8316\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 38.2820 - val_loss: 43.5664\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 40.8907 - val_loss: 50.5680\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 38.0267 - val_loss: 44.0475\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 33.9976 - val_loss: 43.8069\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 33.9811 - val_loss: 43.5452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.4620 - val_loss: 43.1375\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 36.9003 - val_loss: 41.9734\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.4919 - val_loss: 43.7076\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.7799 - val_loss: 43.6307\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.9432 - val_loss: 43.3176\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 34.3145 - val_loss: 42.2910\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.6333 - val_loss: 43.5080\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 34.0648 - val_loss: 42.5163\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 33.9404 - val_loss: 48.2339\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 38.8107 - val_loss: 42.3080\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 34.0066 - val_loss: 41.9011\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.1031 - val_loss: 42.6772\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 32.7996 - val_loss: 41.0155\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 34.9874 - val_loss: 43.9270\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 34.8440 - val_loss: 44.4973\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 35.8080 - val_loss: 44.8071\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 35.1884 - val_loss: 45.2420\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.8606 - val_loss: 42.0249\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 33.5889 - val_loss: 51.7629\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 39.9808 - val_loss: 42.6574\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 36.3467 - val_loss: 42.5711\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 35.8636 - val_loss: 42.0579\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 39.8790 - val_loss: 43.6425\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.8006 - val_loss: 42.6943\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.7221 - val_loss: 42.3769\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.8426 - val_loss: 45.2406\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.1200 - val_loss: 43.8532\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 33.8639 - val_loss: 44.5866\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.8229 - val_loss: 44.1184\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 35.0237 - val_loss: 53.2061\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 35.1963 - val_loss: 41.7107\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.9523 - val_loss: 44.9943\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 35.1693 - val_loss: 42.8533\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 35.4980 - val_loss: 45.6379\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.4366 - val_loss: 45.1822\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.7903 - val_loss: 43.6584\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.6434 - val_loss: 43.4088\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 33.5050 - val_loss: 45.3398\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 35.5960 - val_loss: 43.8684\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 36.0452 - val_loss: 43.2155\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.1564 - val_loss: 43.2008\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.5848 - val_loss: 42.8355\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.7106 - val_loss: 42.3558\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.2109 - val_loss: 42.8307\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 33.1610 - val_loss: 46.7931\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 35.7862 - val_loss: 50.3555\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.4351 - val_loss: 44.3515\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 33.1133 - val_loss: 43.3700\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.5546 - val_loss: 44.8373\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 33.3041 - val_loss: 50.6595\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 37.3302 - val_loss: 50.2200\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.0551 - val_loss: 44.8419\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.8492 - val_loss: 46.3954\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.3688 - val_loss: 44.7280\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 38.2374 - val_loss: 43.6632\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.7619 - val_loss: 43.1650\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.4881 - val_loss: 44.0254\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.5604 - val_loss: 43.9756\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 32.7346 - val_loss: 45.0338\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 33.7427 - val_loss: 44.1199\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.0497 - val_loss: 42.9263\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.2957 - val_loss: 43.1775\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 34.6917 - val_loss: 44.6043\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 34.2718 - val_loss: 44.7352\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 35.0481 - val_loss: 44.1287\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 35.8377 - val_loss: 57.8577\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 40.5246 - val_loss: 52.7558\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 33.8027 - val_loss: 43.7323\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 33.4183 - val_loss: 43.8192\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 33.9085 - val_loss: 47.4031\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 34.1280 - val_loss: 43.1125\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.3595 - val_loss: 43.2913\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 34.7839 - val_loss: 45.9759\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 32.9997 - val_loss: 47.6841\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 34.8564 - val_loss: 43.8590\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 34.1847 - val_loss: 41.9351\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 34.9488 - val_loss: 45.4786\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 35.6390 - val_loss: 43.5744\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 33.3903 - val_loss: 42.4527\n",
      "Epoch 35/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 4ms/step - loss: 33.8078 - val_loss: 43.0435\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 35.5010 - val_loss: 50.9525\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 33.9572 - val_loss: 42.7696\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 33.2071 - val_loss: 45.3055\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 32.7755 - val_loss: 45.1105\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 33.0605 - val_loss: 41.3532\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 35.7958 - val_loss: 44.1542\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 32.2903 - val_loss: 43.0943\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 33.2571 - val_loss: 43.3301\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 33.4629 - val_loss: 46.3160\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 38.6080 - val_loss: 48.2938\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.7043 - val_loss: 50.5908\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 33.9126 - val_loss: 41.9804\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 33.3811 - val_loss: 45.0904\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.1246 - val_loss: 42.8277\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 33.7739 - val_loss: 43.8896\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 33.9084 - val_loss: 46.3211\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 33.7785 - val_loss: 43.5407\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 34.6899 - val_loss: 43.0927\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 34.2721 - val_loss: 43.5928\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 32.7340 - val_loss: 44.6964\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 32.9492 - val_loss: 42.4962\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.4449 - val_loss: 43.0428\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.5073 - val_loss: 45.5014\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.1429 - val_loss: 45.6142\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.6924 - val_loss: 43.8621\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.1543 - val_loss: 42.4227\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 37.6352 - val_loss: 44.0607\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 42.9591 - val_loss: 50.5158\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 41.9054 - val_loss: 44.7825\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 33.0223 - val_loss: 41.2729\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.9921 - val_loss: 43.8429\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 32.5476 - val_loss: 42.0257\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.6168 - val_loss: 43.4374\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 33.6987 - val_loss: 40.8682\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 33.1754 - val_loss: 43.7087\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 33.6451 - val_loss: 43.6143\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.4110 - val_loss: 44.4961\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.3841 - val_loss: 48.6535\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.4721 - val_loss: 44.0345\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 33.1532 - val_loss: 43.9987\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.5441 - val_loss: 44.0004\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 34.2405 - val_loss: 42.4834\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.7935 - val_loss: 42.6238\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.6341 - val_loss: 45.1601\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 38.1840 - val_loss: 43.8925\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 34.8660 - val_loss: 41.7642\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.7949 - val_loss: 45.5026\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 36.9448 - val_loss: 48.4162\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 37.0534 - val_loss: 44.9437\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 33.7214 - val_loss: 42.0314\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 31.6465 - val_loss: 45.3484\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.3859 - val_loss: 42.0497\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 32.7460 - val_loss: 44.4715\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 35.7572 - val_loss: 48.9564\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 36.8211 - val_loss: 45.4661\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 34.1068 - val_loss: 43.8732\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.0199 - val_loss: 42.4744\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.7870 - val_loss: 41.9206\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.3470 - val_loss: 43.1666\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.2818 - val_loss: 44.3243\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.4191 - val_loss: 42.6465\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.7507 - val_loss: 47.0207\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.0882 - val_loss: 42.3233\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.0844 - val_loss: 43.0660\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.3798 - val_loss: 43.0103\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 34.1697 - val_loss: 42.7864\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.0350 - val_loss: 44.6442\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.0996 - val_loss: 43.6585\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.7555 - val_loss: 43.5184\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.2274 - val_loss: 42.8640\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.4923 - val_loss: 48.7208\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.0456 - val_loss: 46.9766\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.8029 - val_loss: 45.5960\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.5552 - val_loss: 44.3410\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.2110 - val_loss: 42.4800\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 33.1770 - val_loss: 43.6245\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.7510 - val_loss: 43.9595\n",
      "Epoch 13/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 33.7895 - val_loss: 47.7412\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.1239 - val_loss: 42.9684\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 32.6311 - val_loss: 41.1395\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.1765 - val_loss: 44.2420\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.3364 - val_loss: 41.3840\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.3450 - val_loss: 43.2101\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.7516 - val_loss: 43.0655\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.5493 - val_loss: 43.6770\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 32.4976 - val_loss: 42.7105\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.4285 - val_loss: 44.9680\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 32.0382 - val_loss: 44.0058\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.1051 - val_loss: 42.3900\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.5072 - val_loss: 45.6331\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.1638 - val_loss: 45.7618\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.1166 - val_loss: 41.4068\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.0071 - val_loss: 42.8289\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 33.5889 - val_loss: 45.7292\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 33.5826 - val_loss: 42.7297\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 31.7798 - val_loss: 46.3015\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 33.3812 - val_loss: 42.3829\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 32.7312 - val_loss: 43.2652\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 34.2928 - val_loss: 43.4012\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 32.1138 - val_loss: 43.7411\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.0351 - val_loss: 42.8056\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.8821 - val_loss: 43.3615\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.1473 - val_loss: 43.1113\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.3951 - val_loss: 45.5175\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.7787 - val_loss: 42.7302\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.4270 - val_loss: 44.7706\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.2675 - val_loss: 41.0559\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.6877 - val_loss: 43.9128\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.7174 - val_loss: 41.0165\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.5684 - val_loss: 42.7650\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.5485 - val_loss: 44.1191\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.4491 - val_loss: 42.0968\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.0926 - val_loss: 44.1736\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 33.4365 - val_loss: 44.6889\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.7061 - val_loss: 42.5053\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.6361 - val_loss: 45.8239\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.0512 - val_loss: 43.4961\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.6092 - val_loss: 42.9793\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.9248 - val_loss: 42.5609\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.9946 - val_loss: 43.0193\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.6887 - val_loss: 46.8678\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 39.7750 - val_loss: 42.0427\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.4800 - val_loss: 48.5880\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 33.4174 - val_loss: 42.6591\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 33.7472 - val_loss: 53.2917\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 37.5054 - val_loss: 42.7983\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.6430 - val_loss: 43.1471\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.3166 - val_loss: 43.1720\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.7487 - val_loss: 41.9150\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 37.0200 - val_loss: 46.1421\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.6218 - val_loss: 43.7740\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 34.4569 - val_loss: 50.5245\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.7831 - val_loss: 42.4156\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.0778 - val_loss: 43.3159\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 31.6105 - val_loss: 43.9181\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.9008 - val_loss: 43.1193\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.6152 - val_loss: 41.6922\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 33.3879 - val_loss: 44.4675\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.8816 - val_loss: 43.7322\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.5088 - val_loss: 41.9300\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.3450 - val_loss: 43.6596\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.1823 - val_loss: 45.5452\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.2543 - val_loss: 48.9697\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 38.0130 - val_loss: 46.9612\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.5889 - val_loss: 47.7835\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 35.6654 - val_loss: 51.3104\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.6970 - val_loss: 43.1649\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.5900 - val_loss: 48.9366\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 33.2518 - val_loss: 41.9066\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.8238 - val_loss: 43.2449\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.2415 - val_loss: 43.1204\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.2943 - val_loss: 44.3403\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.8589 - val_loss: 41.3576\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.1465 - val_loss: 42.0308\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.5263 - val_loss: 42.8401\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.5784 - val_loss: 42.8932\n",
      "Epoch 42/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 6ms/step - loss: 32.3101 - val_loss: 45.4972\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.4387 - val_loss: 42.6527\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.3820 - val_loss: 42.4268\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.8828 - val_loss: 42.0135\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.9345 - val_loss: 44.5218\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.6564 - val_loss: 42.0598\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.5550 - val_loss: 53.7302\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.7455 - val_loss: 44.1730\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.4971 - val_loss: 42.9631\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 33.4834 - val_loss: 41.8696\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.3008 - val_loss: 45.9208\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.3082 - val_loss: 43.1059\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.4997 - val_loss: 42.4649\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.7011 - val_loss: 45.4014\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.1140 - val_loss: 41.8903\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.1355 - val_loss: 43.2905\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.8784 - val_loss: 45.2573\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.3579 - val_loss: 44.2921\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.8532 - val_loss: 50.7527\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 38.5423 - val_loss: 46.3256\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.8343 - val_loss: 42.1394\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 33.1035 - val_loss: 44.6113\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.8117 - val_loss: 43.7724\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 31.3316 - val_loss: 43.8702\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.9611 - val_loss: 43.1356\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.1740 - val_loss: 42.4807\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.4480 - val_loss: 44.3748\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.1916 - val_loss: 43.0523\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 32.1504 - val_loss: 49.0457\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.9959 - val_loss: 43.7219\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.2431 - val_loss: 43.7700\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.6117 - val_loss: 41.7390\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.3197 - val_loss: 43.3754\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.7818 - val_loss: 42.4776\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.1922 - val_loss: 43.1477\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.1691 - val_loss: 54.8005\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.3071 - val_loss: 47.0078\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.7993 - val_loss: 41.8613\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.4612 - val_loss: 42.3590\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 32.6879 - val_loss: 42.7425\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.0416 - val_loss: 43.2865\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.4194 - val_loss: 44.4992\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.6672 - val_loss: 42.6332\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.2488 - val_loss: 44.1049\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.8803 - val_loss: 43.5367\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.4148 - val_loss: 41.4581\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 34.3793 - val_loss: 48.2542\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.1024 - val_loss: 54.4119\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.8169 - val_loss: 43.3869\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.0233 - val_loss: 42.5311\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.2930 - val_loss: 45.0309\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.8635 - val_loss: 43.8126\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 31.7541 - val_loss: 41.1293\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 33.4284 - val_loss: 43.0186\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.5703 - val_loss: 48.0881\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.2021 - val_loss: 42.7812\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.7628 - val_loss: 41.9817\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.7656 - val_loss: 44.9080\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.1623 - val_loss: 42.1793\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 32.2460 - val_loss: 44.5477\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.3452 - val_loss: 41.9868\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.8118 - val_loss: 45.9393\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.7102 - val_loss: 47.0625\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.8234 - val_loss: 45.4756\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.4606 - val_loss: 47.5912\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.7381 - val_loss: 44.5536\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.2952 - val_loss: 41.9754\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.2572 - val_loss: 42.6412\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 31.2646 - val_loss: 42.2677\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 32.1517 - val_loss: 46.7095\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.7691 - val_loss: 41.5879\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.5966 - val_loss: 43.6428\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.9462 - val_loss: 41.9820\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.7499 - val_loss: 44.2869\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.3020 - val_loss: 42.0391\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.8473 - val_loss: 46.9155\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 32.6027 - val_loss: 44.2726\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.9094 - val_loss: 43.2528\n",
      "Epoch 20/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 6ms/step - loss: 32.0385 - val_loss: 43.4139\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 32.7938 - val_loss: 46.2695\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.4756 - val_loss: 42.3084\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.6591 - val_loss: 51.4449\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 40.3547 - val_loss: 54.6782\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 39.1655 - val_loss: 49.2534\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 38.9777 - val_loss: 45.7355\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.1028 - val_loss: 45.3311\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.3127 - val_loss: 47.1472\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.3880 - val_loss: 43.7902\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.1787 - val_loss: 43.4437\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.4843 - val_loss: 43.5922\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.9415 - val_loss: 43.6851\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.5699 - val_loss: 42.6943\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.2497 - val_loss: 44.1339\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.2999 - val_loss: 44.9014\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.8728 - val_loss: 42.5449\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 32.1689 - val_loss: 42.9143\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.8578 - val_loss: 46.8326\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 37.9975 - val_loss: 44.6425\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 31.7510 - val_loss: 42.1839\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 33.1276 - val_loss: 45.0784\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.1177 - val_loss: 42.4161\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.2420 - val_loss: 43.4603\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 31.6125 - val_loss: 43.3669\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.2222 - val_loss: 44.3717\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 33.0143 - val_loss: 46.6450\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.2332 - val_loss: 44.4000\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.9684 - val_loss: 42.4192\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.1902 - val_loss: 42.4910\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.1804 - val_loss: 45.0672\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 31.6317 - val_loss: 43.4620\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.7162 - val_loss: 43.4573\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.0672 - val_loss: 43.2850\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.5345 - val_loss: 44.0853\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.2740 - val_loss: 41.6467\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.6916 - val_loss: 42.7153\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.4582 - val_loss: 41.7155\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.2973 - val_loss: 45.7654\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.4341 - val_loss: 41.5702\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 36.0600 - val_loss: 50.9826\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.7834 - val_loss: 43.8122\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.5422 - val_loss: 42.7117\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 31.8506 - val_loss: 44.1178\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.2899 - val_loss: 42.9082\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.0194 - val_loss: 43.1743\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.0583 - val_loss: 42.9241\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.8096 - val_loss: 44.5459\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 38.2341 - val_loss: 59.6226\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.2023 - val_loss: 45.6274\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.6786 - val_loss: 41.8514\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 31.5155 - val_loss: 44.4271\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.6081 - val_loss: 43.7251\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.7298 - val_loss: 43.5470\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.5125 - val_loss: 48.6324\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.5150 - val_loss: 42.3848\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.0008 - val_loss: 43.9419\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.8411 - val_loss: 42.8011\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.1493 - val_loss: 43.1128\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.0216 - val_loss: 44.8514\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.5267 - val_loss: 42.4995\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.7585 - val_loss: 48.0650\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 33.0825 - val_loss: 42.5829\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.9067 - val_loss: 46.0485\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.5173 - val_loss: 42.3441\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.2898 - val_loss: 46.6914\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.2503 - val_loss: 40.7202\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.3234 - val_loss: 44.2659\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.0781 - val_loss: 45.4278\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.0150 - val_loss: 42.7945\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.4381 - val_loss: 43.4668\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.5315 - val_loss: 45.5773\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.1207 - val_loss: 45.4868\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.0942 - val_loss: 43.5292\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.4172 - val_loss: 43.5769\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.7048 - val_loss: 42.5374\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.2508 - val_loss: 44.9790\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.7234 - val_loss: 41.8862\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.0597 - val_loss: 43.1075\n",
      "Epoch 49/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 6ms/step - loss: 32.3143 - val_loss: 43.8047\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.7539 - val_loss: 43.4838\n",
      "10/10 [==============================] - 0s 0s/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 33.4760 - val_loss: 45.9694\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.8143 - val_loss: 45.7632\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.0179 - val_loss: 42.0695\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.9051 - val_loss: 45.3706\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.0998 - val_loss: 44.8654\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.8868 - val_loss: 46.5649\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 32.3239 - val_loss: 43.6261\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.7079 - val_loss: 43.4915\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 31.6781 - val_loss: 42.0503\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.3703 - val_loss: 43.0218\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.3785 - val_loss: 45.4420\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.0803 - val_loss: 42.6037\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.7902 - val_loss: 48.7148\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 38.1613 - val_loss: 43.5206\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.2893 - val_loss: 45.4083\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.7177 - val_loss: 49.0777\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.6677 - val_loss: 44.6066\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.9644 - val_loss: 42.3914\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.3773 - val_loss: 47.2396\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.2791 - val_loss: 41.8387\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.6291 - val_loss: 44.4272\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.5481 - val_loss: 51.3716\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.0337 - val_loss: 45.2857\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 33.2402 - val_loss: 44.3646\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.0861 - val_loss: 44.1373\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.8170 - val_loss: 45.6347\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 33.4793 - val_loss: 45.3939\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.7192 - val_loss: 41.5672\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.2982 - val_loss: 44.2785\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.2070 - val_loss: 42.2358\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.4101 - val_loss: 46.8976\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.4283 - val_loss: 48.6747\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 33.6744 - val_loss: 43.1786\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.9714 - val_loss: 46.4033\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.0328 - val_loss: 49.9099\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 35.4755 - val_loss: 53.8730\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.5617 - val_loss: 47.2406\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.1509 - val_loss: 44.6484\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.1083 - val_loss: 43.2615\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.8253 - val_loss: 42.0589\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.3496 - val_loss: 47.2501\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 33.8957 - val_loss: 42.8887\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.1696 - val_loss: 46.4550\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.0813 - val_loss: 41.8572\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.3083 - val_loss: 49.6718\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 33.1770 - val_loss: 43.1075\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.7660 - val_loss: 49.1244\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.5283 - val_loss: 43.0970\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.8969 - val_loss: 43.8936\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.2728 - val_loss: 43.9381\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.6074 - val_loss: 42.4436\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.3804 - val_loss: 44.1850\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.5216 - val_loss: 42.8123\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.9794 - val_loss: 42.5676\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.4495 - val_loss: 45.8269\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.8179 - val_loss: 44.0333\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.7444 - val_loss: 43.8742\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.9120 - val_loss: 43.0244\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.1666 - val_loss: 46.3642\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.2605 - val_loss: 43.2763\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.8561 - val_loss: 42.3985\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.4208 - val_loss: 42.3309\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.7802 - val_loss: 44.5667\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.6128 - val_loss: 41.8605\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 33.0172 - val_loss: 45.9229\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.2161 - val_loss: 42.8205\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 31.3407 - val_loss: 42.8766\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.1212 - val_loss: 48.2992\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.3518 - val_loss: 43.2804\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.7726 - val_loss: 45.8885\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 32.3553 - val_loss: 41.4177\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.3244 - val_loss: 42.8024\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.5597 - val_loss: 42.4585\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.9900 - val_loss: 42.3920\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 31.1077 - val_loss: 45.3470\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.3872 - val_loss: 42.5694\n",
      "Epoch 27/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 31.6920 - val_loss: 42.7922\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.9751 - val_loss: 44.9932\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.3863 - val_loss: 44.4292\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.1140 - val_loss: 42.7919\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.1969 - val_loss: 42.2887\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.6878 - val_loss: 44.2726\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.7668 - val_loss: 47.1563\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.3439 - val_loss: 45.9172\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.2873 - val_loss: 42.9131\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.1192 - val_loss: 43.8992\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 31.8064 - val_loss: 43.8886\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.7804 - val_loss: 42.4464\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 33.2756 - val_loss: 51.4853\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 38.2325 - val_loss: 44.3404\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.6003 - val_loss: 43.5513\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.4893 - val_loss: 47.3641\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 33.6286 - val_loss: 43.3222\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.6200 - val_loss: 44.8843\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.3312 - val_loss: 43.5940\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 33.7014 - val_loss: 44.1053\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 33.0699 - val_loss: 41.9389\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.6088 - val_loss: 43.2368\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.5047 - val_loss: 45.8755\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.8224 - val_loss: 42.5430\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.9661 - val_loss: 45.1103\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.9234 - val_loss: 43.0824\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 33.2585 - val_loss: 44.6245\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.3098 - val_loss: 44.4019\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.5058 - val_loss: 46.6563\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.9281 - val_loss: 42.1092\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.3622 - val_loss: 46.2798\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 33.8595 - val_loss: 44.1024\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.5889 - val_loss: 43.4289\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.0337 - val_loss: 42.6325\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.4610 - val_loss: 43.0896\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.2427 - val_loss: 48.9286\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 33.3993 - val_loss: 42.3207\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.2442 - val_loss: 45.5770\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.6068 - val_loss: 47.5367\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.3779 - val_loss: 42.6478\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.5099 - val_loss: 43.9859\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 31.6174 - val_loss: 42.9539\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.5475 - val_loss: 47.8828\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.4543 - val_loss: 44.9893\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.4358 - val_loss: 46.7170\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.8185 - val_loss: 44.5265\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.4447 - val_loss: 42.3574\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.6474 - val_loss: 43.7803\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.5301 - val_loss: 42.1561\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.9640 - val_loss: 44.1536\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 35.2340 - val_loss: 43.1860\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.1677 - val_loss: 47.9105\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.5382 - val_loss: 42.4964\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.2785 - val_loss: 43.5367\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.2878 - val_loss: 42.0954\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.2586 - val_loss: 43.8606\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.8949 - val_loss: 43.2573\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.8450 - val_loss: 43.3299\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.6548 - val_loss: 43.3367\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.5207 - val_loss: 43.1631\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.3496 - val_loss: 46.3742\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.0690 - val_loss: 45.3509\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.2475 - val_loss: 43.6683\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 33.5180 - val_loss: 43.4338\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.7117 - val_loss: 45.9316\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.8342 - val_loss: 41.9280\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.8549 - val_loss: 43.9714\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.0301 - val_loss: 44.1203\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.4474 - val_loss: 47.7476\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 33.0363 - val_loss: 44.3715\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.3204 - val_loss: 43.7957\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.1938 - val_loss: 49.0014\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.1279 - val_loss: 43.4534\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.0035 - val_loss: 45.2974\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 31.0006 - val_loss: 49.4859\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.2667 - val_loss: 45.9752\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.1743 - val_loss: 42.4569\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 31.2077 - val_loss: 43.4490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.7943 - val_loss: 44.0418\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.8893 - val_loss: 47.1396\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 33.5901 - val_loss: 49.2693\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 37.6541 - val_loss: 53.6104\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.6459 - val_loss: 43.3575\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.9646 - val_loss: 42.3967\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.6688 - val_loss: 43.5457\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.9996 - val_loss: 48.1809\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.5514 - val_loss: 49.5944\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.2039 - val_loss: 43.9270\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.6353 - val_loss: 45.7854\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.0787 - val_loss: 46.8239\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.6042 - val_loss: 43.9551\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.3137 - val_loss: 42.2457\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.1448 - val_loss: 45.3390\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.8624 - val_loss: 46.7508\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 33.6102 - val_loss: 46.6278\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.0206 - val_loss: 43.0078\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.0063 - val_loss: 45.2335\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 33.0376 - val_loss: 41.5209\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.5463 - val_loss: 46.0674\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.6479 - val_loss: 43.6966\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.7164 - val_loss: 43.6790\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.4514 - val_loss: 42.3396\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.8295 - val_loss: 45.7856\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.6231 - val_loss: 43.6375\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.8593 - val_loss: 41.6096\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.0181 - val_loss: 52.4498\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 35.7062 - val_loss: 45.4823\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.0964 - val_loss: 43.6556\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.4551 - val_loss: 42.4181\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.6118 - val_loss: 43.4011\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.8967 - val_loss: 45.5953\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.4472 - val_loss: 45.0694\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.7436 - val_loss: 42.1809\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.0550 - val_loss: 47.4628\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.5190 - val_loss: 46.3302\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.3125 - val_loss: 45.1340\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.0822 - val_loss: 49.4033\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.9832 - val_loss: 48.2636\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.0125 - val_loss: 44.1174\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.9144 - val_loss: 51.5864\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.1884 - val_loss: 44.0054\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.2430 - val_loss: 44.9270\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.8089 - val_loss: 44.3872\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.8137 - val_loss: 45.3165\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 34.1747 - val_loss: 45.4224\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.5314 - val_loss: 44.6639\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 30.9130 - val_loss: 42.8895\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.6940 - val_loss: 44.3714\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.8806 - val_loss: 45.2452\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 33.2412 - val_loss: 43.6873\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 34.4928 - val_loss: 44.9085\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.9860 - val_loss: 42.9084\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.6948 - val_loss: 43.3403\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.2154 - val_loss: 42.0825\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.8622 - val_loss: 49.3382\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 32.2629 - val_loss: 43.7773\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.6641 - val_loss: 45.6028\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 31.3496 - val_loss: 45.1085\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.6222 - val_loss: 43.5543\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.4085 - val_loss: 47.2176\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 33.0824 - val_loss: 43.1260\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.3517 - val_loss: 46.3833\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.7080 - val_loss: 46.3645\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 33.5594 - val_loss: 42.4990\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.2510 - val_loss: 45.8717\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.7561 - val_loss: 44.5934\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 30.9954 - val_loss: 44.8141\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 31.4517 - val_loss: 44.1052\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 31.8502 - val_loss: 47.1152\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 33.7858 - val_loss: 45.1483\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 33.8757 - val_loss: 44.4901\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 31.3479 - val_loss: 43.1053\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.0170 - val_loss: 42.4358\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.6425 - val_loss: 42.0731\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.4370 - val_loss: 42.2632\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.1415 - val_loss: 44.6860\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 30.6803 - val_loss: 43.0226\n",
      "Epoch 34/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 4ms/step - loss: 30.7489 - val_loss: 44.3495\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 31.0488 - val_loss: 42.6231\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.9901 - val_loss: 43.2015\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.3537 - val_loss: 44.2435\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 32.9328 - val_loss: 44.6420\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.7071 - val_loss: 44.2985\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 31.2929 - val_loss: 45.3715\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.6323 - val_loss: 42.4383\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.6771 - val_loss: 46.2180\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.7979 - val_loss: 43.0294\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.7289 - val_loss: 46.6799\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.2143 - val_loss: 41.9801\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.3177 - val_loss: 44.6636\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.0534 - val_loss: 46.0246\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 33.3455 - val_loss: 44.1935\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.9539 - val_loss: 45.3778\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.7655 - val_loss: 49.1398\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 31.7542 - val_loss: 44.0525\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 33.9256 - val_loss: 59.5317\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 33.8073 - val_loss: 46.7939\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.5016 - val_loss: 41.9850\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.3722 - val_loss: 43.5536\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.2079 - val_loss: 42.5734\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 33.0567 - val_loss: 48.9508\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 33.7133 - val_loss: 44.5775\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.9415 - val_loss: 50.8020\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 33.5836 - val_loss: 44.1649\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.7658 - val_loss: 46.2796\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.2875 - val_loss: 45.7928\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 31.5687 - val_loss: 43.8189\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.5033 - val_loss: 53.0028\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.3639 - val_loss: 42.2615\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.5296 - val_loss: 45.1542\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 30.4000 - val_loss: 42.0935\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.5247 - val_loss: 44.7214\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.8183 - val_loss: 43.7730\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 33.4971 - val_loss: 47.6924\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 33.9440 - val_loss: 45.6228\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.2657 - val_loss: 45.4319\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.1603 - val_loss: 41.5657\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.9479 - val_loss: 42.8410\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.0194 - val_loss: 45.1132\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 31.4341 - val_loss: 43.1232\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.3723 - val_loss: 42.8351\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.2580 - val_loss: 46.9882\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.5915 - val_loss: 44.6665\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.1902 - val_loss: 45.5593\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.3542 - val_loss: 44.3172\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.5488 - val_loss: 42.4458\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.9338 - val_loss: 55.2315\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.9715 - val_loss: 42.8964\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.6425 - val_loss: 44.1558\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.4899 - val_loss: 42.6540\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.0641 - val_loss: 44.4613\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.8735 - val_loss: 44.9494\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.4379 - val_loss: 41.3461\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.3700 - val_loss: 45.2146\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 30.8620 - val_loss: 43.8096\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.2630 - val_loss: 45.4409\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 30.9098 - val_loss: 45.4600\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 35.6245 - val_loss: 44.3044\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.9869 - val_loss: 42.2808\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.8180 - val_loss: 44.4882\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.9486 - val_loss: 43.8769\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.7765 - val_loss: 41.9690\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 31.4750 - val_loss: 46.9287\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.4393 - val_loss: 41.8086\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 30.9773 - val_loss: 44.8314\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.1045 - val_loss: 42.5892\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.8336 - val_loss: 43.4177\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.4568 - val_loss: 43.5673\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 33.1623 - val_loss: 45.7360\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.6516 - val_loss: 45.7617\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.4306 - val_loss: 43.4208\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 30.5065 - val_loss: 43.6865\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.2585 - val_loss: 48.8471\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 31.3337 - val_loss: 44.5824\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.8700 - val_loss: 43.2852\n",
      "Epoch 12/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step - loss: 30.7998 - val_loss: 43.8400\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.3195 - val_loss: 43.2723\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 34.0945 - val_loss: 47.7816\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 37.4069 - val_loss: 42.0920\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 33.7935 - val_loss: 44.4520\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.2883 - val_loss: 43.9133\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.7510 - val_loss: 52.9235\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 32.9586 - val_loss: 46.6993\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.1787 - val_loss: 45.0900\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.6283 - val_loss: 43.3857\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 30.3620 - val_loss: 45.1105\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 33.0493 - val_loss: 52.7014\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 37.1119 - val_loss: 51.1459\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.6788 - val_loss: 43.6245\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 32.0581 - val_loss: 43.5167\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 37.9236 - val_loss: 41.4719\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 32.2881 - val_loss: 44.3040\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.9082 - val_loss: 41.9903\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.0224 - val_loss: 46.7925\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.8147 - val_loss: 41.6638\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 30.5707 - val_loss: 43.9368\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.5766 - val_loss: 43.8099\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.5205 - val_loss: 44.7867\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.0044 - val_loss: 42.7447\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.2337 - val_loss: 44.9290\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.1682 - val_loss: 42.2268\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.1742 - val_loss: 46.5139\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.4200 - val_loss: 41.4986\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 31.3576 - val_loss: 42.2758\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.8218 - val_loss: 41.9845\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.4531 - val_loss: 44.9467\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.5215 - val_loss: 42.9020\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.5054 - val_loss: 44.9508\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.2853 - val_loss: 46.4079\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.3243 - val_loss: 52.3517\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 32.1535 - val_loss: 45.8744\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.5171 - val_loss: 52.2533\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.8697 - val_loss: 44.5122\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.6287 - val_loss: 48.6074\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 33.0241 - val_loss: 43.1900\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 33.2930 - val_loss: 44.2405\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.7952 - val_loss: 43.1986\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.1236 - val_loss: 43.9978\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 31.0293 - val_loss: 43.8016\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.3645 - val_loss: 45.9750\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.4992 - val_loss: 44.4874\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.9753 - val_loss: 51.2507\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 37.2544 - val_loss: 51.4495\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 37.1566 - val_loss: 48.2579\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.7831 - val_loss: 43.9251\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.3622 - val_loss: 44.2384\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.8887 - val_loss: 43.5145\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.4906 - val_loss: 46.0875\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.1251 - val_loss: 47.3003\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.1572 - val_loss: 42.4507\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.0111 - val_loss: 42.9019\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.2915 - val_loss: 43.7543\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.4198 - val_loss: 42.0672\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 32.8952 - val_loss: 43.2537\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 30.8619 - val_loss: 46.1747\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.5284 - val_loss: 42.9270\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.0313 - val_loss: 45.1285\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 31.4883 - val_loss: 43.1353\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 30.8354 - val_loss: 44.4435\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.8649 - val_loss: 42.9697\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 31.1068 - val_loss: 42.5160\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.4742 - val_loss: 43.2222\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.9769 - val_loss: 41.1084\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.3466 - val_loss: 48.0550\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.5267 - val_loss: 44.7013\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.8520 - val_loss: 41.6794\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 31.0047 - val_loss: 43.7694\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 31.5443 - val_loss: 46.9315\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.7389 - val_loss: 54.7434\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.2154 - val_loss: 44.6311\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.2486 - val_loss: 46.1235\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 32.1097 - val_loss: 44.3289\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.9378 - val_loss: 44.4934\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.7071 - val_loss: 53.3045\n",
      "Epoch 41/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 7ms/step - loss: 32.8518 - val_loss: 44.6246\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.9108 - val_loss: 46.5081\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.8571 - val_loss: 44.7048\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.1177 - val_loss: 46.0394\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 29.8144 - val_loss: 48.7444\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 30.8066 - val_loss: 43.9632\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.9778 - val_loss: 45.2541\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.2458 - val_loss: 47.0078\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.0127 - val_loss: 45.1967\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.6927 - val_loss: 45.7010\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 31.1044 - val_loss: 43.9679\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.4415 - val_loss: 45.9834\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.6642 - val_loss: 44.3335\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 30.2072 - val_loss: 44.0838\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.3100 - val_loss: 44.9855\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.4242 - val_loss: 42.6313\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.1342 - val_loss: 43.7477\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 30.0462 - val_loss: 46.4272\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.6844 - val_loss: 41.9726\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.1296 - val_loss: 43.8676\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.0441 - val_loss: 42.6995\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.5580 - val_loss: 49.6812\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 30.4196 - val_loss: 43.1344\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.1957 - val_loss: 42.6984\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 31.4086 - val_loss: 53.2099\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 37.0439 - val_loss: 47.1288\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 33.0602 - val_loss: 44.3880\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 31.6353 - val_loss: 43.5600\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 29.6813 - val_loss: 42.6022\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 30.8078 - val_loss: 44.0466\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.5443 - val_loss: 43.0920\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.9557 - val_loss: 59.6233\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.6067 - val_loss: 43.9835\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 29.9738 - val_loss: 44.0448\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 31.2923 - val_loss: 43.9249\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 32.1946 - val_loss: 42.2007\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.0672 - val_loss: 44.1644\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.0153 - val_loss: 43.2958\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.9549 - val_loss: 43.6053\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.1569 - val_loss: 46.8411\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.4222 - val_loss: 43.6197\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 29.9803 - val_loss: 42.7658\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 31.6869 - val_loss: 43.0662\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 30.2503 - val_loss: 44.8924\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 30.7205 - val_loss: 41.9824\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.3255 - val_loss: 47.1425\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.3438 - val_loss: 42.7500\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.5552 - val_loss: 44.4270\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.1343 - val_loss: 44.2360\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.0678 - val_loss: 42.2991\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.5196 - val_loss: 44.4466\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.4829 - val_loss: 43.3553\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 29.9045 - val_loss: 45.1927\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.2825 - val_loss: 44.6805\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.6597 - val_loss: 42.2310\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.3744 - val_loss: 43.8784\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.7662 - val_loss: 44.9321\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.6943 - val_loss: 42.5919\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.1953 - val_loss: 45.1398\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.6368 - val_loss: 57.1807\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.6690 - val_loss: 43.6512\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.3169 - val_loss: 44.2597\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 32.0077 - val_loss: 45.6318\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.3414 - val_loss: 47.9181\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.1532 - val_loss: 44.5141\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.2607 - val_loss: 47.3940\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.2944 - val_loss: 43.3420\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.4972 - val_loss: 45.3688\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.9471 - val_loss: 44.8391\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.3570 - val_loss: 44.9245\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.6655 - val_loss: 42.6334\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 31.4925 - val_loss: 44.7339\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.7649 - val_loss: 44.8917\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 33.5205 - val_loss: 50.3933\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 31.4247 - val_loss: 42.6084\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.1167 - val_loss: 42.8836\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 30.5817 - val_loss: 44.2069\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 30.5432 - val_loss: 44.3677\n",
      "Epoch 19/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 4ms/step - loss: 32.2229 - val_loss: 44.3698\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 32.3678 - val_loss: 45.5941\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 30.5532 - val_loss: 43.0458\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.5160 - val_loss: 45.0112\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.0005 - val_loss: 43.2159\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.9581 - val_loss: 43.2637\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.8413 - val_loss: 42.0251\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.4910 - val_loss: 44.4071\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.9448 - val_loss: 47.6450\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.3188 - val_loss: 46.8293\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.4687 - val_loss: 42.6057\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.8608 - val_loss: 41.1648\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.3190 - val_loss: 44.1863\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.9238 - val_loss: 44.1078\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 31.5393 - val_loss: 44.0949\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 33.2951 - val_loss: 44.0401\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 30.6398 - val_loss: 44.5537\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 30.5204 - val_loss: 50.0954\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.8950 - val_loss: 51.4372\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.0514 - val_loss: 45.3465\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.0740 - val_loss: 42.4991\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 30.9851 - val_loss: 43.7941\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 29.3063 - val_loss: 45.5394\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 31.5769 - val_loss: 46.7015\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.9650 - val_loss: 43.0570\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.0532 - val_loss: 44.5741\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.8214 - val_loss: 44.0667\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.5067 - val_loss: 43.5249\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.3893 - val_loss: 41.9403\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.2426 - val_loss: 46.7257\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.5781 - val_loss: 45.6451\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.9524 - val_loss: 43.9433\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 33.0503 - val_loss: 55.3661\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.7020 - val_loss: 42.8976\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.4408 - val_loss: 46.7075\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.7057 - val_loss: 43.9095\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 31.5412 - val_loss: 44.0049\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 32.5449 - val_loss: 52.7253\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.3407 - val_loss: 42.2908\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.5957 - val_loss: 48.2624\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.2617 - val_loss: 44.1528\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.9252 - val_loss: 45.2055\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.5674 - val_loss: 46.4925\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.3006 - val_loss: 46.1637\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.1165 - val_loss: 48.1745\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.7759 - val_loss: 44.5360\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.6512 - val_loss: 45.5706\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.4598 - val_loss: 48.4551\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 33.0024 - val_loss: 44.4401\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.7772 - val_loss: 43.3479\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.3034 - val_loss: 44.8424\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 32.1031 - val_loss: 44.4002\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.0282 - val_loss: 43.4739\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 30.0599 - val_loss: 44.0369\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 30.3885 - val_loss: 46.0394\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.3710 - val_loss: 42.5880\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 30.0620 - val_loss: 46.2153\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 32.8982 - val_loss: 45.4888\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 31.5754 - val_loss: 43.4776\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.7065 - val_loss: 44.6265\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.7604 - val_loss: 45.4480\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.9663 - val_loss: 42.3399\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.3144 - val_loss: 47.2218\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 33.8543 - val_loss: 44.3535\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.8717 - val_loss: 43.5540\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.5141 - val_loss: 42.2431\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.0101 - val_loss: 43.9904\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.7242 - val_loss: 45.8067\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.8354 - val_loss: 49.3687\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.9875 - val_loss: 43.1031\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.0196 - val_loss: 41.7050\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.9089 - val_loss: 43.8700\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.7207 - val_loss: 46.1738\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.6897 - val_loss: 44.1125\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.6698 - val_loss: 42.1879\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.1220 - val_loss: 43.3450\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.7585 - val_loss: 44.9489\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.3557 - val_loss: 42.7839\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.6902 - val_loss: 45.4190\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 6ms/step - loss: 31.6511 - val_loss: 55.7933\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 37.7334 - val_loss: 50.9249\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.3425 - val_loss: 46.4627\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 30.2635 - val_loss: 45.2902\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.0044 - val_loss: 43.9539\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.2656 - val_loss: 43.4817\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.8488 - val_loss: 43.1552\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.3546 - val_loss: 42.4032\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.5020 - val_loss: 42.9340\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.8507 - val_loss: 44.5900\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.8665 - val_loss: 43.0507\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.2274 - val_loss: 42.8653\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 30.2393 - val_loss: 42.9493\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.0093 - val_loss: 43.2123\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.2407 - val_loss: 42.9122\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.5285 - val_loss: 43.5683\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.2649 - val_loss: 45.1156\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.3465 - val_loss: 44.7201\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.3273 - val_loss: 44.5737\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 32.1398 - val_loss: 41.7171\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.1114 - val_loss: 45.4584\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.0093 - val_loss: 42.7415\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.2654 - val_loss: 45.8479\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.2970 - val_loss: 45.8084\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.6974 - val_loss: 44.5863\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 29.4238 - val_loss: 42.5991\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 30.9551 - val_loss: 49.2956\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 30.5011 - val_loss: 42.2577\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.5385 - val_loss: 46.1941\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 33.2661 - val_loss: 44.8373\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 30.2105 - val_loss: 44.3755\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 30.3651 - val_loss: 43.9684\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 33.5108 - val_loss: 47.4534\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.9393 - val_loss: 43.3411\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.5540 - val_loss: 45.0168\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 29.4672 - val_loss: 44.5327\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.9734 - val_loss: 50.5942\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.8198 - val_loss: 44.9226\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.6679 - val_loss: 43.3616\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 30.0408 - val_loss: 42.2741\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 29.5295 - val_loss: 43.7490\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.4310 - val_loss: 42.8098\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.6063 - val_loss: 43.5153\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.1812 - val_loss: 44.7038\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 30.7293 - val_loss: 44.5809\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.1273 - val_loss: 43.8560\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.6192 - val_loss: 41.6530\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.6101 - val_loss: 47.1566\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.1660 - val_loss: 44.4531\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.2143 - val_loss: 43.8880\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.0435 - val_loss: 43.6220\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 29.3228 - val_loss: 41.7159\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.6222 - val_loss: 42.9072\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 33.5367 - val_loss: 44.5558\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.2595 - val_loss: 53.0200\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 32.0017 - val_loss: 44.9360\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.4755 - val_loss: 45.3056\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 32.5208 - val_loss: 42.4498\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 35.5746 - val_loss: 47.6127\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 34.1735 - val_loss: 50.8400\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.9164 - val_loss: 42.9666\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.6452 - val_loss: 43.8331\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.5527 - val_loss: 43.6163\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.8968 - val_loss: 43.6455\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 33.7881 - val_loss: 53.9614\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.9890 - val_loss: 49.1254\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.9502 - val_loss: 43.8224\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.4958 - val_loss: 43.5063\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.9179 - val_loss: 43.3788\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 29.7148 - val_loss: 43.6280\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 28.8832 - val_loss: 42.6525\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.0060 - val_loss: 43.6302\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 29.2312 - val_loss: 45.3623\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.0916 - val_loss: 43.9606\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.2728 - val_loss: 48.9664\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.4254 - val_loss: 43.3688\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.1479 - val_loss: 44.6651\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 30.7641 - val_loss: 43.4654\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 4ms/step - loss: 30.5677 - val_loss: 43.3951\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.2375 - val_loss: 43.5522\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.8562 - val_loss: 53.1226\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.1426 - val_loss: 45.2958\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 30.3580 - val_loss: 43.4284\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 30.6859 - val_loss: 43.8805\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.8288 - val_loss: 44.1773\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.5415 - val_loss: 44.8751\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.1970 - val_loss: 46.6500\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 33.8825 - val_loss: 44.8335\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 30.4252 - val_loss: 43.7141\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.2057 - val_loss: 47.4170\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.8447 - val_loss: 44.6585\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.4635 - val_loss: 44.6332\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.3363 - val_loss: 47.0205\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.3160 - val_loss: 45.1017\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.4690 - val_loss: 43.3850\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.4659 - val_loss: 46.9723\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.8710 - val_loss: 44.5598\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.9383 - val_loss: 43.3729\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.7003 - val_loss: 42.1785\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.1679 - val_loss: 44.0452\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.0146 - val_loss: 48.2204\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 29.7561 - val_loss: 45.0686\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.0455 - val_loss: 42.4621\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 29.4814 - val_loss: 42.4785\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 30.8568 - val_loss: 50.4362\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.1720 - val_loss: 42.9959\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.1026 - val_loss: 43.5876\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.5475 - val_loss: 43.3519\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.9137 - val_loss: 44.9896\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 29.8261 - val_loss: 43.7779\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.2523 - val_loss: 44.3642\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.3183 - val_loss: 50.8222\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 36.0538 - val_loss: 45.9293\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.3589 - val_loss: 44.5338\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.8453 - val_loss: 42.6049\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.0175 - val_loss: 43.5816\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 29.8914 - val_loss: 48.0223\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.9401 - val_loss: 42.3541\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.3061 - val_loss: 46.8140\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.6080 - val_loss: 43.0057\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 28.9650 - val_loss: 46.2550\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.2959 - val_loss: 43.4009\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.8317 - val_loss: 43.0473\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.7552 - val_loss: 42.0050\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.4538 - val_loss: 44.0069\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.1127 - val_loss: 50.3070\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.5900 - val_loss: 43.3516\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.8328 - val_loss: 47.1812\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.4156 - val_loss: 43.1312\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.6652 - val_loss: 43.5568\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.9438 - val_loss: 44.7643\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.2571 - val_loss: 44.2569\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.2185 - val_loss: 42.9752\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.5352 - val_loss: 42.9624\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.5806 - val_loss: 47.2917\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.6137 - val_loss: 44.4678\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.1553 - val_loss: 42.4780\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 31.5877 - val_loss: 43.4260\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.9983 - val_loss: 44.0742\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.0745 - val_loss: 42.4677\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.4403 - val_loss: 46.2159\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.3354 - val_loss: 45.1297\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 31.0893 - val_loss: 48.1865\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.3548 - val_loss: 45.4693\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 31.0724 - val_loss: 43.3264\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 29.1190 - val_loss: 41.7796\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.5399 - val_loss: 42.9773\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.4770 - val_loss: 45.6961\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 29.8010 - val_loss: 46.0495\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.4954 - val_loss: 46.0130\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.6753 - val_loss: 44.7806\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.0212 - val_loss: 44.0128\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.6469 - val_loss: 43.5603\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 29.2347 - val_loss: 44.8865\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 29.6859 - val_loss: 43.4993\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.0650 - val_loss: 45.0384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.8027 - val_loss: 44.3023\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.2451 - val_loss: 48.3128\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.7193 - val_loss: 44.5680\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.1610 - val_loss: 42.8872\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.5522 - val_loss: 44.6704\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 29.0278 - val_loss: 44.4240\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.7275 - val_loss: 44.1640\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 31.4929 - val_loss: 44.0270\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.2282 - val_loss: 43.3864\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.2720 - val_loss: 43.7933\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.5833 - val_loss: 44.7509\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.0940 - val_loss: 43.3335\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.9967 - val_loss: 43.0058\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.8032 - val_loss: 43.1126\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.7188 - val_loss: 46.9545\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 30.4454 - val_loss: 44.8733\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 29.9309 - val_loss: 45.9003\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.8237 - val_loss: 45.7922\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.6713 - val_loss: 42.5305\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.1652 - val_loss: 44.0108\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 28.9397 - val_loss: 44.0151\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 30.1263 - val_loss: 44.6906\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.3780 - val_loss: 45.8989\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 29.7567 - val_loss: 41.7941\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.2043 - val_loss: 44.5356\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.0409 - val_loss: 56.1071\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 30.2514 - val_loss: 43.7317\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.8356 - val_loss: 43.7050\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 30.1397 - val_loss: 47.6879\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 32.6678 - val_loss: 46.1208\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.8378 - val_loss: 43.9182\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.2979 - val_loss: 43.8691\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 31.3125 - val_loss: 44.3022\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 30.8429 - val_loss: 44.5522\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 28.1925 - val_loss: 43.2745\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 29.1111 - val_loss: 42.8002\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 31.8079 - val_loss: 53.9856\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.9252 - val_loss: 43.6508\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.1645 - val_loss: 44.6454\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.8333 - val_loss: 43.8962\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.4718 - val_loss: 43.9030\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.9320 - val_loss: 43.8129\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.6281 - val_loss: 42.3119\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.7151 - val_loss: 43.4987\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.2554 - val_loss: 43.4988\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 30.1635 - val_loss: 54.1936\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.1985 - val_loss: 44.7189\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 30.5132 - val_loss: 43.7251\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.3667 - val_loss: 44.4245\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.0907 - val_loss: 45.0273\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.3381 - val_loss: 53.1888\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 31.1997 - val_loss: 46.9369\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 29.4894 - val_loss: 44.2646\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 30.7039 - val_loss: 43.7049\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 30.6561 - val_loss: 47.8748\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.0124 - val_loss: 44.3879\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.8850 - val_loss: 43.3021\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 28.7842 - val_loss: 45.3019\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.6619 - val_loss: 42.9907\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.9120 - val_loss: 45.8809\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.0430 - val_loss: 42.0663\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.4884 - val_loss: 42.1827\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.8239 - val_loss: 46.9256\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.8183 - val_loss: 47.5417\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.0635 - val_loss: 43.2642\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.0776 - val_loss: 43.5090\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.4768 - val_loss: 49.2114\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 29.8067 - val_loss: 44.9456\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.4300 - val_loss: 42.8225\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.1598 - val_loss: 43.6935\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 27.7382 - val_loss: 44.3489\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.4876 - val_loss: 49.7534\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.6237 - val_loss: 45.1692\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.9462 - val_loss: 42.6392\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.3975 - val_loss: 45.4540\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.4519 - val_loss: 45.5679\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.8546 - val_loss: 43.4917\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.1882 - val_loss: 46.8796\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.3620 - val_loss: 43.7719\n",
      "Epoch 33/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 29.9614 - val_loss: 50.2111\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 32.1085 - val_loss: 44.7514\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.5150 - val_loss: 44.9513\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.3668 - val_loss: 43.6283\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.1938 - val_loss: 44.5742\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.3333 - val_loss: 44.3377\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 32.3638 - val_loss: 43.8567\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.7374 - val_loss: 44.8789\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.2242 - val_loss: 44.4880\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.5913 - val_loss: 46.3784\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.6993 - val_loss: 42.9485\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.5732 - val_loss: 42.5167\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.0619 - val_loss: 43.0133\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.4779 - val_loss: 44.2415\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.1356 - val_loss: 44.8840\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.6285 - val_loss: 42.3997\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.0414 - val_loss: 43.2184\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.6162 - val_loss: 45.8042\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 29.5505 - val_loss: 44.7393\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.4487 - val_loss: 44.2301\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.7941 - val_loss: 42.4399\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.4913 - val_loss: 47.2720\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 30.0016 - val_loss: 43.8910\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.4020 - val_loss: 44.4879\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.4045 - val_loss: 49.1998\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.0862 - val_loss: 43.3963\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 28.8379 - val_loss: 43.3637\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.8223 - val_loss: 45.1489\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.5118 - val_loss: 47.6145\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.2448 - val_loss: 44.9122\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.0773 - val_loss: 44.3147\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.0629 - val_loss: 42.2463\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.5148 - val_loss: 45.0160\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 29.7511 - val_loss: 42.4573\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 29.7301 - val_loss: 44.6876\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.0831 - val_loss: 47.0004\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 30.9590 - val_loss: 49.2609\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.8064 - val_loss: 49.7845\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 30.9163 - val_loss: 43.0753\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.2243 - val_loss: 44.7447\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.8910 - val_loss: 43.7539\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.2112 - val_loss: 43.5322\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.6911 - val_loss: 46.7816\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 30.8503 - val_loss: 46.7596\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.0323 - val_loss: 44.6225\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.8115 - val_loss: 45.3476\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.0377 - val_loss: 44.9199\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 30.0585 - val_loss: 45.5838\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 29.3209 - val_loss: 42.5399\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 29.5995 - val_loss: 45.7626\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.8912 - val_loss: 47.5660\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.0041 - val_loss: 50.9042\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.7694 - val_loss: 43.8431\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.6755 - val_loss: 44.1683\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.2647 - val_loss: 45.7332\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.0098 - val_loss: 43.1716\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.3443 - val_loss: 45.9326\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.3428 - val_loss: 43.8607\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.7355 - val_loss: 43.5648\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.0595 - val_loss: 47.9927\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.3460 - val_loss: 43.5079\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.2027 - val_loss: 41.8390\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.2307 - val_loss: 42.9218\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.9704 - val_loss: 53.4298\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 38.6830 - val_loss: 47.2512\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.2749 - val_loss: 43.6827\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.4674 - val_loss: 45.5350\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.2031 - val_loss: 44.4759\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 28.6665 - val_loss: 44.4900\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.0935 - val_loss: 43.4113\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.2051 - val_loss: 43.0435\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.1039 - val_loss: 47.9760\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.2998 - val_loss: 45.1900\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.4952 - val_loss: 49.6722\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.3003 - val_loss: 42.7516\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.9900 - val_loss: 44.2046\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.6107 - val_loss: 43.3615\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.1110 - val_loss: 42.7193\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 30.2779 - val_loss: 50.2998\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.0683 - val_loss: 43.2286\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 32.0701 - val_loss: 55.8801\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.7783 - val_loss: 44.2193\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.5647 - val_loss: 42.2663\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.4052 - val_loss: 44.8387\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 28.8711 - val_loss: 45.0476\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.8690 - val_loss: 42.3205\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.8123 - val_loss: 44.2098\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 28.5147 - val_loss: 43.1371\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 30.0551 - val_loss: 47.0981\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 29.2195 - val_loss: 43.4378\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.3917 - val_loss: 43.2273\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.9735 - val_loss: 44.2134\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.9544 - val_loss: 47.3796\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 29.3528 - val_loss: 44.8523\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 31.9521 - val_loss: 41.8558\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.3233 - val_loss: 46.1536\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.8419 - val_loss: 43.2352\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 28.9586 - val_loss: 44.4395\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.7597 - val_loss: 47.5107\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.3842 - val_loss: 45.2093\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.3002 - val_loss: 44.1783\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.5967 - val_loss: 44.8706\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 28.7492 - val_loss: 44.5866\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.4040 - val_loss: 45.8759\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.2006 - val_loss: 44.5971\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.1983 - val_loss: 43.9711\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.7270 - val_loss: 43.5012\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.4907 - val_loss: 43.6410\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 28.4453 - val_loss: 44.3970\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.7584 - val_loss: 44.4216\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 30.4130 - val_loss: 44.5475\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.3240 - val_loss: 45.3704\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.7711 - val_loss: 42.5452\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.3899 - val_loss: 42.7418\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.2067 - val_loss: 45.2392\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.5455 - val_loss: 49.0715\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 30.4458 - val_loss: 43.9630\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.2336 - val_loss: 44.8305\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 29.1043 - val_loss: 43.6994\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.1058 - val_loss: 43.5754\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.4276 - val_loss: 43.3016\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.9542 - val_loss: 47.8065\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 29.3416 - val_loss: 46.4406\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.1357 - val_loss: 45.0131\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.3968 - val_loss: 43.9317\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.0362 - val_loss: 44.6017\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.8547 - val_loss: 43.2823\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.2842 - val_loss: 50.9457\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.4359 - val_loss: 42.6696\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.7597 - val_loss: 43.5831\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.7799 - val_loss: 43.4793\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.0652 - val_loss: 43.3415\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.5011 - val_loss: 43.0314\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.6677 - val_loss: 45.9673\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.6811 - val_loss: 41.8725\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.1409 - val_loss: 44.9416\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 29.9263 - val_loss: 45.1785\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.5310 - val_loss: 46.3151\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 29.9567 - val_loss: 43.7107\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 28.6475 - val_loss: 43.4881\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.2532 - val_loss: 44.3935\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 28.7858 - val_loss: 43.6084\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.4864 - val_loss: 43.0221\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.2804 - val_loss: 43.5745\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.9043 - val_loss: 45.6736\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.5827 - val_loss: 43.7051\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.6538 - val_loss: 44.5861\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.4398 - val_loss: 44.6027\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 29.9763 - val_loss: 45.4464\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.7786 - val_loss: 43.0008\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.1250 - val_loss: 44.3072\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.5013 - val_loss: 43.5411\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 30.3135 - val_loss: 43.6041\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.0170 - val_loss: 46.0823\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.5761 - val_loss: 43.4739\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.5930 - val_loss: 43.6745\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.2018 - val_loss: 43.1437\n",
      "Epoch 40/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 6ms/step - loss: 27.8876 - val_loss: 42.9391\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.8170 - val_loss: 45.8541\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.6639 - val_loss: 44.4200\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 30.2520 - val_loss: 46.1905\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.0408 - val_loss: 43.2969\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.0818 - val_loss: 47.3756\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.9226 - val_loss: 45.4001\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.1808 - val_loss: 42.7084\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.1914 - val_loss: 43.2715\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.8340 - val_loss: 42.5288\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.1119 - val_loss: 48.0306\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.6721 - val_loss: 46.7594\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.6463 - val_loss: 42.5951\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.1298 - val_loss: 45.9128\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.7607 - val_loss: 45.9635\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.7060 - val_loss: 47.0054\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.6095 - val_loss: 42.8288\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.7702 - val_loss: 47.1757\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 29.7801 - val_loss: 42.8367\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 29.0804 - val_loss: 44.1177\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.4379 - val_loss: 45.2265\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.4086 - val_loss: 43.9249\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.3580 - val_loss: 43.7531\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 27.7858 - val_loss: 44.9162\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.3204 - val_loss: 45.1516\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.1526 - val_loss: 42.3757\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.4498 - val_loss: 48.3058\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.5035 - val_loss: 49.2934\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.6287 - val_loss: 42.0165\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.4720 - val_loss: 45.5518\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.9907 - val_loss: 45.9722\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.8134 - val_loss: 45.8853\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.1859 - val_loss: 52.8148\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 35.2201 - val_loss: 44.6278\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.1930 - val_loss: 44.2931\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 28.4481 - val_loss: 43.0164\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.2471 - val_loss: 61.0941\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.4271 - val_loss: 43.2685\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.3172 - val_loss: 44.1371\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.7389 - val_loss: 43.4907\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.3689 - val_loss: 43.1500\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 30.3521 - val_loss: 45.0860\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.5376 - val_loss: 43.5787\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.4761 - val_loss: 44.6207\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.5131 - val_loss: 43.4201\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.6151 - val_loss: 43.8787\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.1304 - val_loss: 43.2715\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.2968 - val_loss: 46.6894\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.7678 - val_loss: 44.4561\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.5101 - val_loss: 48.3292\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.9708 - val_loss: 49.7196\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.0472 - val_loss: 43.1237\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 29.2804 - val_loss: 44.3278\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.0096 - val_loss: 46.2246\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.8045 - val_loss: 43.3283\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.4210 - val_loss: 49.6037\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.0947 - val_loss: 42.1973\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.2530 - val_loss: 43.6135\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.5064 - val_loss: 42.9071\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.7623 - val_loss: 43.7535\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.1226 - val_loss: 42.3226\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 29.5010 - val_loss: 47.0503\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.9032 - val_loss: 42.9404\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.5303 - val_loss: 42.7106\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 27.8030 - val_loss: 44.7852\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 29.4616 - val_loss: 44.4095\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.7109 - val_loss: 46.7053\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 32.4738 - val_loss: 44.2301\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.6830 - val_loss: 43.3955\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.4051 - val_loss: 46.5626\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.2019 - val_loss: 45.9769\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 28.0648 - val_loss: 43.7542\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.0589 - val_loss: 43.2790\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.1573 - val_loss: 43.6262\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.3959 - val_loss: 42.8772\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 27.9432 - val_loss: 42.7059\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.2055 - val_loss: 44.0298\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.7332 - val_loss: 44.1898\n",
      "Epoch 18/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 29.1168 - val_loss: 45.6073\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.8609 - val_loss: 42.8524\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.1445 - val_loss: 43.7238\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.1828 - val_loss: 42.7849\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.9898 - val_loss: 46.6030\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.3888 - val_loss: 42.7966\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 30.1069 - val_loss: 47.2809\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 28.4034 - val_loss: 43.9963\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.6853 - val_loss: 44.9708\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.6695 - val_loss: 42.7746\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.8997 - val_loss: 46.0925\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.4500 - val_loss: 43.4533\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.4149 - val_loss: 44.4427\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.1136 - val_loss: 44.7836\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.1187 - val_loss: 46.0312\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.8781 - val_loss: 44.3260\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.2152 - val_loss: 44.2518\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.4683 - val_loss: 42.6222\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.6472 - val_loss: 44.7195\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.7467 - val_loss: 42.4260\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 28.4337 - val_loss: 43.7862\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.0586 - val_loss: 59.0625\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 34.4400 - val_loss: 43.4561\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.2390 - val_loss: 47.2934\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.8264 - val_loss: 43.3704\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.4452 - val_loss: 43.8720\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.5525 - val_loss: 48.1414\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.2628 - val_loss: 43.1210\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.4410 - val_loss: 44.2422\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.6011 - val_loss: 44.9268\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.5021 - val_loss: 61.9312\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.0061 - val_loss: 44.6772\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.8555 - val_loss: 44.4545\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 28.8419 - val_loss: 42.5881\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.4528 - val_loss: 43.6337\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.1095 - val_loss: 44.9687\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.5004 - val_loss: 44.7308\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.1968 - val_loss: 46.0547\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.6827 - val_loss: 41.6831\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.6569 - val_loss: 43.8527\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.1094 - val_loss: 47.5992\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.5867 - val_loss: 55.1134\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.6936 - val_loss: 44.3718\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 28.6558 - val_loss: 43.0463\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.8378 - val_loss: 44.2328\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.4155 - val_loss: 43.2130\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.4064 - val_loss: 43.6059\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.4219 - val_loss: 45.1559\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.5385 - val_loss: 45.0220\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 28.4914 - val_loss: 45.9716\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.4247 - val_loss: 43.7751\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.4386 - val_loss: 48.6355\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.7692 - val_loss: 45.3700\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.2711 - val_loss: 43.7658\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 28.5723 - val_loss: 42.9577\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.1069 - val_loss: 46.6867\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.2688 - val_loss: 44.6263\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.7493 - val_loss: 49.9663\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.9264 - val_loss: 42.9732\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.1368 - val_loss: 43.2045\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.2722 - val_loss: 45.1708\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 30.3579 - val_loss: 43.1337\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.2266 - val_loss: 43.0525\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.1678 - val_loss: 43.9209\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.0214 - val_loss: 44.9473\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.2811 - val_loss: 42.9688\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 27.9477 - val_loss: 45.4933\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.8904 - val_loss: 43.2039\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.7486 - val_loss: 42.8150\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 28.5990 - val_loss: 43.5977\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.3293 - val_loss: 45.0380\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.3357 - val_loss: 42.5266\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.6095 - val_loss: 43.8431\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.1754 - val_loss: 44.5012\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.5012 - val_loss: 43.1441\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.6002 - val_loss: 45.0105\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.9259 - val_loss: 45.9515\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.3890 - val_loss: 42.4474\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.3456 - val_loss: 43.4954\n",
      "Epoch 47/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 29.7383 - val_loss: 45.2064\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.4973 - val_loss: 44.2258\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.0362 - val_loss: 43.2870\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.1246 - val_loss: 43.0838\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 30.6893 - val_loss: 54.2096\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.3516 - val_loss: 44.9842\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.3634 - val_loss: 53.3913\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.9037 - val_loss: 48.3320\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.7513 - val_loss: 44.7966\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.4222 - val_loss: 43.1872\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.3524 - val_loss: 43.8558\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.2615 - val_loss: 46.1317\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.9400 - val_loss: 47.8536\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.6145 - val_loss: 42.5581\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.0607 - val_loss: 50.6331\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.7068 - val_loss: 44.1430\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.7823 - val_loss: 46.7622\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.6344 - val_loss: 42.3684\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.4653 - val_loss: 42.4913\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.7215 - val_loss: 42.4470\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.3909 - val_loss: 44.2451\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.5080 - val_loss: 44.6289\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.2220 - val_loss: 42.9710\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.2386 - val_loss: 46.4548\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.6512 - val_loss: 42.9502\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.2608 - val_loss: 43.7031\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.1491 - val_loss: 42.6160\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.3846 - val_loss: 42.9617\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 27.9374 - val_loss: 42.8539\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 27.7260 - val_loss: 43.4859\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 27.6538 - val_loss: 47.2180\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.0848 - val_loss: 49.8087\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.5673 - val_loss: 43.8286\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.1504 - val_loss: 42.7104\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 27.9476 - val_loss: 41.8850\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.0833 - val_loss: 43.4145\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 27.8855 - val_loss: 46.1839\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.1099 - val_loss: 43.1594\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.8498 - val_loss: 43.9462\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.2100 - val_loss: 43.9629\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.1921 - val_loss: 43.0932\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 28.2271 - val_loss: 42.9495\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 28.0375 - val_loss: 42.4369\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.1782 - val_loss: 47.5332\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.8397 - val_loss: 42.3733\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 28.1520 - val_loss: 43.5081\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.8405 - val_loss: 43.4095\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.2710 - val_loss: 44.0680\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.4721 - val_loss: 45.5309\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 27.9858 - val_loss: 46.0731\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.2275 - val_loss: 44.2167\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.1731 - val_loss: 43.3434\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.9421 - val_loss: 43.2585\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.4684 - val_loss: 50.8675\n",
      "10/10 [==============================] - 0s 894us/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 30.7210 - val_loss: 44.8858\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.9203 - val_loss: 45.8860\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.1786 - val_loss: 46.3398\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.6734 - val_loss: 43.8257\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.4878 - val_loss: 46.5978\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.2791 - val_loss: 44.5480\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.9354 - val_loss: 44.1981\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.8759 - val_loss: 43.7804\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.6142 - val_loss: 44.4539\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.5893 - val_loss: 44.2905\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.2083 - val_loss: 44.2374\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.1141 - val_loss: 43.3008\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.2359 - val_loss: 42.9253\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.5713 - val_loss: 44.4256\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.7290 - val_loss: 45.7998\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.9279 - val_loss: 43.2824\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.2099 - val_loss: 43.7378\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.7291 - val_loss: 42.5444\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.3165 - val_loss: 43.2333\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.4285 - val_loss: 43.5713\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.5578 - val_loss: 43.9177\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.4942 - val_loss: 42.5279\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 27.7201 - val_loss: 42.1572\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.7471 - val_loss: 43.2110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.9675 - val_loss: 43.4070\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.8690 - val_loss: 42.1471\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.9001 - val_loss: 43.7821\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.0505 - val_loss: 43.0786\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 29.3418 - val_loss: 42.6399\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.2005 - val_loss: 42.7938\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.6075 - val_loss: 44.2857\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.8149 - val_loss: 42.6849\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.2489 - val_loss: 42.4790\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.9129 - val_loss: 42.6854\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.1805 - val_loss: 42.5582\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 27.9414 - val_loss: 42.6303\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.3393 - val_loss: 51.4715\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.6424 - val_loss: 42.2191\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.5831 - val_loss: 43.2618\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.4810 - val_loss: 47.3643\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 33.9184 - val_loss: 48.4337\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.0431 - val_loss: 43.8993\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.1109 - val_loss: 43.5834\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 27.8252 - val_loss: 44.7156\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.3545 - val_loss: 42.8896\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.0093 - val_loss: 44.4890\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.8235 - val_loss: 43.0958\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.8416 - val_loss: 42.4578\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.2789 - val_loss: 43.1860\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.1232 - val_loss: 42.4971\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.5446 - val_loss: 45.6973\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 27.7886 - val_loss: 43.7971\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.1053 - val_loss: 43.5749\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 29.7733 - val_loss: 49.8509\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.3975 - val_loss: 46.2327\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.9788 - val_loss: 43.1738\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.0654 - val_loss: 43.9529\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.3907 - val_loss: 43.2641\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.4265 - val_loss: 44.3022\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.6064 - val_loss: 47.7112\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.6380 - val_loss: 42.6754\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.3629 - val_loss: 42.1288\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.8930 - val_loss: 44.0405\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.1171 - val_loss: 42.7002\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.2405 - val_loss: 43.3265\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.2609 - val_loss: 42.4368\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.3542 - val_loss: 46.0116\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.5166 - val_loss: 44.7824\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.9792 - val_loss: 50.1792\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.3057 - val_loss: 42.8915\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.3646 - val_loss: 45.9020\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.8652 - val_loss: 43.0529\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.4574 - val_loss: 45.4672\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.7758 - val_loss: 42.1260\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.8409 - val_loss: 42.9260\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.2197 - val_loss: 43.4869\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 32.6961 - val_loss: 47.3118\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.2061 - val_loss: 43.9781\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.0028 - val_loss: 44.3047\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.9269 - val_loss: 43.9279\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 27.7472 - val_loss: 43.5748\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.1558 - val_loss: 43.1165\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.1310 - val_loss: 49.7718\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 30.2889 - val_loss: 43.3439\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 27.3642 - val_loss: 44.4505\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 29.0077 - val_loss: 44.2863\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.1120 - val_loss: 47.8091\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 35.1835 - val_loss: 48.6429\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.7074 - val_loss: 44.1015\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.0011 - val_loss: 44.1546\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.1329 - val_loss: 42.7289\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.4217 - val_loss: 49.5492\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.0784 - val_loss: 44.7993\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.7792 - val_loss: 42.5315\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 27.7730 - val_loss: 44.8309\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 29.6361 - val_loss: 42.8894\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.3825 - val_loss: 42.9237\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.7430 - val_loss: 43.7725\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.1100 - val_loss: 44.2691\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.7002 - val_loss: 44.4010\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.3315 - val_loss: 43.5326\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.2373 - val_loss: 52.2316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.4311 - val_loss: 43.1442\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.8904 - val_loss: 43.5068\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 29.2889 - val_loss: 45.0106\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.8723 - val_loss: 43.0462\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.0772 - val_loss: 44.5372\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.3870 - val_loss: 42.9033\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.6378 - val_loss: 42.6972\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 27.6349 - val_loss: 42.9478\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.5358 - val_loss: 43.5531\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.1469 - val_loss: 42.8293\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.7040 - val_loss: 45.4123\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.1074 - val_loss: 44.0423\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.7560 - val_loss: 43.4991\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.5502 - val_loss: 47.2859\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.0326 - val_loss: 44.6025\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.8611 - val_loss: 43.2652\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.0416 - val_loss: 44.8836\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.1357 - val_loss: 43.4323\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.1529 - val_loss: 42.6374\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.4232 - val_loss: 43.3497\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.6107 - val_loss: 43.7054\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 27.9798 - val_loss: 43.2252\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 27.4413 - val_loss: 43.2446\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 27.8993 - val_loss: 47.8700\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.7045 - val_loss: 42.2031\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.0444 - val_loss: 44.4838\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.8633 - val_loss: 43.5925\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.3178 - val_loss: 44.1180\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 27.6261 - val_loss: 45.0940\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.0766 - val_loss: 48.3433\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.2391 - val_loss: 42.7195\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.4729 - val_loss: 46.1577\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.1461 - val_loss: 42.9708\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.3686 - val_loss: 51.1031\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.9569 - val_loss: 43.6210\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.8753 - val_loss: 50.8387\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.0427 - val_loss: 44.1087\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 28.1430 - val_loss: 43.0174\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.0462 - val_loss: 43.1557\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.2791 - val_loss: 44.2218\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.6795 - val_loss: 45.1417\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.1991 - val_loss: 43.3433\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 27.9333 - val_loss: 42.7604\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 27.9985 - val_loss: 44.3679\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.8492 - val_loss: 46.4210\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.3601 - val_loss: 42.8528\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.7376 - val_loss: 45.2288\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.4824 - val_loss: 42.8690\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 29.3197 - val_loss: 45.6372\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 27.8877 - val_loss: 46.6570\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.3027 - val_loss: 43.6429\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.9243 - val_loss: 43.2634\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.6244 - val_loss: 44.7760\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.2023 - val_loss: 42.4384\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 27.9189 - val_loss: 46.0760\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.1728 - val_loss: 43.8536\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.9753 - val_loss: 45.5503\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.5130 - val_loss: 50.0905\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.6553 - val_loss: 49.0369\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.2482 - val_loss: 45.8744\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.1611 - val_loss: 42.9540\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.2959 - val_loss: 44.2863\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.2335 - val_loss: 42.8456\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.1736 - val_loss: 46.9945\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.2403 - val_loss: 43.7101\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 28.6792 - val_loss: 44.7454\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.2478 - val_loss: 44.0447\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.8823 - val_loss: 44.6270\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.1432 - val_loss: 49.3345\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.9454 - val_loss: 44.3270\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 28.0563 - val_loss: 42.0504\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.1156 - val_loss: 43.1082\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.4141 - val_loss: 43.5163\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.5743 - val_loss: 43.3435\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.2856 - val_loss: 45.6616\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.9745 - val_loss: 50.3902\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.9124 - val_loss: 44.1391\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.9168 - val_loss: 42.9007\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.5462 - val_loss: 46.7845\n",
      "Epoch 32/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 6ms/step - loss: 30.2054 - val_loss: 42.7099\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.0185 - val_loss: 43.9061\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.3688 - val_loss: 44.0245\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.0167 - val_loss: 43.7626\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.9480 - val_loss: 47.9374\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.4881 - val_loss: 45.6498\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.4732 - val_loss: 44.9071\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.8004 - val_loss: 45.9335\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.5529 - val_loss: 43.5186\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 27.6482 - val_loss: 42.7451\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 27.4241 - val_loss: 45.3951\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.7065 - val_loss: 42.3165\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 28.8058 - val_loss: 44.2587\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.3147 - val_loss: 48.4212\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.1888 - val_loss: 44.4896\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.2886 - val_loss: 43.4830\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.6880 - val_loss: 42.6692\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 27.9618 - val_loss: 43.4676\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 27.8843 - val_loss: 44.0116\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "-----DESCRIPTION---- Predictors Labels\n",
      "Size of training set: (721, 8) (721, 1)\n",
      "Size of testing set:  (309, 8) (309, 1)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 27.4214 - val_loss: 43.1447\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 28.1047 - val_loss: 43.2318\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 27.5333 - val_loss: 43.7499\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 27.9416 - val_loss: 45.2443\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 27.8479 - val_loss: 44.2049\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 27.9196 - val_loss: 42.6385\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 29.2957 - val_loss: 47.5126\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.7902 - val_loss: 43.8637\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.6468 - val_loss: 45.6542\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 30.0761 - val_loss: 47.1162\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 28.5603 - val_loss: 45.6306\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.2895 - val_loss: 45.2122\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.9213 - val_loss: 44.0601\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 33.5966 - val_loss: 55.8766\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 31.1963 - val_loss: 46.0179\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.6492 - val_loss: 49.0842\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.3003 - val_loss: 43.5623\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.1802 - val_loss: 45.6003\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.1436 - val_loss: 42.8881\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.3670 - val_loss: 43.2361\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.7803 - val_loss: 43.9302\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.9690 - val_loss: 43.5842\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.7966 - val_loss: 42.4667\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.9791 - val_loss: 47.2806\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.0804 - val_loss: 43.8351\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.3161 - val_loss: 43.8369\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.7161 - val_loss: 43.6308\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.7870 - val_loss: 43.1213\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.4587 - val_loss: 44.0162\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.0912 - val_loss: 45.1826\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.3222 - val_loss: 43.3991\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.6977 - val_loss: 43.7014\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.1533 - val_loss: 47.0907\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 30.3868 - val_loss: 48.4653\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.8021 - val_loss: 45.1199\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.6893 - val_loss: 43.1523\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.7239 - val_loss: 48.9082\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.9841 - val_loss: 46.4173\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 27.8669 - val_loss: 43.5739\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.3294 - val_loss: 43.5502\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.9045 - val_loss: 45.8127\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.1328 - val_loss: 42.3144\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.7916 - val_loss: 47.2163\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30.6995 - val_loss: 45.2433\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.4069 - val_loss: 42.9482\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 27.8696 - val_loss: 42.9161\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.0283 - val_loss: 47.3279\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.2944 - val_loss: 45.4802\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.3998 - val_loss: 48.6130\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.8387 - val_loss: 44.8352\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Computing mean squared error for each iteration\n",
    "mse_new = [] # Initializing the list for appending the MSE upon each iteration\n",
    "for i in range(50):\n",
    "    mse_new.append(MSE(model_new, X_norm, Y, 50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reporting Mean and Standard Deviation of the Mean Squared Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the mean squared error\n",
    "x = ['{0}'.format(i+1) for i in range(50)]\n",
    "plt.bar(x,mse_new)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Mean Squared Error - MSE')\n",
    "plt.title('Evolution of MSE of normalized data over the iterations - epochs:100')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of the MSE's: 51.086674511009605\n",
      "Standard deviation of the MSE's: 3.4092534187366597\n"
     ]
    }
   ],
   "source": [
    "# Mean of the MSE's\n",
    "mean_partD = np.array(mse_new).mean()\n",
    "print(\"Mean of the MSE's:\",mean_partD)\n",
    "\n",
    "# Standard deviation of the MSE'S\n",
    "std_partD = np.array(mse_new).std()\n",
    "print(\"Standard deviation of the MSE's:\",std_partD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison between the Mean of the Mean Squared Errors on increasing the hidden layers in the model built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(['1 hidden layer','3 hidden layer'],[mean_partB,mean_partD])\n",
    "plt.xlabel('Number of epochs')\n",
    "plt.ylabel(\"Mean of the MSE's\")\n",
    "plt.title('Normalized data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6.189292722789197"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Difference between both mean of the MSE's\n",
    "mean_partD-mean_partB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus it can be observef on the hidden layers in the model, the error decreases and accuracy of the prediction increases."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
